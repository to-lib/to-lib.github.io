"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[90721],{48885:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var r=t(99378);const s={},i=r.createContext(s);function o(e){const n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(i.Provider,{value:n},e.children)}},63393:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>o,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"ml/contrastive-learning","title":"\ud83d\udd04 \u5bf9\u6bd4\u5b66\u4e60","description":"\u5bf9\u6bd4\u5b66\u4e60\u901a\u8fc7\u6bd4\u8f83\u76f8\u4f3c\u548c\u4e0d\u76f8\u4f3c\u7684\u6837\u672c\u6765\u5b66\u4e60\u8868\u793a\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u7b7e\u3002","source":"@site/docs/ml/contrastive-learning.md","sourceDirName":"ml","slug":"/ml/contrastive-learning","permalink":"/docs/ml/contrastive-learning","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ml/contrastive-learning.md","tags":[],"version":"current","sidebarPosition":26,"frontMatter":{"sidebar_position":26,"title":"\ud83d\udd04 \u5bf9\u6bd4\u5b66\u4e60"},"sidebar":"ml","previous":{"title":"\ud83c\udfa8 \u751f\u6210\u6a21\u578b","permalink":"/docs/ml/generative-models"},"next":{"title":"\ud83c\udfaf \u591a\u4efb\u52a1\u5b66\u4e60","permalink":"/docs/ml/multi-task-learning"}}');var s=t(22714),i=t(48885);const o={sidebar_position:26,title:"\ud83d\udd04 \u5bf9\u6bd4\u5b66\u4e60"},a="\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u81ea\u76d1\u7763\u5b66\u4e60",l={},d=[{value:"\u6838\u5fc3\u601d\u60f3",id:"\u6838\u5fc3\u601d\u60f3",level:2},{value:"SimCLR",id:"simclr",level:2},{value:"MoCo",id:"moco",level:2},{value:"CLIP",id:"clip",level:2},{value:"\u5e94\u7528\u573a\u666f",id:"\u5e94\u7528\u573a\u666f",level:2},{value:"\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03",id:"\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",mermaid:"mermaid",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u81ea\u76d1\u7763\u5b66\u4e60",children:"\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u81ea\u76d1\u7763\u5b66\u4e60"})}),"\n",(0,s.jsx)(n.p,{children:"\u5bf9\u6bd4\u5b66\u4e60\u901a\u8fc7\u6bd4\u8f83\u76f8\u4f3c\u548c\u4e0d\u76f8\u4f3c\u7684\u6837\u672c\u6765\u5b66\u4e60\u8868\u793a\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u7b7e\u3002"}),"\n",(0,s.jsx)(n.h2,{id:"\u6838\u5fc3\u601d\u60f3",children:"\u6838\u5fc3\u601d\u60f3"}),"\n",(0,s.jsx)(n.mermaid,{value:"graph LR\n    A[\u539f\u59cb\u6837\u672c] --\x3e B[\u589e\u5f3a1]\n    A --\x3e C[\u589e\u5f3a2]\n    B --\x3e D[\u7f16\u7801\u5668]\n    C --\x3e D\n    D --\x3e E[\u6b63\u6837\u672c\u5bf9\u63a5\u8fd1]\n    D --\x3e F[\u8d1f\u6837\u672c\u5bf9\u8fdc\u79bb]"}),"\n",(0,s.jsx)(n.h2,{id:"simclr",children:"SimCLR"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import torch\nimport torch.nn as nn\nimport torchvision.transforms as T\n\n# \u6570\u636e\u589e\u5f3a\naugmentation = T.Compose([\n    T.RandomResizedCrop(224),\n    T.RandomHorizontalFlip(),\n    T.ColorJitter(0.4, 0.4, 0.4, 0.1),\n    T.RandomGrayscale(p=0.2),\n    T.GaussianBlur(kernel_size=23),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nclass SimCLR(nn.Module):\n    def __init__(self, encoder, projection_dim=128):\n        super().__init__()\n        self.encoder = encoder\n        self.projector = nn.Sequential(\n            nn.Linear(encoder.output_dim, 512),\n            nn.ReLU(),\n            nn.Linear(512, projection_dim)\n        )\n\n    def forward(self, x):\n        h = self.encoder(x)\n        z = self.projector(h)\n        return nn.functional.normalize(z, dim=1)\n\n# NT-Xent \u635f\u5931\ndef nt_xent_loss(z1, z2, temperature=0.5):\n    batch_size = z1.size(0)\n    z = torch.cat([z1, z2], dim=0)\n    sim = torch.mm(z, z.t()) / temperature\n\n    # \u6b63\u6837\u672c\u5bf9\u7684\u4f4d\u7f6e\n    pos_mask = torch.zeros(2 * batch_size, 2 * batch_size, dtype=torch.bool)\n    pos_mask[:batch_size, batch_size:] = torch.eye(batch_size, dtype=torch.bool)\n    pos_mask[batch_size:, :batch_size] = torch.eye(batch_size, dtype=torch.bool)\n\n    # \u6392\u9664\u81ea\u8eab\n    self_mask = torch.eye(2 * batch_size, dtype=torch.bool)\n    sim.masked_fill_(self_mask, float('-inf'))\n\n    loss = -torch.log(torch.exp(sim[pos_mask]) / torch.exp(sim).sum(dim=1))\n    return loss.mean()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"moco",children:"MoCo"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class MoCo(nn.Module):\n    def __init__(self, encoder, dim=128, K=65536, m=0.999, T=0.07):\n        super().__init__()\n        self.K = K\n        self.m = m\n        self.T = T\n\n        self.encoder_q = encoder\n        self.encoder_k = copy.deepcopy(encoder)\n\n        # \u51bb\u7ed3\u52a8\u91cf\u7f16\u7801\u5668\n        for param in self.encoder_k.parameters():\n            param.requires_grad = False\n\n        # \u961f\u5217\n        self.register_buffer("queue", torch.randn(dim, K))\n        self.queue = nn.functional.normalize(self.queue, dim=0)\n\n    @torch.no_grad()\n    def momentum_update(self):\n        for p_q, p_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n            p_k.data = self.m * p_k.data + (1 - self.m) * p_q.data\n'})}),"\n",(0,s.jsx)(n.h2,{id:"clip",children:"CLIP"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class CLIP(nn.Module):\n    def __init__(self, image_encoder, text_encoder, embed_dim):\n        super().__init__()\n        self.image_encoder = image_encoder\n        self.text_encoder = text_encoder\n        self.temperature = nn.Parameter(torch.ones([]) * 0.07)\n\n    def forward(self, images, texts):\n        image_features = self.image_encoder(images)\n        text_features = self.text_encoder(texts)\n\n        # \u5f52\u4e00\u5316\n        image_features = nn.functional.normalize(image_features, dim=-1)\n        text_features = nn.functional.normalize(text_features, dim=-1)\n\n        # \u8ba1\u7b97\u76f8\u4f3c\u5ea6\n        logits = image_features @ text_features.t() / self.temperature\n        return logits\n"})}),"\n",(0,s.jsx)(n.h2,{id:"\u5e94\u7528\u573a\u666f",children:"\u5e94\u7528\u573a\u666f"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"\u65b9\u6cd5"}),(0,s.jsx)(n.th,{children:"\u7279\u70b9"}),(0,s.jsx)(n.th,{children:"\u5e94\u7528"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"SimCLR"}),(0,s.jsx)(n.td,{children:"\u7b80\u5355\u6709\u6548"}),(0,s.jsx)(n.td,{children:"\u56fe\u50cf\u8868\u793a\u9884\u8bad\u7ec3"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"MoCo"}),(0,s.jsx)(n.td,{children:"\u5927\u89c4\u6a21\u8d1f\u6837\u672c"}),(0,s.jsx)(n.td,{children:"\u89c6\u89c9\u8868\u793a\u5b66\u4e60"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CLIP"}),(0,s.jsx)(n.td,{children:"\u56fe\u6587\u5bf9\u9f50"}),(0,s.jsx)(n.td,{children:"\u96f6\u6837\u672c\u5206\u7c7b\u3001\u56fe\u50cf\u68c0\u7d22"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"BERT"}),(0,s.jsx)(n.td,{children:"\u63a9\u7801\u8bed\u8a00\u6a21\u578b"}),(0,s.jsx)(n.td,{children:"NLP \u9884\u8bad\u7ec3"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03",children:"\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\npretrained_encoder = load_pretrained()\n\n# \u6dfb\u52a0\u5206\u7c7b\u5934\nclassifier = nn.Sequential(\n    pretrained_encoder,\n    nn.Linear(encoder_dim, num_classes)\n)\n\n# \u5fae\u8c03\nfor param in pretrained_encoder.parameters():\n    param.requires_grad = False  # \u51bb\u7ed3\u7f16\u7801\u5668\uff0c\u6216\u8bbe\u4e3a True \u8fdb\u884c\u5168\u91cf\u5fae\u8c03\n"})})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);