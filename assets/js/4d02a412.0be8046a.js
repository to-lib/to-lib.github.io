"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[75315],{48885:(n,e,t)=>{t.d(e,{R:()=>l,x:()=>i});var s=t(99378);const a={},r=s.createContext(a);function l(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:l(n.components),s.createElement(r.Provider,{value:e},n.children)}},64451:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>o,contentTitle:()=>i,default:()=>_,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"ai/continual-learning","title":"\ud83d\udcda \u6301\u7eed\u5b66\u4e60","description":"\u6301\u7eed\u5b66\u4e60\u662f\u8ba9\u6a21\u578b\u80fd\u591f\u4e0d\u65ad\u5b66\u4e60\u65b0\u77e5\u8bc6\uff0c\u540c\u65f6\u4fdd\u7559\u65e7\u77e5\u8bc6\u7684\u6280\u672f\uff0c\u89e3\u51b3\\"\u707e\u96be\u6027\u9057\u5fd8\\"\u95ee\u9898\u3002","source":"@site/docs/ai/continual-learning.md","sourceDirName":"ai","slug":"/ai/continual-learning","permalink":"/docs/ai/continual-learning","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ai/continual-learning.md","tags":[],"version":"current","sidebarPosition":40,"frontMatter":{"sidebar_position":40,"title":"\ud83d\udcda \u6301\u7eed\u5b66\u4e60"},"sidebar":"ai","previous":{"title":"\ud83c\udfaf RLHF \u4e0e DPO","permalink":"/docs/ai/rlhf"},"next":{"title":"\ud83d\udd12 \u8054\u90a6\u5b66\u4e60","permalink":"/docs/ai/federated-learning"}}');var a=t(22714),r=t(48885);const l={sidebar_position:40,title:"\ud83d\udcda \u6301\u7eed\u5b66\u4e60"},i="\u6301\u7eed\u5b66\u4e60\uff08Continual Learning\uff09",o={},d=[{value:"\u707e\u96be\u6027\u9057\u5fd8",id:"\u707e\u96be\u6027\u9057\u5fd8",level:2},{value:"\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5",id:"\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5",level:2},{value:"\u7ecf\u9a8c\u56de\u653e\uff08Replay\uff09",id:"\u7ecf\u9a8c\u56de\u653ereplay",level:2},{value:"EWC\uff08\u5f39\u6027\u6743\u91cd\u5de9\u56fa\uff09",id:"ewc\u5f39\u6027\u6743\u91cd\u5de9\u56fa",level:2},{value:"LoRA \u7d2f\u52a0",id:"lora-\u7d2f\u52a0",level:2},{value:"\u77e5\u8bc6\u84b8\u998f\u4fdd\u7559",id:"\u77e5\u8bc6\u84b8\u998f\u4fdd\u7559",level:2},{value:"LLM \u6301\u7eed\u9884\u8bad\u7ec3",id:"llm-\u6301\u7eed\u9884\u8bad\u7ec3",level:2},{value:"\u8bc4\u4f30\u9057\u5fd8\u7a0b\u5ea6",id:"\u8bc4\u4f30\u9057\u5fd8\u7a0b\u5ea6",level:2},{value:"\u65b9\u6cd5\u5bf9\u6bd4",id:"\u65b9\u6cd5\u5bf9\u6bd4",level:2},{value:"\u6700\u4f73\u5b9e\u8df5",id:"\u6700\u4f73\u5b9e\u8df5",level:2},{value:"\u5ef6\u4f38\u9605\u8bfb",id:"\u5ef6\u4f38\u9605\u8bfb",level:2}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"\u6301\u7eed\u5b66\u4e60continual-learning",children:"\u6301\u7eed\u5b66\u4e60\uff08Continual Learning\uff09"})}),"\n",(0,a.jsx)(e.p,{children:'\u6301\u7eed\u5b66\u4e60\u662f\u8ba9\u6a21\u578b\u80fd\u591f\u4e0d\u65ad\u5b66\u4e60\u65b0\u77e5\u8bc6\uff0c\u540c\u65f6\u4fdd\u7559\u65e7\u77e5\u8bc6\u7684\u6280\u672f\uff0c\u89e3\u51b3"\u707e\u96be\u6027\u9057\u5fd8"\u95ee\u9898\u3002'}),"\n",(0,a.jsx)(e.h2,{id:"\u707e\u96be\u6027\u9057\u5fd8",children:"\u707e\u96be\u6027\u9057\u5fd8"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"\u4f20\u7edf\u5fae\u8c03\uff1a\n\u4efb\u52a1A\u8bad\u7ec3 \u2500\u2500> \u6a21\u578b\u64c5\u957fA\n    \u2502\n    \u25bc\n\u4efb\u52a1B\u8bad\u7ec3 \u2500\u2500> \u6a21\u578b\u64c5\u957fB\uff0c\u4f46\u5fd8\u8bb0A \u274c\n\n\u6301\u7eed\u5b66\u4e60\uff1a\n\u4efb\u52a1A\u8bad\u7ec3 \u2500\u2500> \u6a21\u578b\u64c5\u957fA\n    \u2502\n    \u25bc\n\u4efb\u52a1B\u8bad\u7ec3 \u2500\u2500> \u6a21\u578b\u540c\u65f6\u64c5\u957fA\u548cB \u2713\n"})}),"\n",(0,a.jsx)(e.h2,{id:"\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5",children:"\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"\u65b9\u6cd5"}),(0,a.jsx)(e.th,{children:"\u539f\u7406"}),(0,a.jsx)(e.th,{children:"\u9002\u7528\u573a\u666f"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Replay"}),(0,a.jsx)(e.td,{children:"\u91cd\u653e\u65e7\u6570\u636e"}),(0,a.jsx)(e.td,{children:"\u6570\u636e\u53ef\u5b58\u50a8"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"EWC"}),(0,a.jsx)(e.td,{children:"\u4fdd\u62a4\u91cd\u8981\u53c2\u6570"}),(0,a.jsx)(e.td,{children:"\u53c2\u6570\u7ea7\u4fdd\u62a4"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"LoRA \u7d2f\u52a0"}),(0,a.jsx)(e.td,{children:"\u72ec\u7acb\u9002\u914d\u5668"}),(0,a.jsx)(e.td,{children:"LLM \u5fae\u8c03"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"\u77e5\u8bc6\u84b8\u998f"}),(0,a.jsx)(e.td,{children:"\u4fdd\u7559\u65e7\u6a21\u578b\u77e5\u8bc6"}),(0,a.jsx)(e.td,{children:"\u6a21\u578b\u66f4\u65b0"})]})]})]}),"\n",(0,a.jsx)(e.h2,{id:"\u7ecf\u9a8c\u56de\u653ereplay",children:"\u7ecf\u9a8c\u56de\u653e\uff08Replay\uff09"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import random\nfrom collections import deque\n\nclass ReplayBuffer:\n    """\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a"""\n    \n    def __init__(self, max_size: int = 10000):\n        self.buffer = deque(maxlen=max_size)\n    \n    def add(self, samples: list):\n        """\u6dfb\u52a0\u65b0\u6837\u672c"""\n        self.buffer.extend(samples)\n    \n    def sample(self, batch_size: int) -> list:\n        """\u968f\u673a\u91c7\u6837"""\n        return random.sample(list(self.buffer), min(batch_size, len(self.buffer)))\n\nclass ContinualTrainer:\n    """\u6301\u7eed\u5b66\u4e60\u8bad\u7ec3\u5668"""\n    \n    def __init__(self, model, replay_ratio: float = 0.3):\n        self.model = model\n        self.replay_buffer = ReplayBuffer()\n        self.replay_ratio = replay_ratio\n    \n    def train_task(self, new_data: list, epochs: int = 3):\n        """\u8bad\u7ec3\u65b0\u4efb\u52a1"""\n        for epoch in range(epochs):\n            # \u6df7\u5408\u65b0\u6570\u636e\u548c\u56de\u653e\u6570\u636e\n            replay_size = int(len(new_data) * self.replay_ratio)\n            replay_data = self.replay_buffer.sample(replay_size)\n            \n            combined_data = new_data + replay_data\n            random.shuffle(combined_data)\n            \n            # \u8bad\u7ec3\n            for batch in self._batch(combined_data):\n                self._train_step(batch)\n        \n        # \u5c06\u65b0\u6570\u636e\u52a0\u5165\u56de\u653e\u7f13\u51b2\u533a\n        self.replay_buffer.add(new_data)\n    \n    def _batch(self, data, batch_size=32):\n        for i in range(0, len(data), batch_size):\n            yield data[i:i + batch_size]\n    \n    def _train_step(self, batch):\n        # \u8bad\u7ec3\u903b\u8f91\n        pass\n'})}),"\n",(0,a.jsx)(e.h2,{id:"ewc\u5f39\u6027\u6743\u91cd\u5de9\u56fa",children:"EWC\uff08\u5f39\u6027\u6743\u91cd\u5de9\u56fa\uff09"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nfrom copy import deepcopy\n\nclass EWC:\n    """Elastic Weight Consolidation"""\n    \n    def __init__(self, model: nn.Module, lambda_ewc: float = 1000):\n        self.model = model\n        self.lambda_ewc = lambda_ewc\n        self.fisher = {}\n        self.optimal_params = {}\n    \n    def compute_fisher(self, dataloader):\n        """\u8ba1\u7b97 Fisher \u4fe1\u606f\u77e9\u9635"""\n        self.fisher = {n: torch.zeros_like(p) for n, p in self.model.named_parameters()}\n        \n        self.model.eval()\n        for batch in dataloader:\n            self.model.zero_grad()\n            output = self.model(batch["input_ids"])\n            loss = output.loss\n            loss.backward()\n            \n            for n, p in self.model.named_parameters():\n                if p.grad is not None:\n                    self.fisher[n] += p.grad.data ** 2\n        \n        # \u5f52\u4e00\u5316\n        for n in self.fisher:\n            self.fisher[n] /= len(dataloader)\n        \n        # \u4fdd\u5b58\u6700\u4f18\u53c2\u6570\n        self.optimal_params = {n: p.clone() for n, p in self.model.named_parameters()}\n    \n    def ewc_loss(self) -> torch.Tensor:\n        """\u8ba1\u7b97 EWC \u6b63\u5219\u5316\u635f\u5931"""\n        loss = 0\n        for n, p in self.model.named_parameters():\n            if n in self.fisher:\n                loss += (self.fisher[n] * (p - self.optimal_params[n]) ** 2).sum()\n        return self.lambda_ewc * loss\n\ndef train_with_ewc(model, ewc, dataloader, optimizer, epochs=3):\n    """\u5e26 EWC \u7684\u8bad\u7ec3"""\n    for epoch in range(epochs):\n        for batch in dataloader:\n            optimizer.zero_grad()\n            \n            # \u4efb\u52a1\u635f\u5931\n            output = model(batch["input_ids"], labels=batch["labels"])\n            task_loss = output.loss\n            \n            # EWC \u635f\u5931\n            ewc_loss = ewc.ewc_loss()\n            \n            # \u603b\u635f\u5931\n            total_loss = task_loss + ewc_loss\n            total_loss.backward()\n            optimizer.step()\n'})}),"\n",(0,a.jsx)(e.h2,{id:"lora-\u7d2f\u52a0",children:"LoRA \u7d2f\u52a0"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from peft import LoraConfig, get_peft_model, PeftModel\n\nclass LoRAContinualLearning:\n    """\u57fa\u4e8e LoRA \u7684\u6301\u7eed\u5b66\u4e60"""\n    \n    def __init__(self, base_model_path: str):\n        self.base_model_path = base_model_path\n        self.adapters = {}  # task_name -> adapter_path\n    \n    def train_task(self, task_name: str, train_data, output_dir: str):\n        """\u4e3a\u65b0\u4efb\u52a1\u8bad\u7ec3 LoRA \u9002\u914d\u5668"""\n        from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n        \n        # \u52a0\u8f7d\u57fa\u7840\u6a21\u578b\n        model = AutoModelForCausalLM.from_pretrained(self.base_model_path)\n        \n        # \u6dfb\u52a0 LoRA\n        lora_config = LoraConfig(\n            r=16,\n            lora_alpha=32,\n            target_modules=["q_proj", "v_proj"],\n            lora_dropout=0.05\n        )\n        model = get_peft_model(model, lora_config)\n        \n        # \u8bad\u7ec3\n        trainer = Trainer(\n            model=model,\n            train_dataset=train_data,\n            args=TrainingArguments(output_dir=output_dir, num_train_epochs=3)\n        )\n        trainer.train()\n        \n        # \u4fdd\u5b58\u9002\u914d\u5668\n        model.save_pretrained(output_dir)\n        self.adapters[task_name] = output_dir\n    \n    def load_for_task(self, task_name: str):\n        """\u52a0\u8f7d\u7279\u5b9a\u4efb\u52a1\u7684\u6a21\u578b"""\n        model = AutoModelForCausalLM.from_pretrained(self.base_model_path)\n        model = PeftModel.from_pretrained(model, self.adapters[task_name])\n        return model\n    \n    def merge_adapters(self, task_names: list, weights: list = None):\n        """\u5408\u5e76\u591a\u4e2a\u9002\u914d\u5668"""\n        if weights is None:\n            weights = [1.0 / len(task_names)] * len(task_names)\n        \n        model = AutoModelForCausalLM.from_pretrained(self.base_model_path)\n        \n        # \u52a0\u8f7d\u5e76\u52a0\u6743\u5408\u5e76\u9002\u914d\u5668\n        merged_state = None\n        for task_name, weight in zip(task_names, weights):\n            adapter = PeftModel.from_pretrained(model, self.adapters[task_name])\n            adapter_state = adapter.state_dict()\n            \n            if merged_state is None:\n                merged_state = {k: v * weight for k, v in adapter_state.items()}\n            else:\n                for k, v in adapter_state.items():\n                    merged_state[k] += v * weight\n        \n        model.load_state_dict(merged_state, strict=False)\n        return model\n'})}),"\n",(0,a.jsx)(e.h2,{id:"\u77e5\u8bc6\u84b8\u998f\u4fdd\u7559",children:"\u77e5\u8bc6\u84b8\u998f\u4fdd\u7559"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class DistillationContinualLearning:\n    """\u57fa\u4e8e\u84b8\u998f\u7684\u6301\u7eed\u5b66\u4e60"""\n    \n    def __init__(self, model, temperature: float = 2.0, alpha: float = 0.5):\n        self.current_model = model\n        self.old_model = None\n        self.temperature = temperature\n        self.alpha = alpha\n    \n    def before_task(self):\n        """\u4efb\u52a1\u5f00\u59cb\u524d\u4fdd\u5b58\u65e7\u6a21\u578b"""\n        self.old_model = deepcopy(self.current_model)\n        self.old_model.eval()\n        for p in self.old_model.parameters():\n            p.requires_grad = False\n    \n    def compute_loss(self, inputs, labels):\n        """\u8ba1\u7b97\u5e26\u84b8\u998f\u7684\u635f\u5931"""\n        # \u5f53\u524d\u6a21\u578b\u8f93\u51fa\n        current_outputs = self.current_model(inputs)\n        current_logits = current_outputs.logits\n        \n        # \u4efb\u52a1\u635f\u5931\n        task_loss = nn.CrossEntropyLoss()(\n            current_logits.view(-1, current_logits.size(-1)),\n            labels.view(-1)\n        )\n        \n        if self.old_model is None:\n            return task_loss\n        \n        # \u84b8\u998f\u635f\u5931\n        with torch.no_grad():\n            old_logits = self.old_model(inputs).logits\n        \n        distill_loss = nn.KLDivLoss(reduction="batchmean")(\n            nn.functional.log_softmax(current_logits / self.temperature, dim=-1),\n            nn.functional.softmax(old_logits / self.temperature, dim=-1)\n        ) * (self.temperature ** 2)\n        \n        return self.alpha * distill_loss + (1 - self.alpha) * task_loss\n'})}),"\n",(0,a.jsx)(e.h2,{id:"llm-\u6301\u7eed\u9884\u8bad\u7ec3",children:"LLM \u6301\u7eed\u9884\u8bad\u7ec3"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n\ndef continual_pretrain(\n    model_path: str,\n    new_corpus_path: str,\n    output_dir: str,\n    replay_corpus_path: str = None\n):\n    """LLM \u6301\u7eed\u9884\u8bad\u7ec3"""\n    model = AutoModelForCausalLM.from_pretrained(model_path)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    \n    # \u52a0\u8f7d\u65b0\u8bed\u6599\n    from datasets import load_dataset\n    new_data = load_dataset("text", data_files=new_corpus_path)\n    \n    # \u53ef\u9009\uff1a\u6df7\u5408\u65e7\u8bed\u6599\n    if replay_corpus_path:\n        old_data = load_dataset("text", data_files=replay_corpus_path)\n        # \u6df7\u5408\u6bd4\u4f8b 8:2\n        combined = concatenate_datasets([\n            new_data["train"].select(range(int(len(new_data["train"]) * 0.8))),\n            old_data["train"].select(range(int(len(old_data["train"]) * 0.2)))\n        ])\n    else:\n        combined = new_data["train"]\n    \n    # \u8bad\u7ec3\u914d\u7f6e\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        num_train_epochs=1,\n        per_device_train_batch_size=4,\n        learning_rate=1e-5,  # \u8f83\u5c0f\u7684\u5b66\u4e60\u7387\n        warmup_ratio=0.1,\n        save_strategy="epoch"\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=combined,\n        tokenizer=tokenizer\n    )\n    \n    trainer.train()\n'})}),"\n",(0,a.jsx)(e.h2,{id:"\u8bc4\u4f30\u9057\u5fd8\u7a0b\u5ea6",children:"\u8bc4\u4f30\u9057\u5fd8\u7a0b\u5ea6"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def evaluate_forgetting(model, task_datasets: dict) -> dict:\n    """\u8bc4\u4f30\u5404\u4efb\u52a1\u7684\u9057\u5fd8\u7a0b\u5ea6"""\n    results = {}\n    \n    for task_name, dataset in task_datasets.items():\n        # \u8bc4\u4f30\u5f53\u524d\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\n        score = evaluate_task(model, dataset)\n        results[task_name] = score\n    \n    return results\n\ndef compute_forgetting_rate(\n    scores_before: dict,\n    scores_after: dict\n) -> dict:\n    """\u8ba1\u7b97\u9057\u5fd8\u7387"""\n    forgetting = {}\n    \n    for task in scores_before:\n        if task in scores_after:\n            forgetting[task] = (scores_before[task] - scores_after[task]) / scores_before[task]\n    \n    return forgetting\n'})}),"\n",(0,a.jsx)(e.h2,{id:"\u65b9\u6cd5\u5bf9\u6bd4",children:"\u65b9\u6cd5\u5bf9\u6bd4"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"\u65b9\u6cd5"}),(0,a.jsx)(e.th,{children:"\u4f18\u70b9"}),(0,a.jsx)(e.th,{children:"\u7f3a\u70b9"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Replay"}),(0,a.jsx)(e.td,{children:"\u7b80\u5355\u6709\u6548"}),(0,a.jsx)(e.td,{children:"\u9700\u8981\u5b58\u50a8\u6570\u636e"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"EWC"}),(0,a.jsx)(e.td,{children:"\u4e0d\u9700\u8981\u65e7\u6570\u636e"}),(0,a.jsx)(e.td,{children:"\u8ba1\u7b97 Fisher \u5f00\u9500\u5927"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"LoRA \u7d2f\u52a0"}),(0,a.jsx)(e.td,{children:"\u7075\u6d3b\u3001\u53ef\u7ec4\u5408"}),(0,a.jsx)(e.td,{children:"\u591a\u4e2a\u9002\u914d\u5668\u7ba1\u7406\u590d\u6742"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"\u84b8\u998f"}),(0,a.jsx)(e.td,{children:"\u6548\u679c\u597d"}),(0,a.jsx)(e.td,{children:"\u9700\u8981\u4fdd\u5b58\u65e7\u6a21\u578b"})]})]})]}),"\n",(0,a.jsx)(e.h2,{id:"\u6700\u4f73\u5b9e\u8df5",children:"\u6700\u4f73\u5b9e\u8df5"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\u6df7\u5408\u4f7f\u7528"}),"\uff1aReplay + \u6b63\u5219\u5316\u6548\u679c\u66f4\u597d"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\u63a7\u5236\u5b66\u4e60\u7387"}),"\uff1a\u6301\u7eed\u5b66\u4e60\u7528\u8f83\u5c0f\u7684\u5b66\u4e60\u7387"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\u5b9a\u671f\u8bc4\u4f30"}),"\uff1a\u76d1\u63a7\u65e7\u4efb\u52a1\u7684\u6027\u80fd"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\u6570\u636e\u5e73\u8861"}),"\uff1a\u65b0\u65e7\u6570\u636e\u6bd4\u4f8b\u8981\u5408\u7406"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\u9009\u62e9\u6027\u66f4\u65b0"}),"\uff1a\u53ea\u66f4\u65b0\u90e8\u5206\u53c2\u6570\uff08\u5982 LoRA\uff09"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"\u5ef6\u4f38\u9605\u8bfb",children:"\u5ef6\u4f38\u9605\u8bfb"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://arxiv.org/abs/1612.00796",children:"EWC Paper"})}),"\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://arxiv.org/abs/2302.00487",children:"Continual Learning Survey"})}),"\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://arxiv.org/abs/2308.04014",children:"LLM Continual Learning"})}),"\n"]})]})}function _(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(c,{...n})}):c(n)}}}]);