"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[39576],{48885:(n,e,i)=>{i.d(e,{R:()=>l,x:()=>o});var r=i(99378);const t={},a=r.createContext(t);function l(n){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:l(n.components),r.createElement(a.Provider,{value:e},n.children)}},64346:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"ai/lora-fine-tuning","title":"\ud83d\ude80 LoRA Fine-tuning\uff08\u5b9e\u6218\uff09","description":"LoRA (Low-Rank Adaptation) \u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u51bb\u7ed3\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\uff0c\u4ec5\u5728\u6bcf\u4e00\u5c42\u6ce8\u5165\u53ef\u8bad\u7ec3\u7684\u4f4e\u79e9\u77e9\u9635\uff0c\u4ece\u800c\u5728\u663e\u8457\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6548\u679c\u3002","source":"@site/docs/ai/lora-fine-tuning.md","sourceDirName":"ai","slug":"/ai/lora-fine-tuning","permalink":"/docs/ai/lora-fine-tuning","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ai/lora-fine-tuning.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"title":"\ud83d\ude80 LoRA Fine-tuning\uff08\u5b9e\u6218\uff09"},"sidebar":"ai","previous":{"title":"\ud83e\uddea Fine-tuning\uff08\u5fae\u8c03\uff09","permalink":"/docs/ai/fine-tuning"},"next":{"title":"\ud83d\udccf Evaluation\uff08\u8bc4\u4f30\u4e0e\u6d4b\u8bd5\uff09","permalink":"/docs/ai/evaluation"}}');var t=i(22714),a=i(48885);const l={sidebar_position:10,title:"\ud83d\ude80 LoRA Fine-tuning\uff08\u5b9e\u6218\uff09"},o="LoRA Fine-tuning\uff08\u5b9e\u6218\uff09",s={},d=[{value:"\u4e3a\u4ec0\u4e48\u9009\u62e9 LoRA\uff1f",id:"\u4e3a\u4ec0\u4e48\u9009\u62e9-lora",level:2},{value:"\u73af\u5883\u51c6\u5907",id:"\u73af\u5883\u51c6\u5907",level:2},{value:"\u5b9e\u6218\u6b65\u9aa4",id:"\u5b9e\u6218\u6b65\u9aa4",level:2},{value:"1. \u52a0\u8f7d\u57fa\u5ea7\u6a21\u578b\uff084-bit \u91cf\u5316\uff09",id:"1-\u52a0\u8f7d\u57fa\u5ea7\u6a21\u578b4-bit-\u91cf\u5316",level:3},{value:"2. \u914d\u7f6e LoRA",id:"2-\u914d\u7f6e-lora",level:3},{value:"3. \u51c6\u5907\u6570\u636e",id:"3-\u51c6\u5907\u6570\u636e",level:3},{value:"4. \u5f00\u59cb\u8bad\u7ec3",id:"4-\u5f00\u59cb\u8bad\u7ec3",level:3},{value:"5. \u4fdd\u5b58\u4e0e\u5408\u5e76",id:"5-\u4fdd\u5b58\u4e0e\u5408\u5e76",level:3},{value:"\u63a8\u7406\u65f6\u52a0\u8f7d",id:"\u63a8\u7406\u65f6\u52a0\u8f7d",level:4},{value:"\u5408\u5e76\u6743\u91cd (\u53ef\u9009)",id:"\u5408\u5e76\u6743\u91cd-\u53ef\u9009",level:4},{value:"\u5e38\u89c1\u95ee\u9898",id:"\u5e38\u89c1\u95ee\u9898",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"lora-fine-tuning\u5b9e\u6218",children:"LoRA Fine-tuning\uff08\u5b9e\u6218\uff09"})}),"\n",(0,t.jsx)(e.p,{children:"LoRA (Low-Rank Adaptation) \u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u51bb\u7ed3\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\uff0c\u4ec5\u5728\u6bcf\u4e00\u5c42\u6ce8\u5165\u53ef\u8bad\u7ec3\u7684\u4f4e\u79e9\u77e9\u9635\uff0c\u4ece\u800c\u5728\u663e\u8457\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6548\u679c\u3002"}),"\n",(0,t.jsx)(e.h2,{id:"\u4e3a\u4ec0\u4e48\u9009\u62e9-lora",children:"\u4e3a\u4ec0\u4e48\u9009\u62e9 LoRA\uff1f"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u6548\u7387\u9ad8"}),"\uff1a\u8bad\u7ec3\u53c2\u6570\u91cf\u901a\u5e38\u4ec5\u4e3a\u539f\u6a21\u578b\u7684 1% - 10%\u3002"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u786c\u4ef6\u95e8\u69db\u4f4e"}),"\uff1a\u663e\u5b58\u5360\u7528\u5927\u5e45\u964d\u4f4e\uff0c\u5355\u5361 3090/4090 \u5373\u53ef\u5fae\u8c03 7B/13B \u6a21\u578b\u3002"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u65e0\u5ef6\u8fdf"}),"\uff1a\u63a8\u7406\u65f6\u53ef\u4ee5\u5c06 Adapter \u6743\u91cd\u5408\u5e76\u56de\u57fa\u5ea7\u6a21\u578b\uff0c\u4e0d\u589e\u52a0\u63a8\u7406\u5ef6\u65f6\u3002"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u7075\u6d3b\u5207\u6362"}),"\uff1a\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u8bad\u7ec3\u5373\u4f7f\u4e0d\u540c\u7684 Adapter\uff0c\u5207\u6362\u65f6\u53ea\u9700\u70ed\u63d2\u62d4 Adapter \u6743\u91cd\u3002"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"\u73af\u5883\u51c6\u5907",children:"\u73af\u5883\u51c6\u5907"}),"\n",(0,t.jsx)(e.p,{children:"\u6211\u4eec\u9700\u8981\u5b89\u88c5 HuggingFace \u751f\u6001\u7684\u6838\u5fc3\u5e93\uff1a"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"pip install transformers peft bitsandbytes datasets accelerate\n"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"transformers"}),": \u52a0\u8f7d\u6a21\u578b\u4e0e Tokenizer"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"peft"}),": LoRA \u7b49\u5fae\u8c03\u5e93 (Parameter-Efficient Fine-Tuning)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"bitsandbytes"}),": 4-bit/8-bit \u91cf\u5316\u652f\u6301"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"datasets"}),": \u6570\u636e\u52a0\u8f7d"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"accelerate"}),": \u5206\u5e03\u5f0f\u8bad\u7ec3\u4e0e\u786c\u4ef6\u52a0\u901f"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"\u5b9e\u6218\u6b65\u9aa4",children:"\u5b9e\u6218\u6b65\u9aa4"}),"\n",(0,t.jsx)(e.h3,{id:"1-\u52a0\u8f7d\u57fa\u5ea7\u6a21\u578b4-bit-\u91cf\u5316",children:"1. \u52a0\u8f7d\u57fa\u5ea7\u6a21\u578b\uff084-bit \u91cf\u5316\uff09"}),"\n",(0,t.jsx)(e.p,{children:"\u4e3a\u4e86\u8282\u7701\u663e\u5b58\uff0c\u6211\u4eec\u901a\u5e38\u4f7f\u7528 QLoRA\uff084-bit \u91cf\u5316 + LoRA\uff09\u3002"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nmodel_id = "meta-llama/Llama-2-7b-chat-hf"  # \u6216\u5176\u4ed6\u6a21\u578b\n\n# 4-bit \u91cf\u5316\u914d\u7f6e\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type="nf4",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False,\n)\n\n# \u52a0\u8f7d\u6a21\u578b\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    device_map="auto"\n)\n\n# \u52a0\u8f7d Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token # Llama \u7cfb\u5217\u901a\u5e38\u9700\u8981\u8bbe\u7f6e pad_token\n'})}),"\n",(0,t.jsx)(e.h3,{id:"2-\u914d\u7f6e-lora",children:"2. \u914d\u7f6e LoRA"}),"\n",(0,t.jsxs)(e.p,{children:["\u4f7f\u7528 ",(0,t.jsx)(e.code,{children:"peft"})," \u5e93\u5b9a\u4e49 LoRA \u914d\u7f6e\u3002"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from peft import LoraConfig, get_peft_model, TaskType\n\nlora_config = LoraConfig(\n    r=16,                    # \u4f4e\u79e9\u77e9\u9635\u7684\u79e9\uff0c\u8d8a\u5927\u53c2\u6570\u8d8a\u591a\u4f46\u5e76\u975e\u8d8a\u597d\n    lora_alpha=32,           # \u7f29\u653e\u7cfb\u6570\uff0c\u901a\u5e38\u662f r \u7684 2 \u500d\n    target_modules=["q_proj", "v_proj"], # \u6307\u5b9a\u9700\u8981\u5fae\u8c03\u7684\u5c42\uff08\u901a\u5e38\u662f attention \u76f8\u5173\u7684\u5c42\uff09\n    lora_dropout=0.05,\n    bias="none",\n    task_type=TaskType.CAUSAL_LM\n)\n\n# \u5e94\u7528 LoRA \u914d\u7f6e\u5230\u6a21\u578b\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n# \u8f93\u51fa\u793a\u4f8b: trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.062\n'})}),"\n",(0,t.jsx)(e.h3,{id:"3-\u51c6\u5907\u6570\u636e",children:"3. \u51c6\u5907\u6570\u636e"}),"\n",(0,t.jsxs)(e.p,{children:["\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a JSONL \u6587\u4ef6 ",(0,t.jsx)(e.code,{children:"train.jsonl"}),"\uff0c\u683c\u5f0f\u5982\u4e0b\uff1a"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-json",children:'{ "text": "Human: \u600e\u4e48\u505a\u897f\u7ea2\u67ff\u7092\u86cb\uff1f\\nAssistant: \u9996\u5148\u51c6\u5907\u897f\u7ea2\u67ff\u548c\u9e21\u86cb..." }\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from datasets import load_dataset\n\ndataset = load_dataset("json", data_files="train.jsonl", split="train")\n\ndef format_prompt(sample):\n    return {"text": sample["text"]} # \u786e\u4fdd\u5b57\u6bb5\u540d\u7b26\u5408\u6a21\u578b\u8f93\u5165\u8981\u6c42\n\ndataset = dataset.map(format_prompt)\n'})}),"\n",(0,t.jsx)(e.h3,{id:"4-\u5f00\u59cb\u8bad\u7ec3",children:"4. \u5f00\u59cb\u8bad\u7ec3"}),"\n",(0,t.jsxs)(e.p,{children:["\u4f7f\u7528 ",(0,t.jsx)(e.code,{children:"SFTTrainer"})," (\u6765\u81ea ",(0,t.jsx)(e.code,{children:"trl"})," \u5e93) \u6216\u6807\u51c6\u7684 ",(0,t.jsx)(e.code,{children:"Trainer"}),"\u3002\u8fd9\u91cc\u6f14\u793a\u6807\u51c6 ",(0,t.jsx)(e.code,{children:"Trainer"}),"\u3002"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from transformers import TrainingArguments, Trainer\nfrom transformers import DataCollatorForLanguageModeling\n\n# \u6570\u636e\u6536\u96c6\u5668\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n# \u8bad\u7ec3\u53c2\u6570\ntraining_args = TrainingArguments(\n    output_dir="./lora_model",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    logging_steps=10,\n    max_steps=500,               # \u5feb\u901f\u6f14\u793a\uff0c\u5b9e\u9645\u8bad\u7ec3\u53ef\u4ee5\u7528 num_train_epochs\n    fp16=True,                   # \u5f00\u542f\u6df7\u5408\u7cbe\u5ea6\n    optim="paged_adamw_32bit",   # \u8282\u7701\u663e\u5b58\u7684\u4f18\u5316\u5668\n    save_strategy="steps",\n    save_steps=100,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset,\n    data_collator=data_collator,\n)\n\ntrainer.train()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"5-\u4fdd\u5b58\u4e0e\u5408\u5e76",children:"5. \u4fdd\u5b58\u4e0e\u5408\u5e76"}),"\n",(0,t.jsx)(e.p,{children:"\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u4fdd\u5b58 Adapter \u6743\u91cd\u3002"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'trainer.save_model("my_lora_adapter")\n'})}),"\n",(0,t.jsx)(e.h4,{id:"\u63a8\u7406\u65f6\u52a0\u8f7d",children:"\u63a8\u7406\u65f6\u52a0\u8f7d"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from peft import PeftModel\n\n# 1. \u91cd\u65b0\u52a0\u8f7d\u57fa\u5ea7\u6a21\u578b\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    device_map="auto"\n)\n\n# 2. \u52a0\u8f7d Adapter\nmodel = PeftModel.from_pretrained(base_model, "my_lora_adapter")\n\n# 3. \u63a8\u7406\ninputs = tokenizer("Human: \u4f60\u597d\\nAssistant:", return_tensors="pt").to("cuda")\noutputs = model.generate(**inputs, max_new_tokens=50)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n'})}),"\n",(0,t.jsx)(e.h4,{id:"\u5408\u5e76\u6743\u91cd-\u53ef\u9009",children:"\u5408\u5e76\u6743\u91cd (\u53ef\u9009)"}),"\n",(0,t.jsx)(e.p,{children:"\u5982\u679c\u4f60\u60f3\u5bfc\u51fa\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\u6587\u4ef6\u7528\u4e8e\u90e8\u7f72\uff08\u4e0d\u518d\u4f9d\u8d56 peft\uff09\uff1a"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# \u6ce8\u610f\uff1a\u5408\u5e76\u65f6\u4e0d\u80fd\u4f7f\u7528 4-bit/8-bit \u91cf\u5316\u52a0\u8f7d\u57fa\u5ea7\u6a21\u578b\uff0c\u5fc5\u987b\u7528 fp16/fp32\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    device_map="auto"\n)\nmodel = PeftModel.from_pretrained(base_model, "my_lora_adapter")\n\n# \u5408\u5e76\u5e76\u5378\u8f7d\nmodel = model.merge_and_unload()\n\n# \u4fdd\u5b58\u5b8c\u6574\u6a21\u578b\nmodel.save_pretrained("merged_model")\ntokenizer.save_pretrained("merged_model")\n'})}),"\n",(0,t.jsx)(e.h2,{id:"\u5e38\u89c1\u95ee\u9898",children:"\u5e38\u89c1\u95ee\u9898"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"OOM (\u663e\u5b58\u4e0d\u8db3)"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\u51cf\u5c0f ",(0,t.jsx)(e.code,{children:"batch_size"}),"\u3002"]}),"\n",(0,t.jsxs)(e.li,{children:["\u589e\u52a0 ",(0,t.jsx)(e.code,{children:"gradient_accumulation_steps"})," \u7528\u4e8e\u5f25\u8865 batch size \u7684\u51cf\u5c0f\u3002"]}),"\n",(0,t.jsxs)(e.li,{children:["\u786e\u4fdd\u5f00\u542f\u4e86 4-bit \u91cf\u5316\u548c ",(0,t.jsx)(e.code,{children:"paged_adamw_32bit"}),"\u3002"]}),"\n",(0,t.jsxs)(e.li,{children:["\u542f\u7528 ",(0,t.jsx)(e.code,{children:"gradient_checkpointing"})," (\u5728 TrainingArguments \u4e2d\u8bbe\u7f6e)\u3002"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Loss \u4e0d\u4e0b\u964d"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u68c0\u67e5\u6570\u636e\u8d28\u91cf\u548c\u683c\u5f0f\u3002"}),"\n",(0,t.jsxs)(e.li,{children:["\u5c1d\u8bd5\u8c03\u6574 ",(0,t.jsx)(e.code,{children:"learning_rate"})," (LoRA \u901a\u5e38\u6bd4\u5168\u91cf\u5fae\u8c03\u5927\uff0c\u5982 2e-4)\u3002"]}),"\n",(0,t.jsxs)(e.li,{children:["\u68c0\u67e5 ",(0,t.jsx)(e.code,{children:"target_modules"})," \u662f\u5426\u8986\u76d6\u4e86\u5173\u952e\u5c42\u3002"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u707e\u96be\u6027\u9057\u5fd8"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["LoRA \u76f8\u5bf9\u4e0d\u5bb9\u6613\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4f46\u5982\u679c\u53d1\u73b0\u57fa\u5ea7\u901a\u7528\u80fd\u529b\u4e0b\u964d\u4e25\u91cd\uff0c\u53ef\u4ee5\u51cf\u5c0f ",(0,t.jsx)(e.code,{children:"r"})," \u6216\u51cf\u5c11\u8bad\u7ec3\u6b65\u6570\u3002"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(c,{...n})}):c(n)}}}]);