"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[45572],{48885:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>l});var s=t(99378);const r={},a=s.createContext(r);function i(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(a.Provider,{value:n},e.children)}},54653:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ai/evaluation","title":"\ud83d\udccf Evaluation\uff08\u8bc4\u4f30\u4e0e\u6d4b\u8bd5\uff09","description":"LLM \u5e94\u7528\u7684\u96be\u70b9\u4e4b\u4e00\u662f\\"\u770b\u8d77\u6765\u80fd\u7528\\"\uff0c\u4f46\u7ebf\u4e0a\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002\u4e00\u4e2a\u53ef\u6301\u7eed\u8fed\u4ee3\u7684 AI \u7cfb\u7edf\uff0c\u9700\u8981\u628a\u8bc4\u4f30\u5f53\u6210\u5de5\u7a0b\u80fd\u529b\uff1a\u53ef\u590d\u73b0\u3001\u53ef\u5bf9\u6bd4\u3001\u53ef\u56de\u5f52\u3002","source":"@site/docs/ai/evaluation.md","sourceDirName":"ai","slug":"/ai/evaluation","permalink":"/docs/ai/evaluation","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ai/evaluation.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"title":"\ud83d\udccf Evaluation\uff08\u8bc4\u4f30\u4e0e\u6d4b\u8bd5\uff09"},"sidebar":"ai","previous":{"title":"\ud83d\udd12 \u8054\u90a6\u5b66\u4e60","permalink":"/docs/ai/federated-learning"},"next":{"title":"\ud83d\ude80 Production\uff08\u751f\u4ea7\u5316\u4e0e\u90e8\u7f72\uff09","permalink":"/docs/ai/production"}}');var r=t(22714),a=t(48885);const i={sidebar_position:10,title:"\ud83d\udccf Evaluation\uff08\u8bc4\u4f30\u4e0e\u6d4b\u8bd5\uff09"},l="Evaluation\uff08\u8bc4\u4f30\u4e0e\u6d4b\u8bd5\uff09",o={},c=[{value:"\u8bc4\u4f30\u76ee\u6807",id:"\u8bc4\u4f30\u76ee\u6807",level:2},{value:"\u8bc4\u4f30\u4f53\u7cfb\u67b6\u6784",id:"\u8bc4\u4f30\u4f53\u7cfb\u67b6\u6784",level:2},{value:"\u79bb\u7ebf\u8bc4\u4f30\uff08Offline Eval\uff09",id:"\u79bb\u7ebf\u8bc4\u4f30offline-eval",level:2},{value:"1. \u6784\u5efa\u9ec4\u91d1\u6570\u636e\u96c6\uff08Golden Set\uff09",id:"1-\u6784\u5efa\u9ec4\u91d1\u6570\u636e\u96c6golden-set",level:3},{value:"2. \u81ea\u52a8\u5316\u8bc4\u5206",id:"2-\u81ea\u52a8\u5316\u8bc4\u5206",level:3},{value:"\u89c4\u5219/\u65ad\u8a00\u8bc4\u5206",id:"\u89c4\u5219\u65ad\u8a00\u8bc4\u5206",level:4},{value:"\u6307\u6807\u8ba1\u7b97",id:"\u6307\u6807\u8ba1\u7b97",level:4},{value:"3. LLM-as-Judge",id:"3-llm-as-judge",level:3},{value:"4. RAG \u4e13\u9879\u8bc4\u4f30",id:"4-rag-\u4e13\u9879\u8bc4\u4f30",level:3},{value:"\u5728\u7ebf\u8bc4\u4f30\uff08Online Eval\uff09",id:"\u5728\u7ebf\u8bc4\u4f30online-eval",level:2},{value:"A/B \u6d4b\u8bd5\u6846\u67b6",id:"ab-\u6d4b\u8bd5\u6846\u67b6",level:3},{value:"\u4e1a\u52a1\u6307\u6807\u76d1\u63a7",id:"\u4e1a\u52a1\u6307\u6807\u76d1\u63a7",level:3},{value:"\u8bc4\u4f30\u5de5\u5177\u63a8\u8350",id:"\u8bc4\u4f30\u5de5\u5177\u63a8\u8350",level:2},{value:"LangSmith",id:"langsmith",level:3},{value:"DeepEval",id:"deepeval",level:3},{value:"RAGAS",id:"ragas",level:3},{value:"\u6700\u5c0f\u53ef\u884c\u8bc4\u4f30\u4f53\u7cfb\uff08MVP\uff09",id:"\u6700\u5c0f\u53ef\u884c\u8bc4\u4f30\u4f53\u7cfbmvp",level:2},{value:"\u7b2c\u4e00\u9636\u6bb5\uff1a\u57fa\u7840\u8bc4\u4f30",id:"\u7b2c\u4e00\u9636\u6bb5\u57fa\u7840\u8bc4\u4f30",level:3},{value:"\u7b2c\u4e8c\u9636\u6bb5\uff1a\u81ea\u52a8\u5316\u8bc4\u4f30",id:"\u7b2c\u4e8c\u9636\u6bb5\u81ea\u52a8\u5316\u8bc4\u4f30",level:3},{value:"\u7b2c\u4e09\u9636\u6bb5\uff1a\u5728\u7ebf\u8bc4\u4f30",id:"\u7b2c\u4e09\u9636\u6bb5\u5728\u7ebf\u8bc4\u4f30",level:3},{value:"\u5ef6\u4f38\u9605\u8bfb",id:"\u5ef6\u4f38\u9605\u8bfb",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"evaluation\u8bc4\u4f30\u4e0e\u6d4b\u8bd5",children:"Evaluation\uff08\u8bc4\u4f30\u4e0e\u6d4b\u8bd5\uff09"})}),"\n",(0,r.jsx)(n.p,{children:'LLM \u5e94\u7528\u7684\u96be\u70b9\u4e4b\u4e00\u662f"\u770b\u8d77\u6765\u80fd\u7528"\uff0c\u4f46\u7ebf\u4e0a\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002\u4e00\u4e2a\u53ef\u6301\u7eed\u8fed\u4ee3\u7684 AI \u7cfb\u7edf\uff0c\u9700\u8981\u628a\u8bc4\u4f30\u5f53\u6210\u5de5\u7a0b\u80fd\u529b\uff1a\u53ef\u590d\u73b0\u3001\u53ef\u5bf9\u6bd4\u3001\u53ef\u56de\u5f52\u3002'}),"\n",(0,r.jsx)(n.h2,{id:"\u8bc4\u4f30\u76ee\u6807",children:"\u8bc4\u4f30\u76ee\u6807"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"\u7ef4\u5ea6"}),(0,r.jsx)(n.th,{children:"\u8bf4\u660e"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\u6b63\u786e\u6027"})}),(0,r.jsx)(n.td,{children:"\u7b54\u6848\u662f\u5426\u7b26\u5408\u4e8b\u5b9e/\u4e1a\u52a1\u89c4\u5219"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\u76f8\u5173\u6027"})}),(0,r.jsx)(n.td,{children:"\u56de\u7b54\u662f\u5426\u5207\u4e2d\u7528\u6237\u95ee\u9898"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\u5b8c\u6574\u6027"})}),(0,r.jsx)(n.td,{children:"\u5173\u952e\u70b9\u662f\u5426\u9057\u6f0f"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\u5b89\u5168\u6027"})}),(0,r.jsx)(n.td,{children:"\u662f\u5426\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u3001\u662f\u5426\u9075\u5b88\u7b56\u7565"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\u683c\u5f0f/\u7ed3\u6784"})}),(0,r.jsx)(n.td,{children:"JSON/\u8868\u683c/\u5b57\u6bb5\u662f\u5426\u7b26\u5408\u7ea6\u675f"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"\u6210\u672c\u4e0e\u5ef6\u8fdf"})}),(0,r.jsx)(n.td,{children:"\u662f\u5426\u6ee1\u8db3 SLA"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"\u8bc4\u4f30\u4f53\u7cfb\u67b6\u6784",children:"\u8bc4\u4f30\u4f53\u7cfb\u67b6\u6784"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    \u8bc4\u4f30\u4f53\u7cfb                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u79bb\u7ebf\u8bc4\u4f30 (Offline)          \u2502  \u5728\u7ebf\u8bc4\u4f30 (Online)        \u2502\n\u2502  \u251c\u2500 \u9ec4\u91d1\u6570\u636e\u96c6               \u2502  \u251c\u2500 A/B \u6d4b\u8bd5              \u2502\n\u2502  \u251c\u2500 \u81ea\u52a8\u5316\u8bc4\u5206               \u2502  \u251c\u2500 \u4e1a\u52a1\u6307\u6807\u76d1\u63a7          \u2502\n\u2502  \u251c\u2500 LLM-as-Judge            \u2502  \u251c\u2500 \u7528\u6237\u53cd\u9988\u6536\u96c6          \u2502\n\u2502  \u2514\u2500 \u4eba\u5de5\u62bd\u68c0                 \u2502  \u2514\u2500 \u5f02\u5e38\u68c0\u6d4b              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h2,{id:"\u79bb\u7ebf\u8bc4\u4f30offline-eval",children:"\u79bb\u7ebf\u8bc4\u4f30\uff08Offline Eval\uff09"}),"\n",(0,r.jsx)(n.h3,{id:"1-\u6784\u5efa\u9ec4\u91d1\u6570\u636e\u96c6golden-set",children:"1. \u6784\u5efa\u9ec4\u91d1\u6570\u636e\u96c6\uff08Golden Set\uff09"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from dataclasses import dataclass\nfrom typing import Optional\nimport json\n\n@dataclass\nclass EvalSample:\n    """\u8bc4\u4f30\u6837\u672c"""\n    id: str\n    input: str\n    expected_output: str\n    context: Optional[str] = None  # RAG \u573a\u666f\u7684\u68c0\u7d22\u7ed3\u679c\n    category: str = "general"\n    difficulty: str = "medium"\n    \n    def to_dict(self):\n        return {\n            "id": self.id,\n            "input": self.input,\n            "expected_output": self.expected_output,\n            "context": self.context,\n            "category": self.category,\n            "difficulty": self.difficulty\n        }\n\n# \u521b\u5efa\u8bc4\u4f30\u6570\u636e\u96c6\neval_dataset = [\n    EvalSample(\n        id="001",\n        input="\u4ec0\u4e48\u662f RAG\uff1f",\n        expected_output="RAG (Retrieval-Augmented Generation) \u662f\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u548c\u751f\u6210\u7684 AI \u6280\u672f...",\n        category="concept",\n        difficulty="easy"\n    ),\n    EvalSample(\n        id="002",\n        input="\u5982\u4f55\u4f18\u5316 LLM \u7684\u54cd\u5e94\u5ef6\u8fdf\uff1f",\n        expected_output="\u4f18\u5316 LLM \u54cd\u5e94\u5ef6\u8fdf\u7684\u65b9\u6cd5\u5305\u62ec\uff1a1. \u4f7f\u7528\u66f4\u5c0f\u7684\u6a21\u578b...",\n        category="optimization",\n        difficulty="hard"\n    )\n]\n\n# \u4fdd\u5b58\u4e3a JSONL\ndef save_eval_dataset(samples: list[EvalSample], path: str):\n    with open(path, \'w\', encoding=\'utf-8\') as f:\n        for sample in samples:\n            f.write(json.dumps(sample.to_dict(), ensure_ascii=False) + \'\\n\')\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-\u81ea\u52a8\u5316\u8bc4\u5206",children:"2. \u81ea\u52a8\u5316\u8bc4\u5206"}),"\n",(0,r.jsx)(n.h4,{id:"\u89c4\u5219\u65ad\u8a00\u8bc4\u5206",children:"\u89c4\u5219/\u65ad\u8a00\u8bc4\u5206"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import json\nimport re\n\nclass RuleBasedEvaluator:\n    """\u57fa\u4e8e\u89c4\u5219\u7684\u8bc4\u4f30\u5668"""\n    \n    @staticmethod\n    def check_json_valid(output: str) -> bool:\n        """\u68c0\u67e5 JSON \u683c\u5f0f\u662f\u5426\u6709\u6548"""\n        try:\n            json.loads(output)\n            return True\n        except json.JSONDecodeError:\n            return False\n    \n    @staticmethod\n    def check_contains_keywords(output: str, keywords: list[str]) -> float:\n        """\u68c0\u67e5\u662f\u5426\u5305\u542b\u5173\u952e\u8bcd"""\n        found = sum(1 for kw in keywords if kw.lower() in output.lower())\n        return found / len(keywords) if keywords else 0\n    \n    @staticmethod\n    def check_length(output: str, min_len: int = 10, max_len: int = 1000) -> bool:\n        """\u68c0\u67e5\u957f\u5ea6\u662f\u5426\u5728\u8303\u56f4\u5185"""\n        return min_len <= len(output) <= max_len\n    \n    @staticmethod\n    def check_no_sensitive_info(output: str) -> bool:\n        """\u68c0\u67e5\u662f\u5426\u5305\u542b\u654f\u611f\u4fe1\u606f"""\n        patterns = [\n            r\'\\b\\d{11}\\b\',  # \u624b\u673a\u53f7\n            r\'\\b\\d{18}\\b\',  # \u8eab\u4efd\u8bc1\u53f7\n            r\'sk-[a-zA-Z0-9]+\',  # API Key\n        ]\n        for pattern in patterns:\n            if re.search(pattern, output):\n                return False\n        return True\n\n# \u4f7f\u7528\u793a\u4f8b\nevaluator = RuleBasedEvaluator()\noutput = \'{"result": "success", "data": [1, 2, 3]}\'\n\nresults = {\n    "json_valid": evaluator.check_json_valid(output),\n    "length_ok": evaluator.check_length(output),\n    "no_sensitive": evaluator.check_no_sensitive_info(output)\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"\u6307\u6807\u8ba1\u7b97",children:"\u6307\u6807\u8ba1\u7b97"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from collections import Counter\nimport numpy as np\n\ndef calculate_accuracy(predictions: list[str], labels: list[str]) -> float:\n    """\u8ba1\u7b97\u51c6\u786e\u7387"""\n    correct = sum(1 for p, l in zip(predictions, labels) if p.strip() == l.strip())\n    return correct / len(predictions)\n\ndef calculate_f1(predictions: list[str], labels: list[str], positive_label: str) -> dict:\n    """\u8ba1\u7b97 F1 \u5206\u6570"""\n    tp = sum(1 for p, l in zip(predictions, labels) if p == positive_label and l == positive_label)\n    fp = sum(1 for p, l in zip(predictions, labels) if p == positive_label and l != positive_label)\n    fn = sum(1 for p, l in zip(predictions, labels) if p != positive_label and l == positive_label)\n    \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n    \n    return {"precision": precision, "recall": recall, "f1": f1}\n\ndef calculate_retrieval_metrics(retrieved_ids: list[list[str]], relevant_ids: list[list[str]], k: int = 5) -> dict:\n    """\u8ba1\u7b97\u68c0\u7d22\u6307\u6807"""\n    recall_at_k = []\n    mrr = []\n    \n    for retrieved, relevant in zip(retrieved_ids, relevant_ids):\n        # Recall@K\n        retrieved_k = set(retrieved[:k])\n        relevant_set = set(relevant)\n        recall = len(retrieved_k & relevant_set) / len(relevant_set) if relevant_set else 0\n        recall_at_k.append(recall)\n        \n        # MRR\n        for i, doc_id in enumerate(retrieved):\n            if doc_id in relevant_set:\n                mrr.append(1 / (i + 1))\n                break\n        else:\n            mrr.append(0)\n    \n    return {\n        f"recall@{k}": np.mean(recall_at_k),\n        "mrr": np.mean(mrr)\n    }\n'})}),"\n",(0,r.jsx)(n.h3,{id:"3-llm-as-judge",children:"3. LLM-as-Judge"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from openai import OpenAI\n\nclient = OpenAI()\n\ndef llm_judge(question: str, answer: str, reference: str, criteria: str = "accuracy") -> dict:\n    """\u4f7f\u7528 LLM \u4f5c\u4e3a\u8bc4\u5224\u8005"""\n    \n    judge_prompt = f"""\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684\u8bc4\u4f30\u4e13\u5bb6\u3002\u8bf7\u6839\u636e\u4ee5\u4e0b\u6807\u51c6\u8bc4\u4f30\u56de\u7b54\u7684\u8d28\u91cf\u3002\n\n\u8bc4\u4f30\u6807\u51c6\uff1a{criteria}\n\n\u95ee\u9898\uff1a{question}\n\n\u53c2\u8003\u7b54\u6848\uff1a{reference}\n\n\u5f85\u8bc4\u4f30\u7b54\u6848\uff1a{answer}\n\n\u8bf7\u6309\u4ee5\u4e0b\u683c\u5f0f\u8f93\u51fa\u8bc4\u4f30\u7ed3\u679c\uff1a\n1. \u5206\u6570 (1-5)\uff1a\n2. \u7406\u7531\uff1a\n3. \u6539\u8fdb\u5efa\u8bae\uff1a\n\n\u53ea\u8f93\u51fa JSON \u683c\u5f0f\uff1a\n{{"score": <1-5>, "reason": "<\u7406\u7531>", "suggestion": "<\u5efa\u8bae>"}}\n"""\n    \n    response = client.chat.completions.create(\n        model="gpt-4o",\n        messages=[{"role": "user", "content": judge_prompt}],\n        temperature=0,\n        response_format={"type": "json_object"}\n    )\n    \n    return json.loads(response.choices[0].message.content)\n\n# \u6279\u91cf\u8bc4\u4f30\ndef batch_evaluate(samples: list[dict], judge_model: str = "gpt-4o") -> list[dict]:\n    """\u6279\u91cf\u8bc4\u4f30"""\n    results = []\n    for sample in samples:\n        result = llm_judge(\n            question=sample["input"],\n            answer=sample["output"],\n            reference=sample["expected"]\n        )\n        results.append({\n            "id": sample["id"],\n            **result\n        })\n    return results\n'})}),"\n",(0,r.jsx)(n.h3,{id:"4-rag-\u4e13\u9879\u8bc4\u4f30",children:"4. RAG \u4e13\u9879\u8bc4\u4f30"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def evaluate_rag_faithfulness(answer: str, context: str) -> dict:\n    """\u8bc4\u4f30 RAG \u56de\u7b54\u7684\u5fe0\u5b9e\u5ea6\uff08\u662f\u5426\u57fa\u4e8e\u68c0\u7d22\u5185\u5bb9\uff09"""\n    \n    prompt = f"""\u8bc4\u4f30\u4ee5\u4e0b\u56de\u7b54\u662f\u5426\u5fe0\u5b9e\u4e8e\u7ed9\u5b9a\u7684\u4e0a\u4e0b\u6587\u3002\n\n\u4e0a\u4e0b\u6587\uff1a\n{context}\n\n\u56de\u7b54\uff1a\n{answer}\n\n\u8bc4\u4f30\u6807\u51c6\uff1a\n- \u56de\u7b54\u4e2d\u7684\u6240\u6709\u4e8b\u5b9e\u662f\u5426\u90fd\u80fd\u5728\u4e0a\u4e0b\u6587\u4e2d\u627e\u5230\u4f9d\u636e\n- \u662f\u5426\u6709\u7f16\u9020\u6216\u81c6\u6d4b\u7684\u5185\u5bb9\n\n\u8f93\u51fa JSON\uff1a{{"faithfulness_score": <0-1>, "unsupported_claims": ["<\u4e0d\u652f\u6301\u7684\u58f0\u660e>"]}}\n"""\n    \n    response = client.chat.completions.create(\n        model="gpt-4o",\n        messages=[{"role": "user", "content": prompt}],\n        temperature=0,\n        response_format={"type": "json_object"}\n    )\n    \n    return json.loads(response.choices[0].message.content)\n\ndef evaluate_rag_relevancy(question: str, answer: str) -> dict:\n    """\u8bc4\u4f30\u56de\u7b54\u4e0e\u95ee\u9898\u7684\u76f8\u5173\u6027"""\n    \n    prompt = f"""\u8bc4\u4f30\u4ee5\u4e0b\u56de\u7b54\u4e0e\u95ee\u9898\u7684\u76f8\u5173\u6027\u3002\n\n\u95ee\u9898\uff1a{question}\n\n\u56de\u7b54\uff1a{answer}\n\n\u8bc4\u4f30\u6807\u51c6\uff1a\n- \u56de\u7b54\u662f\u5426\u76f4\u63a5\u56de\u5e94\u4e86\u95ee\u9898\n- \u662f\u5426\u6709\u65e0\u5173\u7684\u5185\u5bb9\n\n\u8f93\u51fa JSON\uff1a{{"relevancy_score": <0-1>, "irrelevant_parts": ["<\u65e0\u5173\u90e8\u5206>"]}}\n"""\n    \n    response = client.chat.completions.create(\n        model="gpt-4o",\n        messages=[{"role": "user", "content": prompt}],\n        temperature=0,\n        response_format={"type": "json_object"}\n    )\n    \n    return json.loads(response.choices[0].message.content)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u5728\u7ebf\u8bc4\u4f30online-eval",children:"\u5728\u7ebf\u8bc4\u4f30\uff08Online Eval\uff09"}),"\n",(0,r.jsx)(n.h3,{id:"ab-\u6d4b\u8bd5\u6846\u67b6",children:"A/B \u6d4b\u8bd5\u6846\u67b6"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import random\nimport hashlib\nfrom datetime import datetime\n\nclass ABTestManager:\n    """A/B \u6d4b\u8bd5\u7ba1\u7406\u5668"""\n    \n    def __init__(self):\n        self.experiments = {}\n    \n    def create_experiment(self, name: str, variants: dict[str, float]):\n        """\u521b\u5efa\u5b9e\u9a8c\uff0cvariants \u4e3a\u53d8\u4f53\u540d\u79f0\u548c\u6d41\u91cf\u6bd4\u4f8b"""\n        self.experiments[name] = {\n            "variants": variants,\n            "created_at": datetime.now(),\n            "metrics": {v: [] for v in variants}\n        }\n    \n    def get_variant(self, experiment_name: str, user_id: str) -> str:\n        """\u6839\u636e\u7528\u6237 ID \u5206\u914d\u53d8\u4f53\uff08\u786e\u4fdd\u540c\u4e00\u7528\u6237\u59cb\u7ec8\u5206\u5230\u540c\u4e00\u7ec4\uff09"""\n        exp = self.experiments[experiment_name]\n        \n        # \u4f7f\u7528 hash \u786e\u4fdd\u5206\u914d\u4e00\u81f4\u6027\n        hash_value = int(hashlib.md5(f"{experiment_name}:{user_id}".encode()).hexdigest(), 16)\n        random_value = (hash_value % 10000) / 10000\n        \n        cumulative = 0\n        for variant, ratio in exp["variants"].items():\n            cumulative += ratio\n            if random_value < cumulative:\n                return variant\n        \n        return list(exp["variants"].keys())[-1]\n    \n    def record_metric(self, experiment_name: str, variant: str, metric_name: str, value: float):\n        """\u8bb0\u5f55\u6307\u6807"""\n        self.experiments[experiment_name]["metrics"][variant].append({\n            "metric": metric_name,\n            "value": value,\n            "timestamp": datetime.now()\n        })\n\n# \u4f7f\u7528\u793a\u4f8b\nab_manager = ABTestManager()\nab_manager.create_experiment("prompt_v2", {\n    "control": 0.5,    # 50% \u4f7f\u7528\u65e7 prompt\n    "treatment": 0.5   # 50% \u4f7f\u7528\u65b0 prompt\n})\n\n# \u83b7\u53d6\u7528\u6237\u5206\u7ec4\nvariant = ab_manager.get_variant("prompt_v2", user_id="user123")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u4e1a\u52a1\u6307\u6807\u76d1\u63a7",children:"\u4e1a\u52a1\u6307\u6807\u76d1\u63a7"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from dataclasses import dataclass, field\nfrom typing import Optional\nimport time\n\n@dataclass\nclass RequestMetrics:\n    """\u8bf7\u6c42\u6307\u6807"""\n    request_id: str\n    user_id: str\n    model: str\n    prompt_tokens: int\n    completion_tokens: int\n    latency_ms: float\n    success: bool\n    error_type: Optional[str] = None\n    user_rating: Optional[int] = None  # 1-5\n    timestamp: float = field(default_factory=time.time)\n\nclass MetricsCollector:\n    """\u6307\u6807\u6536\u96c6\u5668"""\n    \n    def __init__(self):\n        self.metrics: list[RequestMetrics] = []\n    \n    def record(self, metrics: RequestMetrics):\n        self.metrics.append(metrics)\n    \n    def get_summary(self, time_window_hours: int = 24) -> dict:\n        """\u83b7\u53d6\u6307\u6807\u6458\u8981"""\n        cutoff = time.time() - time_window_hours * 3600\n        recent = [m for m in self.metrics if m.timestamp > cutoff]\n        \n        if not recent:\n            return {}\n        \n        return {\n            "total_requests": len(recent),\n            "success_rate": sum(1 for m in recent if m.success) / len(recent),\n            "avg_latency_ms": sum(m.latency_ms for m in recent) / len(recent),\n            "p95_latency_ms": sorted([m.latency_ms for m in recent])[int(len(recent) * 0.95)],\n            "avg_tokens": sum(m.prompt_tokens + m.completion_tokens for m in recent) / len(recent),\n            "avg_rating": sum(m.user_rating for m in recent if m.user_rating) / \n                         sum(1 for m in recent if m.user_rating) if any(m.user_rating for m in recent) else None\n        }\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u8bc4\u4f30\u5de5\u5177\u63a8\u8350",children:"\u8bc4\u4f30\u5de5\u5177\u63a8\u8350"}),"\n",(0,r.jsx)(n.h3,{id:"langsmith",children:"LangSmith"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from langsmith import Client\nfrom langsmith.evaluation import evaluate\n\n# \u521d\u59cb\u5316\u5ba2\u6237\u7aef\nclient = Client()\n\n# \u521b\u5efa\u6570\u636e\u96c6\ndataset = client.create_dataset("my-eval-dataset")\n\n# \u6dfb\u52a0\u6837\u672c\nclient.create_examples(\n    inputs=[{"question": "\u4ec0\u4e48\u662f RAG\uff1f"}],\n    outputs=[{"answer": "RAG \u662f\u68c0\u7d22\u589e\u5f3a\u751f\u6210..."}],\n    dataset_id=dataset.id\n)\n\n# \u5b9a\u4e49\u8bc4\u4f30\u51fd\u6570\ndef my_evaluator(run, example):\n    prediction = run.outputs["answer"]\n    reference = example.outputs["answer"]\n    # \u81ea\u5b9a\u4e49\u8bc4\u4f30\u903b\u8f91\n    score = calculate_similarity(prediction, reference)\n    return {"score": score}\n\n# \u8fd0\u884c\u8bc4\u4f30\nresults = evaluate(\n    lambda inputs: my_llm_app(inputs["question"]),\n    data=dataset.name,\n    evaluators=[my_evaluator]\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"deepeval",children:"DeepEval"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from deepeval import evaluate\nfrom deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric\nfrom deepeval.test_case import LLMTestCase\n\n# \u521b\u5efa\u6d4b\u8bd5\u7528\u4f8b\ntest_case = LLMTestCase(\n    input="\u4ec0\u4e48\u662f\u673a\u5668\u5b66\u4e60\uff1f",\n    actual_output="\u673a\u5668\u5b66\u4e60\u662f\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u4e2a\u5206\u652f...",\n    retrieval_context=["\u673a\u5668\u5b66\u4e60\u662f\u8ba9\u8ba1\u7b97\u673a\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7684\u6280\u672f..."]\n)\n\n# \u5b9a\u4e49\u6307\u6807\nrelevancy_metric = AnswerRelevancyMetric(threshold=0.7)\nfaithfulness_metric = FaithfulnessMetric(threshold=0.7)\n\n# \u8fd0\u884c\u8bc4\u4f30\nevaluate([test_case], [relevancy_metric, faithfulness_metric])\n'})}),"\n",(0,r.jsx)(n.h3,{id:"ragas",children:"RAGAS"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ragas import evaluate\nfrom ragas.metrics import faithfulness, answer_relevancy, context_precision\nfrom datasets import Dataset\n\n# \u51c6\u5907\u6570\u636e\ndata = {\n    "question": ["\u4ec0\u4e48\u662f RAG\uff1f"],\n    "answer": ["RAG \u662f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f..."],\n    "contexts": [["RAG \u5168\u79f0 Retrieval-Augmented Generation..."]],\n    "ground_truth": ["RAG \u662f\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u548c\u751f\u6210\u7684 AI \u6280\u672f"]\n}\n\ndataset = Dataset.from_dict(data)\n\n# \u8bc4\u4f30\nresults = evaluate(\n    dataset,\n    metrics=[faithfulness, answer_relevancy, context_precision]\n)\n\nprint(results)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u6700\u5c0f\u53ef\u884c\u8bc4\u4f30\u4f53\u7cfbmvp",children:"\u6700\u5c0f\u53ef\u884c\u8bc4\u4f30\u4f53\u7cfb\uff08MVP\uff09"}),"\n",(0,r.jsx)(n.h3,{id:"\u7b2c\u4e00\u9636\u6bb5\u57fa\u7840\u8bc4\u4f30",children:"\u7b2c\u4e00\u9636\u6bb5\uff1a\u57fa\u7840\u8bc4\u4f30"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# 1. 10-20 \u6761\u9ec4\u91d1\u6837\u672c\ngolden_set = load_golden_set("golden_samples.jsonl")\n\n# 2. 3 \u4e2a\u786c\u6307\u6807\ndef basic_eval(model_output: str, expected: str) -> dict:\n    return {\n        "format_correct": check_format(model_output),\n        "latency_ms": measure_latency(),\n        "cost_usd": calculate_cost()\n    }\n\n# 3. \u4eba\u5de5 spot-check\ndef spot_check(samples: list, n: int = 20):\n    """\u968f\u673a\u62bd\u53d6 n \u6761\u8fdb\u884c\u4eba\u5de5\u68c0\u67e5"""\n    import random\n    return random.sample(samples, min(n, len(samples)))\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u7b2c\u4e8c\u9636\u6bb5\u81ea\u52a8\u5316\u8bc4\u4f30",children:"\u7b2c\u4e8c\u9636\u6bb5\uff1a\u81ea\u52a8\u5316\u8bc4\u4f30"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# \u6dfb\u52a0 LLM-as-Judge\n# \u6dfb\u52a0 CI/CD \u96c6\u6210\n# \u6dfb\u52a0\u56de\u5f52\u6d4b\u8bd5\n"})}),"\n",(0,r.jsx)(n.h3,{id:"\u7b2c\u4e09\u9636\u6bb5\u5728\u7ebf\u8bc4\u4f30",children:"\u7b2c\u4e09\u9636\u6bb5\uff1a\u5728\u7ebf\u8bc4\u4f30"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# \u6dfb\u52a0 A/B \u6d4b\u8bd5\n# \u6dfb\u52a0\u4e1a\u52a1\u6307\u6807\u76d1\u63a7\n# \u6dfb\u52a0\u5f02\u5e38\u68c0\u6d4b\n"})}),"\n",(0,r.jsx)(n.h2,{id:"\u5ef6\u4f38\u9605\u8bfb",children:"\u5ef6\u4f38\u9605\u8bfb"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.smith.langchain.com/",children:"LangSmith \u6587\u6863"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/confident-ai/deepeval",children:"DeepEval \u6587\u6863"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.ragas.io/",children:"RAGAS \u6587\u6863"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/openai/evals",children:"OpenAI Evals"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);