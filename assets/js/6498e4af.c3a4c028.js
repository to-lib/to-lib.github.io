"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[11060],{11e3:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>o,contentTitle:()=>a,default:()=>p,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"ai/distillation","title":"\ud83e\uddec \u6a21\u578b\u84b8\u998f","description":"\u6a21\u578b\u84b8\u998f\uff08Knowledge Distillation\uff09\u662f\u5c06\u5927\u6a21\u578b\uff08\u6559\u5e08\u6a21\u578b\uff09\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230\u5c0f\u6a21\u578b\uff08\u5b66\u751f\u6a21\u578b\uff09\u7684\u6280\u672f\uff0c\u8ba9\u5c0f\u6a21\u578b\u83b7\u5f97\u63a5\u8fd1\u5927\u6a21\u578b\u7684\u80fd\u529b\u3002","source":"@site/docs/ai/distillation.md","sourceDirName":"ai","slug":"/ai/distillation","permalink":"/docs/ai/distillation","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ai/distillation.md","tags":[],"version":"current","sidebarPosition":32,"frontMatter":{"sidebar_position":32,"title":"\ud83e\uddec \u6a21\u578b\u84b8\u998f"},"sidebar":"ai","previous":{"title":"\ud83d\udddc\ufe0f \u6a21\u578b\u91cf\u5316","permalink":"/docs/ai/quantization"},"next":{"title":"\ud83d\udd00 \u6a21\u578b\u5408\u5e76","permalink":"/docs/ai/model-merging"}}');var r=t(22714),i=t(48885);const l={sidebar_position:32,title:"\ud83e\uddec \u6a21\u578b\u84b8\u998f"},a="\u6a21\u578b\u84b8\u998f",o={},d=[{value:"\u4e3a\u4ec0\u4e48\u9700\u8981\u84b8\u998f\uff1f",id:"\u4e3a\u4ec0\u4e48\u9700\u8981\u84b8\u998f",level:2},{value:"\u84b8\u998f\u65b9\u6cd5",id:"\u84b8\u998f\u65b9\u6cd5",level:2},{value:"\u6570\u636e\u84b8\u998f\uff08\u6700\u5e38\u7528\uff09",id:"\u6570\u636e\u84b8\u998f\u6700\u5e38\u7528",level:2},{value:"\u751f\u6210\u8bad\u7ec3\u6570\u636e",id:"\u751f\u6210\u8bad\u7ec3\u6570\u636e",level:3},{value:"\u5fae\u8c03\u5b66\u751f\u6a21\u578b",id:"\u5fae\u8c03\u5b66\u751f\u6a21\u578b",level:3},{value:"\u8f93\u51fa\u84b8\u998f",id:"\u8f93\u51fa\u84b8\u998f",level:2},{value:"OpenAI \u84b8\u998f API",id:"openai-\u84b8\u998f-api",level:2},{value:"\u5b9e\u6218\uff1a\u84b8\u998f\u4ee3\u7801\u52a9\u624b",id:"\u5b9e\u6218\u84b8\u998f\u4ee3\u7801\u52a9\u624b",level:2},{value:"\u84b8\u998f\u6548\u679c\u8bc4\u4f30",id:"\u84b8\u998f\u6548\u679c\u8bc4\u4f30",level:2},{value:"\u6700\u4f73\u5b9e\u8df5",id:"\u6700\u4f73\u5b9e\u8df5",level:2},{value:"\u5ef6\u4f38\u9605\u8bfb",id:"\u5ef6\u4f38\u9605\u8bfb",level:2}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"\u6a21\u578b\u84b8\u998f",children:"\u6a21\u578b\u84b8\u998f"})}),"\n",(0,r.jsx)(e.p,{children:"\u6a21\u578b\u84b8\u998f\uff08Knowledge Distillation\uff09\u662f\u5c06\u5927\u6a21\u578b\uff08\u6559\u5e08\u6a21\u578b\uff09\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230\u5c0f\u6a21\u578b\uff08\u5b66\u751f\u6a21\u578b\uff09\u7684\u6280\u672f\uff0c\u8ba9\u5c0f\u6a21\u578b\u83b7\u5f97\u63a5\u8fd1\u5927\u6a21\u578b\u7684\u80fd\u529b\u3002"}),"\n",(0,r.jsx)(e.h2,{id:"\u4e3a\u4ec0\u4e48\u9700\u8981\u84b8\u998f",children:"\u4e3a\u4ec0\u4e48\u9700\u8981\u84b8\u998f\uff1f"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"\u5bf9\u6bd4"}),(0,r.jsx)(e.th,{children:"\u5927\u6a21\u578b"}),(0,r.jsx)(e.th,{children:"\u84b8\u998f\u540e\u5c0f\u6a21\u578b"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u53c2\u6570\u91cf"}),(0,r.jsx)(e.td,{children:"70B+"}),(0,r.jsx)(e.td,{children:"7B \u6216\u66f4\u5c0f"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u63a8\u7406\u6210\u672c"}),(0,r.jsx)(e.td,{children:"\u9ad8"}),(0,r.jsx)(e.td,{children:"\u4f4e"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u90e8\u7f72\u96be\u5ea6"}),(0,r.jsx)(e.td,{children:"\u9700\u8981\u591a\u5361"}),(0,r.jsx)(e.td,{children:"\u5355\u5361/CPU"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u54cd\u5e94\u901f\u5ea6"}),(0,r.jsx)(e.td,{children:"\u6162"}),(0,r.jsx)(e.td,{children:"\u5feb"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u80fd\u529b"}),(0,r.jsx)(e.td,{children:"\u901a\u7528\u5f3a"}),(0,r.jsx)(e.td,{children:"\u7279\u5b9a\u4efb\u52a1\u5f3a"})]})]})]}),"\n",(0,r.jsx)(e.h2,{id:"\u84b8\u998f\u65b9\u6cd5",children:"\u84b8\u998f\u65b9\u6cd5"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    \u84b8\u998f\u65b9\u6cd5                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502  1. \u8f93\u51fa\u84b8\u998f\uff1a\u5b66\u4e60\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u5206\u5e03                    \u2502\n\u2502  2. \u7279\u5f81\u84b8\u998f\uff1a\u5b66\u4e60\u4e2d\u95f4\u5c42\u8868\u793a                            \u2502\n\u2502  3. \u6570\u636e\u84b8\u998f\uff1a\u7528\u6559\u5e08\u6a21\u578b\u751f\u6210\u8bad\u7ec3\u6570\u636e                    \u2502\n\u2502                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(e.h2,{id:"\u6570\u636e\u84b8\u998f\u6700\u5e38\u7528",children:"\u6570\u636e\u84b8\u998f\uff08\u6700\u5e38\u7528\uff09"}),"\n",(0,r.jsx)(e.p,{children:"\u4f7f\u7528\u5927\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u7136\u540e\u5fae\u8c03\u5c0f\u6a21\u578b\u3002"}),"\n",(0,r.jsx)(e.h3,{id:"\u751f\u6210\u8bad\u7ec3\u6570\u636e",children:"\u751f\u6210\u8bad\u7ec3\u6570\u636e"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from openai import OpenAI\nimport json\n\nclient = OpenAI()\n\ndef generate_training_data(task_description: str, num_samples: int = 100) -> list:\n    """\u4f7f\u7528 GPT-4 \u751f\u6210\u8bad\u7ec3\u6570\u636e"""\n    samples = []\n    \n    for i in range(num_samples):\n        response = client.chat.completions.create(\n            model="gpt-4o",\n            messages=[\n                {\n                    "role": "system",\n                    "content": f"""\u4f60\u662f\u4e00\u4e2a\u6570\u636e\u751f\u6210\u4e13\u5bb6\u3002\u8bf7\u4e3a\u4ee5\u4e0b\u4efb\u52a1\u751f\u6210\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\uff1a\n\u4efb\u52a1\uff1a{task_description}\n\n\u751f\u6210\u683c\u5f0f\uff1a\n{{"input": "\u8f93\u5165\u6587\u672c", "output": "\u671f\u671b\u8f93\u51fa"}}\n\n\u8981\u6c42\uff1a\n1. \u8f93\u5165\u8981\u591a\u6837\u5316\n2. \u8f93\u51fa\u8981\u51c6\u786e\u3001\u9ad8\u8d28\u91cf\n3. \u53ea\u8fd4\u56de JSON\uff0c\u4e0d\u8981\u5176\u4ed6\u5185\u5bb9"""\n                },\n                {"role": "user", "content": f"\u751f\u6210\u7b2c {i+1} \u4e2a\u6837\u672c"}\n            ],\n            response_format={"type": "json_object"}\n        )\n        \n        sample = json.loads(response.choices[0].message.content)\n        samples.append(sample)\n        \n        if (i + 1) % 10 == 0:\n            print(f"\u5df2\u751f\u6210 {i + 1}/{num_samples} \u4e2a\u6837\u672c")\n    \n    return samples\n\n# \u751f\u6210\u6570\u636e\nsamples = generate_training_data(\n    task_description="\u4e2d\u6587\u6587\u672c\u60c5\u611f\u5206\u7c7b\uff08positive/negative/neutral\uff09",\n    num_samples=500\n)\n\n# \u4fdd\u5b58\nwith open("training_data.jsonl", "w") as f:\n    for sample in samples:\n        f.write(json.dumps(sample, ensure_ascii=False) + "\\n")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\u5fae\u8c03\u5b66\u751f\u6a21\u578b",children:"\u5fae\u8c03\u5b66\u751f\u6a21\u578b"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer\n)\nfrom datasets import load_dataset\nfrom peft import LoraConfig, get_peft_model\n\n# \u52a0\u8f7d\u5b66\u751f\u6a21\u578b\nmodel_name = "Qwen/Qwen2.5-1.5B"\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# \u52a0\u8f7d\u84b8\u998f\u6570\u636e\ndataset = load_dataset("json", data_files="training_data.jsonl")\n\ndef format_sample(sample):\n    text = f"\u8f93\u5165\uff1a{sample[\'input\']}\\n\u8f93\u51fa\uff1a{sample[\'output\']}"\n    return tokenizer(text, truncation=True, max_length=512)\n\ndataset = dataset.map(format_sample)\n\n# LoRA \u914d\u7f6e\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=["q_proj", "v_proj"],\n    lora_dropout=0.05\n)\n\nmodel = get_peft_model(model, lora_config)\n\n# \u8bad\u7ec3\ntraining_args = TrainingArguments(\n    output_dir="./distilled_model",\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    learning_rate=2e-4,\n    save_strategy="epoch"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset["train"]\n)\n\ntrainer.train()\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u8f93\u51fa\u84b8\u998f",children:"\u8f93\u51fa\u84b8\u998f"}),"\n",(0,r.jsx)(e.p,{children:"\u8ba9\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u6982\u7387\u5206\u5e03\u3002"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DistillationLoss(nn.Module):\n    """\u84b8\u998f\u635f\u5931\u51fd\u6570"""\n    \n    def __init__(self, temperature: float = 2.0, alpha: float = 0.5):\n        super().__init__()\n        self.temperature = temperature\n        self.alpha = alpha\n        self.ce_loss = nn.CrossEntropyLoss()\n    \n    def forward(\n        self,\n        student_logits: torch.Tensor,\n        teacher_logits: torch.Tensor,\n        labels: torch.Tensor\n    ) -> torch.Tensor:\n        # \u8f6f\u6807\u7b7e\u635f\u5931\uff08KL \u6563\u5ea6\uff09\n        soft_loss = F.kl_div(\n            F.log_softmax(student_logits / self.temperature, dim=-1),\n            F.softmax(teacher_logits / self.temperature, dim=-1),\n            reduction="batchmean"\n        ) * (self.temperature ** 2)\n        \n        # \u786c\u6807\u7b7e\u635f\u5931\uff08\u4ea4\u53c9\u71b5\uff09\n        hard_loss = self.ce_loss(student_logits, labels)\n        \n        # \u7ec4\u5408\u635f\u5931\n        return self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n\nclass DistillationTrainer:\n    """\u84b8\u998f\u8bad\u7ec3\u5668"""\n    \n    def __init__(\n        self,\n        teacher_model,\n        student_model,\n        tokenizer,\n        temperature: float = 2.0\n    ):\n        self.teacher = teacher_model.eval()\n        self.student = student_model\n        self.tokenizer = tokenizer\n        self.loss_fn = DistillationLoss(temperature=temperature)\n    \n    def train_step(self, batch):\n        # \u6559\u5e08\u6a21\u578b\u63a8\u7406\uff08\u4e0d\u8ba1\u7b97\u68af\u5ea6\uff09\n        with torch.no_grad():\n            teacher_outputs = self.teacher(**batch)\n            teacher_logits = teacher_outputs.logits\n        \n        # \u5b66\u751f\u6a21\u578b\u63a8\u7406\n        student_outputs = self.student(**batch)\n        student_logits = student_outputs.logits\n        \n        # \u8ba1\u7b97\u84b8\u998f\u635f\u5931\n        loss = self.loss_fn(\n            student_logits.view(-1, student_logits.size(-1)),\n            teacher_logits.view(-1, teacher_logits.size(-1)),\n            batch["labels"].view(-1)\n        )\n        \n        return loss\n'})}),"\n",(0,r.jsx)(e.h2,{id:"openai-\u84b8\u998f-api",children:"OpenAI \u84b8\u998f API"}),"\n",(0,r.jsx)(e.p,{children:"OpenAI \u63d0\u4f9b\u4e86\u5b98\u65b9\u7684\u84b8\u998f\u529f\u80fd\u3002"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from openai import OpenAI\n\nclient = OpenAI()\n\n# 1. \u4f7f\u7528\u5927\u6a21\u578b\u751f\u6210\u5e26 metadata \u7684\u54cd\u5e94\nresponse = client.chat.completions.create(\n    model="gpt-4o",\n    messages=[{"role": "user", "content": "\u89e3\u91ca\u91cf\u5b50\u8ba1\u7b97"}],\n    store=True,  # \u5b58\u50a8\u7528\u4e8e\u84b8\u998f\n    metadata={"task": "explanation", "domain": "physics"}\n)\n\n# 2. \u521b\u5efa\u84b8\u998f\u5fae\u8c03\u4efb\u52a1\n# \u4f7f\u7528\u5b58\u50a8\u7684\u9ad8\u8d28\u91cf\u54cd\u5e94\u5fae\u8c03\u5c0f\u6a21\u578b\nfine_tune = client.fine_tuning.jobs.create(\n    training_file="file-xxx",  # \u5305\u542b\u84b8\u998f\u6570\u636e\n    model="gpt-4o-mini",       # \u5b66\u751f\u6a21\u578b\n    method={\n        "type": "supervised",\n        "supervised": {\n            "hyperparameters": {"n_epochs": 3}\n        }\n    }\n)\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u5b9e\u6218\u84b8\u998f\u4ee3\u7801\u52a9\u624b",children:"\u5b9e\u6218\uff1a\u84b8\u998f\u4ee3\u7801\u52a9\u624b"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class CodeAssistantDistiller:\n    """\u4ee3\u7801\u52a9\u624b\u84b8\u998f"""\n    \n    def __init__(self):\n        self.client = OpenAI()\n    \n    def generate_code_samples(self, num_samples: int = 200) -> list:\n        """\u751f\u6210\u4ee3\u7801\u8bad\u7ec3\u6837\u672c"""\n        tasks = [\n            "\u5199\u4e00\u4e2a Python \u51fd\u6570\u5b9e\u73b0\u5feb\u901f\u6392\u5e8f",\n            "\u5b9e\u73b0\u4e00\u4e2a LRU \u7f13\u5b58",\n            "\u5199\u4e00\u4e2a\u5f02\u6b65 HTTP \u5ba2\u6237\u7aef",\n            # ... \u66f4\u591a\u4efb\u52a1\n        ]\n        \n        samples = []\n        for task in tasks:\n            # \u4f7f\u7528 GPT-4 \u751f\u6210\u9ad8\u8d28\u91cf\u4ee3\u7801\n            response = self.client.chat.completions.create(\n                model="gpt-4o",\n                messages=[\n                    {\n                        "role": "system",\n                        "content": "\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684 Python \u5f00\u53d1\u8005\u3002\u751f\u6210\u7b80\u6d01\u3001\u9ad8\u6548\u3001\u6709\u6ce8\u91ca\u7684\u4ee3\u7801\u3002"\n                    },\n                    {"role": "user", "content": task}\n                ]\n            )\n            \n            samples.append({\n                "instruction": task,\n                "output": response.choices[0].message.content\n            })\n        \n        return samples\n    \n    def format_for_training(self, samples: list) -> list:\n        """\u683c\u5f0f\u5316\u4e3a\u8bad\u7ec3\u6570\u636e"""\n        formatted = []\n        for sample in samples:\n            formatted.append({\n                "messages": [\n                    {"role": "system", "content": "\u4f60\u662f\u4e00\u4e2a\u4ee3\u7801\u52a9\u624b\u3002"},\n                    {"role": "user", "content": sample["instruction"]},\n                    {"role": "assistant", "content": sample["output"]}\n                ]\n            })\n        return formatted\n\n# \u4f7f\u7528\ndistiller = CodeAssistantDistiller()\nsamples = distiller.generate_code_samples(200)\ntraining_data = distiller.format_for_training(samples)\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u84b8\u998f\u6548\u679c\u8bc4\u4f30",children:"\u84b8\u998f\u6548\u679c\u8bc4\u4f30"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'def evaluate_distillation(\n    teacher_model,\n    student_model,\n    test_data: list,\n    tokenizer\n) -> dict:\n    """\u8bc4\u4f30\u84b8\u998f\u6548\u679c"""\n    \n    teacher_scores = []\n    student_scores = []\n    \n    for sample in test_data:\n        prompt = sample["input"]\n        reference = sample["output"]\n        \n        # \u6559\u5e08\u6a21\u578b\u8f93\u51fa\n        teacher_output = generate(teacher_model, tokenizer, prompt)\n        \n        # \u5b66\u751f\u6a21\u578b\u8f93\u51fa\n        student_output = generate(student_model, tokenizer, prompt)\n        \n        # \u8bc4\u4f30\uff08\u53ef\u4ee5\u7528 GPT-4 \u8bc4\u5206\uff09\n        teacher_score = evaluate_quality(teacher_output, reference)\n        student_score = evaluate_quality(student_output, reference)\n        \n        teacher_scores.append(teacher_score)\n        student_scores.append(student_score)\n    \n    return {\n        "teacher_avg": sum(teacher_scores) / len(teacher_scores),\n        "student_avg": sum(student_scores) / len(student_scores),\n        "retention_rate": sum(student_scores) / sum(teacher_scores)\n    }\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u6700\u4f73\u5b9e\u8df5",children:"\u6700\u4f73\u5b9e\u8df5"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u6570\u636e\u8d28\u91cf\u4f18\u5148"}),"\uff1a\u84b8\u998f\u6570\u636e\u7684\u8d28\u91cf\u51b3\u5b9a\u5b66\u751f\u6a21\u578b\u4e0a\u9650"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u4efb\u52a1\u805a\u7126"}),"\uff1a\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u84b8\u998f\u6548\u679c\u66f4\u597d"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u591a\u6837\u6027"}),"\uff1a\u8bad\u7ec3\u6570\u636e\u8981\u8986\u76d6\u5404\u79cd\u573a\u666f"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u8fed\u4ee3\u4f18\u5316"}),"\uff1a\u591a\u8f6e\u84b8\u998f\u9010\u6b65\u63d0\u5347"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u8bc4\u4f30\u9a8c\u8bc1"}),"\uff1a\u786e\u4fdd\u5b66\u751f\u6a21\u578b\u8fbe\u5230\u9884\u671f\u6548\u679c"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"\u5ef6\u4f38\u9605\u8bfb",children:"\u5ef6\u4f38\u9605\u8bfb"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://arxiv.org/abs/2305.02301",children:"Distilling Step-by-Step"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://platform.openai.com/docs/guides/distillation",children:"OpenAI Model Distillation"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://arxiv.org/abs/2402.13116",children:"LLM Distillation Survey"})}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(c,{...n})}):c(n)}},48885:(n,e,t)=>{t.d(e,{R:()=>l,x:()=>a});var s=t(99378);const r={},i=s.createContext(r);function l(n){const e=s.useContext(i);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:l(n.components),s.createElement(i.Provider,{value:e},n.children)}}}]);