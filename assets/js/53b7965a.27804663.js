"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[48377],{48885:(s,e,n)=>{n.d(e,{R:()=>t,x:()=>r});var a=n(99378);const l={},i=a.createContext(l);function t(s){const e=a.useContext(i);return a.useMemo(function(){return"function"==typeof s?s(e):{...e,...s}},[e,s])}function r(s){let e;return e=s.disableParentContext?"function"==typeof s.components?s.components(l):s.components||l:t(s.components),a.createElement(i.Provider,{value:e},s.children)}},70981:(s,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>t,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"ml/reinforcement-learning","title":"\ud83c\udfae \u5f3a\u5316\u5b66\u4e60","description":"\u5f3a\u5316\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u7b2c\u4e09\u5927\u8303\u5f0f\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u4e0e\u73af\u5883\u4ea4\u4e92\u6765\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u3002","source":"@site/docs/ml/reinforcement-learning.md","sourceDirName":"ml","slug":"/ml/reinforcement-learning","permalink":"/docs/ml/reinforcement-learning","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ml/reinforcement-learning.md","tags":[],"version":"current","sidebarPosition":19,"frontMatter":{"sidebar_position":19,"title":"\ud83c\udfae \u5f3a\u5316\u5b66\u4e60"},"sidebar":"ml","previous":{"title":"\ud83d\udcca \u8d1d\u53f6\u65af\u65b9\u6cd5","permalink":"/docs/ml/bayesian-methods"},"next":{"title":"\ud83d\udd17 \u795e\u7ecf\u7f51\u7edc\u57fa\u7840","permalink":"/docs/ml/neural-networks"}}');var l=n(22714),i=n(48885);const t={sidebar_position:19,title:"\ud83c\udfae \u5f3a\u5316\u5b66\u4e60"},r="\u5f3a\u5316\u5b66\u4e60",c={},d=[{value:"\u6838\u5fc3\u6982\u5ff5",id:"\u6838\u5fc3\u6982\u5ff5",level:2},{value:"\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b (MDP)",id:"\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b-mdp",level:2},{value:"\u7ecf\u5178\u7b97\u6cd5",id:"\u7ecf\u5178\u7b97\u6cd5",level:2},{value:"Q-Learning",id:"q-learning",level:3},{value:"SARSA",id:"sarsa",level:3},{value:"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60",id:"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60",level:2},{value:"DQN",id:"dqn",level:3},{value:"Policy Gradient",id:"policy-gradient",level:3},{value:"Actor-Critic",id:"actor-critic",level:3},{value:"\u5e38\u7528\u5e93",id:"\u5e38\u7528\u5e93",level:2},{value:"\u7b97\u6cd5\u5206\u7c7b",id:"\u7b97\u6cd5\u5206\u7c7b",level:2}];function m(s){const e={annotation:"annotation",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",math:"math",mermaid:"mermaid",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",msub:"msub",msup:"msup",munderover:"munderover",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...s.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"\u5f3a\u5316\u5b66\u4e60",children:"\u5f3a\u5316\u5b66\u4e60"})}),"\n",(0,l.jsx)(e.p,{children:"\u5f3a\u5316\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u7b2c\u4e09\u5927\u8303\u5f0f\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u4e0e\u73af\u5883\u4ea4\u4e92\u6765\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u3002"}),"\n",(0,l.jsx)(e.h2,{id:"\u6838\u5fc3\u6982\u5ff5",children:"\u6838\u5fc3\u6982\u5ff5"}),"\n",(0,l.jsx)(e.mermaid,{value:"graph LR\n    A[Agent] --\x3e|Action a| B[Environment]\n    B --\x3e|State s| A\n    B --\x3e|Reward r| A"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,l.jsxs)(e.table,{children:[(0,l.jsx)(e.thead,{children:(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.th,{children:"\u6982\u5ff5"}),(0,l.jsx)(e.th,{children:"\u7b26\u53f7"}),(0,l.jsx)(e.th,{children:"\u63cf\u8ff0"})]})}),(0,l.jsxs)(e.tbody,{children:[(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u72b6\u6001"}),(0,l.jsx)(e.td,{children:"s"}),(0,l.jsx)(e.td,{children:"\u73af\u5883\u7684\u5f53\u524d\u60c5\u51b5"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u52a8\u4f5c"}),(0,l.jsx)(e.td,{children:"a"}),(0,l.jsx)(e.td,{children:"\u667a\u80fd\u4f53\u53ef\u6267\u884c\u7684\u64cd\u4f5c"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u5956\u52b1"}),(0,l.jsx)(e.td,{children:"r"}),(0,l.jsx)(e.td,{children:"\u73af\u5883\u53cd\u9988\u7684\u5373\u65f6\u4fe1\u53f7"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u7b56\u7565"}),(0,l.jsx)(e.td,{children:"\u03c0(a|s)"}),(0,l.jsx)(e.td,{children:"\u4ece\u72b6\u6001\u5230\u52a8\u4f5c\u7684\u6620\u5c04"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u4ef7\u503c\u51fd\u6570"}),(0,l.jsx)(e.td,{children:"V(s)"}),(0,l.jsx)(e.td,{children:"\u72b6\u6001\u7684\u957f\u671f\u4ef7\u503c"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"Q \u51fd\u6570"}),(0,l.jsx)(e.td,{children:"Q(s,a)"}),(0,l.jsx)(e.td,{children:"\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\u4ef7\u503c"})]})]})]}),"\n",(0,l.jsx)(e.h2,{id:"\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b-mdp",children:"\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b (MDP)"}),"\n",(0,l.jsx)(e.span,{className:"katex-display",children:(0,l.jsxs)(e.span,{className:"katex",children:[(0,l.jsx)(e.span,{className:"katex-mathml",children:(0,l.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,l.jsxs)(e.semantics,{children:[(0,l.jsxs)(e.mrow,{children:[(0,l.jsxs)(e.msup,{children:[(0,l.jsx)(e.mi,{children:"V"}),(0,l.jsx)(e.mi,{children:"\u03c0"})]}),(0,l.jsx)(e.mo,{stretchy:"false",children:"("}),(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsx)(e.mo,{stretchy:"false",children:")"}),(0,l.jsx)(e.mo,{children:"="}),(0,l.jsx)(e.mi,{mathvariant:"double-struck",children:"E"}),(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mo,{fence:"true",children:"["}),(0,l.jsxs)(e.munderover,{children:[(0,l.jsx)(e.mo,{children:"\u2211"}),(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mi,{children:"t"}),(0,l.jsx)(e.mo,{children:"="}),(0,l.jsx)(e.mn,{children:"0"})]}),(0,l.jsx)(e.mi,{mathvariant:"normal",children:"\u221e"})]}),(0,l.jsxs)(e.msup,{children:[(0,l.jsx)(e.mi,{children:"\u03b3"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"r"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{children:"\u2223"}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsx)(e.mn,{children:"0"})]}),(0,l.jsx)(e.mo,{children:"="}),(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsx)(e.mo,{fence:"true",children:"]"})]})]}),(0,l.jsx)(e.annotation,{encoding:"application/x-tex",children:"V^\\pi(s) = \\mathbb{E}\\left[\\sum_{t=0}^{\\infty} \\gamma^t r_t \\mid s_0 = s\\right]"})]})})}),(0,l.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.22222em"},children:"V"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsx)(e.span,{className:"vlist-t",children:(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.7144em"},children:(0,l.jsxs)(e.span,{style:{top:"-3.113em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"\u03c0"})})]})})})})})]}),(0,l.jsx)(e.span,{className:"mopen",children:"("}),(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"mclose",children:")"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"="}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"3.0171em",verticalAlign:"-1.2671em"}}),(0,l.jsx)(e.span,{className:"mord mathbb",children:"E"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,l.jsxs)(e.span,{className:"minner",children:[(0,l.jsx)(e.span,{className:"mopen delimcenter",style:{top:"0em"},children:(0,l.jsx)(e.span,{className:"delimsizing size4",children:"["})}),(0,l.jsx)(e.span,{className:"mop op-limits",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsxs)(e.span,{className:"vlist",style:{height:"1.6514em"},children:[(0,l.jsxs)(e.span,{style:{top:"-1.8829em",marginLeft:"0em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"3.05em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsxs)(e.span,{className:"mord mtight",children:[(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"}),(0,l.jsx)(e.span,{className:"mrel mtight",children:"="}),(0,l.jsx)(e.span,{className:"mord mtight",children:"0"})]})})]}),(0,l.jsxs)(e.span,{style:{top:"-3.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"3.05em"}}),(0,l.jsx)(e.span,{children:(0,l.jsx)(e.span,{className:"mop op-symbol large-op",children:"\u2211"})})]}),(0,l.jsxs)(e.span,{style:{top:"-4.3em",marginLeft:"0em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"3.05em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mtight",children:(0,l.jsx)(e.span,{className:"mord mtight",children:"\u221e"})})})]})]}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"1.2671em"},children:(0,l.jsx)(e.span,{})})})]})}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05556em"},children:"\u03b3"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsx)(e.span,{className:"vlist-t",children:(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.8436em"},children:(0,l.jsxs)(e.span,{style:{top:"-3.113em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})})})})})]}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.0278em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"\u2223"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.3011em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mtight",children:"0"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"="}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"mclose delimcenter",style:{top:"0em"},children:(0,l.jsx)(e.span,{className:"delimsizing size4",children:"]"})})]})]})]})]})}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"\u03b3 (gamma)"}),": \u6298\u6263\u56e0\u5b50\uff0c0 < \u03b3 \u2264 1"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"\u7ecf\u5178\u7b97\u6cd5",children:"\u7ecf\u5178\u7b97\u6cd5"}),"\n",(0,l.jsx)(e.h3,{id:"q-learning",children:"Q-Learning"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"import numpy as np\n\nclass QLearning:\n    def __init__(self, n_states, n_actions, lr=0.1, gamma=0.99, epsilon=0.1):\n        self.q_table = np.zeros((n_states, n_actions))\n        self.lr = lr\n        self.gamma = gamma\n        self.epsilon = epsilon\n\n    def choose_action(self, state):\n        if np.random.random() < self.epsilon:\n            return np.random.randint(len(self.q_table[state]))\n        return np.argmax(self.q_table[state])\n\n    def update(self, state, action, reward, next_state):\n        # Q(s,a) \u2190 Q(s,a) + \u03b1[r + \u03b3 max Q(s',a') - Q(s,a)]\n        best_next = np.max(self.q_table[next_state])\n        td_target = reward + self.gamma * best_next\n        td_error = td_target - self.q_table[state, action]\n        self.q_table[state, action] += self.lr * td_error\n"})}),"\n",(0,l.jsx)(e.h3,{id:"sarsa",children:"SARSA"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"def sarsa_update(self, s, a, r, s_next, a_next):\n    # Q(s,a) \u2190 Q(s,a) + \u03b1[r + \u03b3 Q(s',a') - Q(s,a)]\n    td_target = r + self.gamma * self.q_table[s_next, a_next]\n    self.q_table[s, a] += self.lr * (td_target - self.q_table[s, a])\n"})}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,l.jsxs)(e.table,{children:[(0,l.jsx)(e.thead,{children:(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.th,{children:"\u7b97\u6cd5"}),(0,l.jsx)(e.th,{children:"\u7c7b\u578b"}),(0,l.jsx)(e.th,{children:"\u7279\u70b9"})]})}),(0,l.jsxs)(e.tbody,{children:[(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"Q-Learning"}),(0,l.jsx)(e.td,{children:"Off-policy"}),(0,l.jsx)(e.td,{children:"\u5b66\u4e60\u6700\u4f18\u7b56\u7565"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"SARSA"}),(0,l.jsx)(e.td,{children:"On-policy"}),(0,l.jsx)(e.td,{children:"\u5b66\u4e60\u5f53\u524d\u7b56\u7565"})]})]})]}),"\n",(0,l.jsx)(e.h2,{id:"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60",children:"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60"}),"\n",(0,l.jsx)(e.h3,{id:"dqn",children:"DQN"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"import torch\nimport torch.nn as nn\n\nclass DQN(nn.Module):\n    def __init__(self, state_dim, action_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(state_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, action_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n# \u7ecf\u9a8c\u56de\u653e\nclass ReplayBuffer:\n    def __init__(self, capacity):\n        self.buffer = []\n        self.capacity = capacity\n\n    def push(self, transition):\n        if len(self.buffer) >= self.capacity:\n            self.buffer.pop(0)\n        self.buffer.append(transition)\n\n    def sample(self, batch_size):\n        indices = np.random.choice(len(self.buffer), batch_size)\n        return [self.buffer[i] for i in indices]\n"})}),"\n",(0,l.jsx)(e.h3,{id:"policy-gradient",children:"Policy Gradient"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"class PolicyNetwork(nn.Module):\n    def __init__(self, state_dim, action_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(state_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, action_dim),\n            nn.Softmax(dim=-1)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n# REINFORCE \u7b97\u6cd5\ndef reinforce_loss(log_probs, rewards, gamma=0.99):\n    returns = []\n    G = 0\n    for r in reversed(rewards):\n        G = r + gamma * G\n        returns.insert(0, G)\n    returns = torch.tensor(returns)\n    returns = (returns - returns.mean()) / (returns.std() + 1e-8)\n    return -torch.sum(log_probs * returns)\n"})}),"\n",(0,l.jsx)(e.h3,{id:"actor-critic",children:"Actor-Critic"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"class ActorCritic(nn.Module):\n    def __init__(self, state_dim, action_dim):\n        super().__init__()\n        self.shared = nn.Linear(state_dim, 128)\n        self.actor = nn.Linear(128, action_dim)\n        self.critic = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.shared(x))\n        policy = torch.softmax(self.actor(x), dim=-1)\n        value = self.critic(x)\n        return policy, value\n"})}),"\n",(0,l.jsx)(e.h2,{id:"\u5e38\u7528\u5e93",children:"\u5e38\u7528\u5e93"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"import gymnasium as gym\n\n# \u521b\u5efa\u73af\u5883\nenv = gym.make('CartPole-v1')\n\nstate, _ = env.reset()\nfor _ in range(1000):\n    action = env.action_space.sample()  # \u968f\u673a\u52a8\u4f5c\n    next_state, reward, terminated, truncated, info = env.step(action)\n    if terminated or truncated:\n        break\n"})}),"\n",(0,l.jsx)(e.h2,{id:"\u7b97\u6cd5\u5206\u7c7b",children:"\u7b97\u6cd5\u5206\u7c7b"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,l.jsxs)(e.table,{children:[(0,l.jsx)(e.thead,{children:(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.th,{children:"\u7c7b\u578b"}),(0,l.jsx)(e.th,{children:"\u7b97\u6cd5"}),(0,l.jsx)(e.th,{children:"\u7279\u70b9"})]})}),(0,l.jsxs)(e.tbody,{children:[(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"Value-based"}),(0,l.jsx)(e.td,{children:"DQN, Double DQN"}),(0,l.jsx)(e.td,{children:"\u5b66\u4e60 Q \u51fd\u6570"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"Policy-based"}),(0,l.jsx)(e.td,{children:"REINFORCE, A2C"}),(0,l.jsx)(e.td,{children:"\u76f4\u63a5\u5b66\u4e60\u7b56\u7565"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"Actor-Critic"}),(0,l.jsx)(e.td,{children:"PPO, SAC, TD3"}),(0,l.jsx)(e.td,{children:"\u7ed3\u5408\u4e24\u8005"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"Model-based"}),(0,l.jsx)(e.td,{children:"MuZero, Dreamer"}),(0,l.jsx)(e.td,{children:"\u5b66\u4e60\u73af\u5883\u6a21\u578b"})]})]})]})]})}function h(s={}){const{wrapper:e}={...(0,i.R)(),...s.components};return e?(0,l.jsx)(e,{...s,children:(0,l.jsx)(m,{...s})}):m(s)}}}]);