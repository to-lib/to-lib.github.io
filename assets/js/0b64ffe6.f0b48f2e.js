"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[89230],{48885:(n,e,t)=>{t.d(e,{R:()=>o,x:()=>l});var s=t(99378);const r={},i=s.createContext(r);function o(n){const e=s.useContext(i);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),s.createElement(i.Provider,{value:e},n.children)}},55026:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ai/structured-output","title":"\ud83d\udcd0 \u7ed3\u6784\u5316\u8f93\u51fa","description":"\u7ed3\u6784\u5316\u8f93\u51fa\u662f\u8ba9 LLM \u6309\u7167\u6307\u5b9a\u7684\u683c\u5f0f\uff08\u5982 JSON\u3001XML\uff09\u8fd4\u56de\u6570\u636e\u7684\u6280\u672f\u3002\u8fd9\u5bf9\u4e8e\u9700\u8981\u7a0b\u5e8f\u89e3\u6790 LLM \u8f93\u51fa\u7684\u573a\u666f\u81f3\u5173\u91cd\u8981\u3002","source":"@site/docs/ai/structured-output.md","sourceDirName":"ai","slug":"/ai/structured-output","permalink":"/docs/ai/structured-output","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ai/structured-output.md","tags":[],"version":"current","sidebarPosition":17,"frontMatter":{"sidebar_position":17,"title":"\ud83d\udcd0 \u7ed3\u6784\u5316\u8f93\u51fa"},"sidebar":"ai","previous":{"title":"\ud83d\udd27 Function Calling","permalink":"/docs/ai/function-calling"},"next":{"title":"\ud83e\udd16 AI Agent (\u667a\u80fd\u4f53)","permalink":"/docs/ai/agent"}}');var r=t(22714),i=t(48885);const o={sidebar_position:17,title:"\ud83d\udcd0 \u7ed3\u6784\u5316\u8f93\u51fa"},l="\u7ed3\u6784\u5316\u8f93\u51fa (Structured Output)",a={},c=[{value:"\u4e3a\u4ec0\u4e48\u9700\u8981\u7ed3\u6784\u5316\u8f93\u51fa\uff1f",id:"\u4e3a\u4ec0\u4e48\u9700\u8981\u7ed3\u6784\u5316\u8f93\u51fa",level:2},{value:"OpenAI JSON Mode",id:"openai-json-mode",level:2},{value:"\u57fa\u7840\u7528\u6cd5",id:"\u57fa\u7840\u7528\u6cd5",level:3},{value:"\u6307\u5b9a JSON Schema",id:"\u6307\u5b9a-json-schema",level:3},{value:"OpenAI Structured Outputs\uff08\u63a8\u8350\uff09",id:"openai-structured-outputs\u63a8\u8350",level:2},{value:"\u4f7f\u7528 Pydantic \u5b9a\u4e49 Schema",id:"\u4f7f\u7528-pydantic-\u5b9a\u4e49-schema",level:3},{value:"\u590d\u6742\u5d4c\u5957\u7ed3\u6784",id:"\u590d\u6742\u5d4c\u5957\u7ed3\u6784",level:3},{value:"Anthropic \u7ed3\u6784\u5316\u8f93\u51fa",id:"anthropic-\u7ed3\u6784\u5316\u8f93\u51fa",level:2},{value:"\u4f7f\u7528 Tool Use \u5b9e\u73b0",id:"\u4f7f\u7528-tool-use-\u5b9e\u73b0",level:3},{value:"LangChain \u7ed3\u6784\u5316\u8f93\u51fa",id:"langchain-\u7ed3\u6784\u5316\u8f93\u51fa",level:2},{value:"\u4f7f\u7528 with_structured_output",id:"\u4f7f\u7528-with_structured_output",level:3},{value:"\u4f7f\u7528 PydanticOutputParser",id:"\u4f7f\u7528-pydanticoutputparser",level:3},{value:"\u5b9e\u6218\u5e94\u7528",id:"\u5b9e\u6218\u5e94\u7528",level:2},{value:"1. \u4fe1\u606f\u62bd\u53d6",id:"1-\u4fe1\u606f\u62bd\u53d6",level:3},{value:"2. \u5206\u7c7b\u4efb\u52a1",id:"2-\u5206\u7c7b\u4efb\u52a1",level:3},{value:"3. \u6570\u636e\u8f6c\u6362",id:"3-\u6570\u636e\u8f6c\u6362",level:3},{value:"4. API \u54cd\u5e94\u683c\u5f0f\u5316",id:"4-api-\u54cd\u5e94\u683c\u5f0f\u5316",level:3},{value:"\u9519\u8bef\u5904\u7406",id:"\u9519\u8bef\u5904\u7406",level:2},{value:"\u6700\u4f73\u5b9e\u8df5",id:"\u6700\u4f73\u5b9e\u8df5",level:2},{value:"\u5ef6\u4f38\u9605\u8bfb",id:"\u5ef6\u4f38\u9605\u8bfb",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"\u7ed3\u6784\u5316\u8f93\u51fa-structured-output",children:"\u7ed3\u6784\u5316\u8f93\u51fa (Structured Output)"})}),"\n",(0,r.jsx)(e.p,{children:"\u7ed3\u6784\u5316\u8f93\u51fa\u662f\u8ba9 LLM \u6309\u7167\u6307\u5b9a\u7684\u683c\u5f0f\uff08\u5982 JSON\u3001XML\uff09\u8fd4\u56de\u6570\u636e\u7684\u6280\u672f\u3002\u8fd9\u5bf9\u4e8e\u9700\u8981\u7a0b\u5e8f\u89e3\u6790 LLM \u8f93\u51fa\u7684\u573a\u666f\u81f3\u5173\u91cd\u8981\u3002"}),"\n",(0,r.jsx)(e.h2,{id:"\u4e3a\u4ec0\u4e48\u9700\u8981\u7ed3\u6784\u5316\u8f93\u51fa",children:"\u4e3a\u4ec0\u4e48\u9700\u8981\u7ed3\u6784\u5316\u8f93\u51fa\uff1f"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"\u95ee\u9898"}),(0,r.jsx)(e.th,{children:"\u8bf4\u660e"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"\u89e3\u6790\u56f0\u96be"})}),(0,r.jsx)(e.td,{children:"\u81ea\u7531\u6587\u672c\u96be\u4ee5\u53ef\u9760\u5730\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"\u683c\u5f0f\u4e0d\u7a33\u5b9a"})}),(0,r.jsx)(e.td,{children:"\u540c\u6837\u7684 prompt \u53ef\u80fd\u8fd4\u56de\u4e0d\u540c\u683c\u5f0f"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"\u7c7b\u578b\u4e0d\u5b89\u5168"})}),(0,r.jsx)(e.td,{children:"\u65e0\u6cd5\u4fdd\u8bc1\u5b57\u6bb5\u7c7b\u578b\u6b63\u786e"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"\u7f3a\u5931\u5b57\u6bb5"})}),(0,r.jsx)(e.td,{children:"\u6a21\u578b\u53ef\u80fd\u9057\u6f0f\u5fc5\u8981\u5b57\u6bb5"})]})]})]}),"\n",(0,r.jsx)(e.h2,{id:"openai-json-mode",children:"OpenAI JSON Mode"}),"\n",(0,r.jsx)(e.h3,{id:"\u57fa\u7840\u7528\u6cd5",children:"\u57fa\u7840\u7528\u6cd5"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n    model="gpt-4o",\n    messages=[\n        {\n            "role": "system",\n            "content": "\u4f60\u662f\u4e00\u4e2a\u6570\u636e\u63d0\u53d6\u52a9\u624b\u3002\u8bf7\u4ee5 JSON \u683c\u5f0f\u8fd4\u56de\u7ed3\u679c\u3002"\n        },\n        {\n            "role": "user",\n            "content": "\u63d0\u53d6\u4ee5\u4e0b\u6587\u672c\u4e2d\u7684\u4eba\u7269\u4fe1\u606f\uff1a\u5f20\u4e09\uff0c\u7537\uff0c30\u5c81\uff0c\u5317\u4eac\u4eba\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08"\n        }\n    ],\n    response_format={"type": "json_object"}\n)\n\nimport json\ndata = json.loads(response.choices[0].message.content)\nprint(data)\n# {"name": "\u5f20\u4e09", "gender": "\u7537", "age": 30, "city": "\u5317\u4eac", "occupation": "\u8f6f\u4ef6\u5de5\u7a0b\u5e08"}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\u6307\u5b9a-json-schema",children:"\u6307\u5b9a JSON Schema"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'response = client.chat.completions.create(\n    model="gpt-4o",\n    messages=[\n        {\n            "role": "system",\n            "content": """\u63d0\u53d6\u4eba\u7269\u4fe1\u606f\uff0c\u4e25\u683c\u6309\u7167\u4ee5\u4e0b JSON Schema \u8fd4\u56de\uff1a\n{\n  "name": "string",\n  "age": "number",\n  "city": "string",\n  "skills": ["string"]\n}"""\n        },\n        {"role": "user", "content": "\u674e\u56db\uff0c25\u5c81\uff0c\u4e0a\u6d77\uff0c\u4f1a Python \u548c Java"}\n    ],\n    response_format={"type": "json_object"}\n)\n'})}),"\n",(0,r.jsx)(e.h2,{id:"openai-structured-outputs\u63a8\u8350",children:"OpenAI Structured Outputs\uff08\u63a8\u8350\uff09"}),"\n",(0,r.jsx)(e.p,{children:"OpenAI \u7684 Structured Outputs \u529f\u80fd\u53ef\u4ee5\u4fdd\u8bc1\u8f93\u51fa\u4e25\u683c\u7b26\u5408\u6307\u5b9a\u7684 JSON Schema\u3002"}),"\n",(0,r.jsx)(e.h3,{id:"\u4f7f\u7528-pydantic-\u5b9a\u4e49-schema",children:"\u4f7f\u7528 Pydantic \u5b9a\u4e49 Schema"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from openai import OpenAI\nfrom pydantic import BaseModel\nfrom typing import List, Optional\n\nclient = OpenAI()\n\n# \u5b9a\u4e49\u6570\u636e\u6a21\u578b\nclass Person(BaseModel):\n    name: str\n    age: int\n    city: str\n    skills: List[str]\n    email: Optional[str] = None\n\nclass ExtractionResult(BaseModel):\n    people: List[Person]\n    summary: str\n\n# \u4f7f\u7528 parse \u65b9\u6cd5\ncompletion = client.beta.chat.completions.parse(\n    model="gpt-4o",\n    messages=[\n        {"role": "system", "content": "\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u4eba\u7269\u4fe1\u606f"},\n        {"role": "user", "content": "\u5f20\u4e0930\u5c81\u5728\u5317\u4eac\u4f1aPython\uff1b\u674e\u56db25\u5c81\u5728\u4e0a\u6d77\u4f1aJava\u548cGo"}\n    ],\n    response_format=ExtractionResult\n)\n\nresult = completion.choices[0].message.parsed\nprint(result.people[0].name)  # \u5f20\u4e09\nprint(result.summary)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\u590d\u6742\u5d4c\u5957\u7ed3\u6784",children:"\u590d\u6742\u5d4c\u5957\u7ed3\u6784"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from pydantic import BaseModel, Field\nfrom typing import List, Literal\nfrom enum import Enum\n\nclass Priority(str, Enum):\n    LOW = "low"\n    MEDIUM = "medium"\n    HIGH = "high"\n\nclass Task(BaseModel):\n    title: str = Field(description="\u4efb\u52a1\u6807\u9898")\n    description: str = Field(description="\u4efb\u52a1\u63cf\u8ff0")\n    priority: Priority = Field(description="\u4f18\u5148\u7ea7")\n    estimated_hours: float = Field(ge=0, le=100, description="\u9884\u4f30\u5de5\u65f6")\n\nclass ProjectPlan(BaseModel):\n    project_name: str\n    tasks: List[Task]\n    total_hours: float\n    risks: List[str]\n\ncompletion = client.beta.chat.completions.parse(\n    model="gpt-4o",\n    messages=[\n        {"role": "system", "content": "\u4f60\u662f\u9879\u76ee\u89c4\u5212\u52a9\u624b"},\n        {"role": "user", "content": "\u5e2e\u6211\u89c4\u5212\u4e00\u4e2a\u7535\u5546\u7f51\u7ad9\u9879\u76ee\uff0c\u5305\u542b\u7528\u6237\u7cfb\u7edf\u3001\u5546\u54c1\u7ba1\u7406\u3001\u8ba2\u5355\u7cfb\u7edf"}\n    ],\n    response_format=ProjectPlan\n)\n\nplan = completion.choices[0].message.parsed\nfor task in plan.tasks:\n    print(f"[{task.priority.value}] {task.title}: {task.estimated_hours}h")\n'})}),"\n",(0,r.jsx)(e.h2,{id:"anthropic-\u7ed3\u6784\u5316\u8f93\u51fa",children:"Anthropic \u7ed3\u6784\u5316\u8f93\u51fa"}),"\n",(0,r.jsx)(e.h3,{id:"\u4f7f\u7528-tool-use-\u5b9e\u73b0",children:"\u4f7f\u7528 Tool Use \u5b9e\u73b0"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import anthropic\nimport json\n\nclient = anthropic.Anthropic()\n\n# \u5b9a\u4e49\u5de5\u5177\u4f5c\u4e3a\u8f93\u51fa\u683c\u5f0f\ntools = [\n    {\n        "name": "extract_person",\n        "description": "\u63d0\u53d6\u4eba\u7269\u4fe1\u606f",\n        "input_schema": {\n            "type": "object",\n            "properties": {\n                "name": {"type": "string", "description": "\u59d3\u540d"},\n                "age": {"type": "integer", "description": "\u5e74\u9f84"},\n                "city": {"type": "string", "description": "\u57ce\u5e02"},\n                "occupation": {"type": "string", "description": "\u804c\u4e1a"}\n            },\n            "required": ["name", "age", "city"]\n        }\n    }\n]\n\nmessage = client.messages.create(\n    model="claude-3-5-sonnet-20241022",\n    max_tokens=1024,\n    tools=tools,\n    tool_choice={"type": "tool", "name": "extract_person"},  # \u5f3a\u5236\u4f7f\u7528\u5de5\u5177\n    messages=[\n        {"role": "user", "content": "\u63d0\u53d6\u4fe1\u606f\uff1a\u738b\u4e94\uff0c28\u5c81\uff0c\u6df1\u5733\uff0c\u4ea7\u54c1\u7ecf\u7406"}\n    ]\n)\n\n# \u83b7\u53d6\u7ed3\u6784\u5316\u8f93\u51fa\ntool_use = next(block for block in message.content if block.type == "tool_use")\nresult = tool_use.input\nprint(result)\n# {"name": "\u738b\u4e94", "age": 28, "city": "\u6df1\u5733", "occupation": "\u4ea7\u54c1\u7ecf\u7406"}\n'})}),"\n",(0,r.jsx)(e.h2,{id:"langchain-\u7ed3\u6784\u5316\u8f93\u51fa",children:"LangChain \u7ed3\u6784\u5316\u8f93\u51fa"}),"\n",(0,r.jsx)(e.h3,{id:"\u4f7f\u7528-with_structured_output",children:"\u4f7f\u7528 with_structured_output"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass MovieReview(BaseModel):\n    """\u7535\u5f71\u8bc4\u8bba\u5206\u6790\u7ed3\u679c"""\n    movie_name: str = Field(description="\u7535\u5f71\u540d\u79f0")\n    sentiment: str = Field(description="\u60c5\u611f\u503e\u5411\uff1apositive/negative/neutral")\n    score: float = Field(ge=0, le=10, description="\u8bc4\u5206")\n    keywords: List[str] = Field(description="\u5173\u952e\u8bcd")\n    summary: str = Field(description="\u4e00\u53e5\u8bdd\u603b\u7ed3")\n\nllm = ChatOpenAI(model="gpt-4o", temperature=0)\nstructured_llm = llm.with_structured_output(MovieReview)\n\nresult = structured_llm.invoke("\u8fd9\u90e8\u7535\u5f71\u592a\u7cbe\u5f69\u4e86\uff01\u5267\u60c5\u7d27\u51d1\uff0c\u6f14\u5458\u6f14\u6280\u5728\u7ebf\uff0c\u7279\u6548\u9707\u64bc\uff0c\u5f3a\u70c8\u63a8\u8350\uff01")\nprint(f"\u60c5\u611f: {result.sentiment}, \u8bc4\u5206: {result.score}")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\u4f7f\u7528-pydanticoutputparser",children:"\u4f7f\u7528 PydanticOutputParser"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain_core.output_parsers import PydanticOutputParser\nfrom langchain_core.prompts import PromptTemplate\n\nparser = PydanticOutputParser(pydantic_object=MovieReview)\n\nprompt = PromptTemplate(\n    template="\u5206\u6790\u4ee5\u4e0b\u7535\u5f71\u8bc4\u8bba\uff1a\\n{review}\\n\\n{format_instructions}",\n    input_variables=["review"],\n    partial_variables={"format_instructions": parser.get_format_instructions()}\n)\n\nchain = prompt | llm | parser\n\nresult = chain.invoke({"review": "\u5267\u60c5\u62d6\u6c93\uff0c\u6f14\u6280\u5c34\u5c2c\uff0c\u6d6a\u8d39\u65f6\u95f4"})\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u5b9e\u6218\u5e94\u7528",children:"\u5b9e\u6218\u5e94\u7528"}),"\n",(0,r.jsx)(e.h3,{id:"1-\u4fe1\u606f\u62bd\u53d6",children:"1. \u4fe1\u606f\u62bd\u53d6"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from pydantic import BaseModel\nfrom typing import List, Optional\n\nclass ContactInfo(BaseModel):\n    name: str\n    phone: Optional[str] = None\n    email: Optional[str] = None\n    company: Optional[str] = None\n    position: Optional[str] = None\n\nclass ExtractionResult(BaseModel):\n    contacts: List[ContactInfo]\n    raw_text: str\n\ndef extract_contacts(text: str) -> ExtractionResult:\n    completion = client.beta.chat.completions.parse(\n        model="gpt-4o",\n        messages=[\n            {"role": "system", "content": "\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u8054\u7cfb\u4eba\u4fe1\u606f"},\n            {"role": "user", "content": text}\n        ],\n        response_format=ExtractionResult\n    )\n    return completion.choices[0].message.parsed\n\n# \u4f7f\u7528\ntext = """\n\u8bf7\u8054\u7cfb\u5f20\u7ecf\u7406\uff08\u624b\u673a\uff1a13800138000\uff0c\u90ae\u7bb1\uff1azhang@example.com\uff09\n\u6216\u8005\u674e\u603b\uff08ABC\u516c\u53f8CEO\uff0c\u7535\u8bdd\uff1a13900139000\uff09\n"""\nresult = extract_contacts(text)\nfor contact in result.contacts:\n    print(f"{contact.name}: {contact.phone}")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-\u5206\u7c7b\u4efb\u52a1",children:"2. \u5206\u7c7b\u4efb\u52a1"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from pydantic import BaseModel\nfrom typing import Literal, List\n\nclass ClassificationResult(BaseModel):\n    category: Literal["bug", "feature", "question", "other"]\n    confidence: float\n    reasoning: str\n    suggested_labels: List[str]\n\ndef classify_issue(title: str, description: str) -> ClassificationResult:\n    completion = client.beta.chat.completions.parse(\n        model="gpt-4o",\n        messages=[\n            {"role": "system", "content": "\u5bf9 GitHub Issue \u8fdb\u884c\u5206\u7c7b"},\n            {"role": "user", "content": f"\u6807\u9898: {title}\\n\u63cf\u8ff0: {description}"}\n        ],\n        response_format=ClassificationResult\n    )\n    return completion.choices[0].message.parsed\n\n# \u4f7f\u7528\nresult = classify_issue(\n    "\u767b\u5f55\u6309\u94ae\u70b9\u51fb\u65e0\u54cd\u5e94",\n    "\u5728 Chrome \u6d4f\u89c8\u5668\u4e0a\u70b9\u51fb\u767b\u5f55\u6309\u94ae\u6ca1\u6709\u4efb\u4f55\u53cd\u5e94\uff0c\u63a7\u5236\u53f0\u663e\u793a TypeError"\n)\nprint(f"\u5206\u7c7b: {result.category}, \u7f6e\u4fe1\u5ea6: {result.confidence}")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"3-\u6570\u636e\u8f6c\u6362",children:"3. \u6570\u636e\u8f6c\u6362"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from pydantic import BaseModel\nfrom typing import List\n\nclass TableRow(BaseModel):\n    date: str\n    product: str\n    quantity: int\n    price: float\n    total: float\n\nclass TableData(BaseModel):\n    headers: List[str]\n    rows: List[TableRow]\n\ndef text_to_table(text: str) -> TableData:\n    """\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u8f6c\u6362\u4e3a\u8868\u683c\u6570\u636e"""\n    completion = client.beta.chat.completions.parse(\n        model="gpt-4o",\n        messages=[\n            {"role": "system", "content": "\u5c06\u6587\u672c\u4e2d\u7684\u6570\u636e\u8f6c\u6362\u4e3a\u8868\u683c\u683c\u5f0f"},\n            {"role": "user", "content": text}\n        ],\n        response_format=TableData\n    )\n    return completion.choices[0].message.parsed\n\n# \u4f7f\u7528\ntext = """\n1\u67085\u65e5\u5356\u4e8610\u4e2a\u82f9\u679c\uff0c\u5355\u4ef75\u5143\uff1b\n1\u67086\u65e5\u5356\u4e8620\u4e2a\u6a59\u5b50\uff0c\u5355\u4ef73\u5143\uff1b\n1\u67087\u65e5\u5356\u4e8615\u4e2a\u9999\u8549\uff0c\u5355\u4ef72\u5143\u3002\n"""\ntable = text_to_table(text)\nfor row in table.rows:\n    print(f"{row.date}: {row.product} x {row.quantity} = {row.total}")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"4-api-\u54cd\u5e94\u683c\u5f0f\u5316",children:"4. API \u54cd\u5e94\u683c\u5f0f\u5316"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from pydantic import BaseModel\nfrom typing import List, Optional, Generic, TypeVar\nfrom datetime import datetime\n\nT = TypeVar(\'T\')\n\nclass APIResponse(BaseModel, Generic[T]):\n    success: bool\n    data: Optional[T] = None\n    error: Optional[str] = None\n    timestamp: str\n\nclass UserProfile(BaseModel):\n    id: int\n    username: str\n    email: str\n    created_at: str\n\ndef generate_api_response(query: str) -> APIResponse[UserProfile]:\n    """\u751f\u6210\u7b26\u5408 API \u89c4\u8303\u7684\u54cd\u5e94"""\n    completion = client.beta.chat.completions.parse(\n        model="gpt-4o",\n        messages=[\n            {"role": "system", "content": "\u751f\u6210\u6a21\u62df\u7684\u7528\u6237\u6570\u636e API \u54cd\u5e94"},\n            {"role": "user", "content": query}\n        ],\n        response_format=APIResponse[UserProfile]\n    )\n    return completion.choices[0].message.parsed\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u9519\u8bef\u5904\u7406",children:"\u9519\u8bef\u5904\u7406"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from openai import OpenAI\nfrom pydantic import BaseModel, ValidationError\n\nclient = OpenAI()\n\nclass Output(BaseModel):\n    name: str\n    age: int\n\ndef safe_parse(text: str) -> Output | None:\n    try:\n        completion = client.beta.chat.completions.parse(\n            model="gpt-4o",\n            messages=[{"role": "user", "content": text}],\n            response_format=Output\n        )\n        \n        # \u68c0\u67e5\u662f\u5426\u6709 refusal\n        if completion.choices[0].message.refusal:\n            print(f"\u6a21\u578b\u62d2\u7edd: {completion.choices[0].message.refusal}")\n            return None\n        \n        return completion.choices[0].message.parsed\n        \n    except ValidationError as e:\n        print(f"\u9a8c\u8bc1\u9519\u8bef: {e}")\n        return None\n    except Exception as e:\n        print(f"\u5176\u4ed6\u9519\u8bef: {e}")\n        return None\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u6700\u4f73\u5b9e\u8df5",children:"\u6700\u4f73\u5b9e\u8df5"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Schema \u8bbe\u8ba1"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u4f7f\u7528 Pydantic \u7684 Field \u6dfb\u52a0\u63cf\u8ff0"}),"\n",(0,r.jsx)(e.li,{children:"\u8bbe\u7f6e\u5408\u7406\u7684\u7ea6\u675f\uff08ge\u3001le\u3001max_length \u7b49\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u4f7f\u7528 Optional \u6807\u8bb0\u53ef\u9009\u5b57\u6bb5"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Prompt \u4f18\u5316"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5728 system prompt \u4e2d\u8bf4\u660e\u8f93\u51fa\u683c\u5f0f\u8981\u6c42"}),"\n",(0,r.jsx)(e.li,{children:"\u63d0\u4f9b\u793a\u4f8b\u5e2e\u52a9\u6a21\u578b\u7406\u89e3"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u9519\u8bef\u5904\u7406"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5904\u7406 refusal \u60c5\u51b5"}),"\n",(0,r.jsx)(e.li,{children:"\u6dfb\u52a0\u91cd\u8bd5\u903b\u8f91"}),"\n",(0,r.jsx)(e.li,{children:"\u9a8c\u8bc1\u8f93\u51fa\u6570\u636e"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u6027\u80fd\u8003\u8651"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u7ed3\u6784\u5316\u8f93\u51fa\u53ef\u80fd\u589e\u52a0\u5ef6\u8fdf"}),"\n",(0,r.jsx)(e.li,{children:"\u590d\u6742 Schema \u53ef\u80fd\u5f71\u54cd\u51c6\u786e\u6027"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"\u5ef6\u4f38\u9605\u8bfb",children:"\u5ef6\u4f38\u9605\u8bfb"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://platform.openai.com/docs/guides/structured-outputs",children:"OpenAI Structured Outputs"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://python.langchain.com/docs/modules/model_io/output_parsers/",children:"LangChain Output Parsers"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://docs.pydantic.dev/",children:"Pydantic \u6587\u6863"})}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}}}]);