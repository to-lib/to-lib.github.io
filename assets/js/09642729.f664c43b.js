"use strict";(globalThis.webpackChunkto_lib_github_io=globalThis.webpackChunkto_lib_github_io||[]).push([[90306],{48885:(n,e,s)=>{s.d(e,{R:()=>a,x:()=>d});var t=s(99378);const r={},i=t.createContext(r);function a(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function d(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:a(n.components),t.createElement(i.Provider,{value:e},n.children)}},65966:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>l,contentTitle:()=>d,default:()=>c,frontMatter:()=>a,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"ml/multi-task-learning","title":"\ud83c\udfaf \u591a\u4efb\u52a1\u5b66\u4e60","description":"\u591a\u4efb\u52a1\u5b66\u4e60\u540c\u65f6\u5b66\u4e60\u591a\u4e2a\u76f8\u5173\u4efb\u52a1\uff0c\u901a\u8fc7\u5171\u4eab\u8868\u793a\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002","source":"@site/docs/ml/multi-task-learning.md","sourceDirName":"ml","slug":"/ml/multi-task-learning","permalink":"/docs/ml/multi-task-learning","draft":false,"unlisted":false,"editUrl":"https://github.com/to-lib/to-lib.github.io/tree/main/docs/ml/multi-task-learning.md","tags":[],"version":"current","sidebarPosition":27,"frontMatter":{"sidebar_position":27,"title":"\ud83c\udfaf \u591a\u4efb\u52a1\u5b66\u4e60"},"sidebar":"ml","previous":{"title":"\ud83d\udd04 \u5bf9\u6bd4\u5b66\u4e60","permalink":"/docs/ml/contrastive-learning"},"next":{"title":"\ud83e\uddec \u5143\u5b66\u4e60","permalink":"/docs/ml/meta-learning"}}');var r=s(22714),i=s(48885);const a={sidebar_position:27,title:"\ud83c\udfaf \u591a\u4efb\u52a1\u5b66\u4e60"},d="\u591a\u4efb\u52a1\u5b66\u4e60",l={},o=[{value:"\u6838\u5fc3\u601d\u60f3",id:"\u6838\u5fc3\u601d\u60f3",level:2},{value:"\u786c\u53c2\u6570\u5171\u4eab",id:"\u786c\u53c2\u6570\u5171\u4eab",level:2},{value:"\u8f6f\u53c2\u6570\u5171\u4eab",id:"\u8f6f\u53c2\u6570\u5171\u4eab",level:2},{value:"\u635f\u5931\u51fd\u6570\u6743\u91cd",id:"\u635f\u5931\u51fd\u6570\u6743\u91cd",level:2},{value:"\u5e94\u7528\u573a\u666f",id:"\u5e94\u7528\u573a\u666f",level:2}];function h(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",mermaid:"mermaid",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"\u591a\u4efb\u52a1\u5b66\u4e60",children:"\u591a\u4efb\u52a1\u5b66\u4e60"})}),"\n",(0,r.jsx)(e.p,{children:"\u591a\u4efb\u52a1\u5b66\u4e60\u540c\u65f6\u5b66\u4e60\u591a\u4e2a\u76f8\u5173\u4efb\u52a1\uff0c\u901a\u8fc7\u5171\u4eab\u8868\u793a\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002"}),"\n",(0,r.jsx)(e.h2,{id:"\u6838\u5fc3\u601d\u60f3",children:"\u6838\u5fc3\u601d\u60f3"}),"\n",(0,r.jsx)(e.mermaid,{value:"graph TB\n    A[\u8f93\u5165] --\x3e B[\u5171\u4eab\u5c42]\n    B --\x3e C[\u4efb\u52a11\u5934]\n    B --\x3e D[\u4efb\u52a12\u5934]\n    B --\x3e E[\u4efb\u52a13\u5934]\n    C --\x3e F[\u8f93\u51fa1]\n    D --\x3e G[\u8f93\u51fa2]\n    E --\x3e H[\u8f93\u51fa3]"}),"\n",(0,r.jsx)(e.h2,{id:"\u786c\u53c2\u6570\u5171\u4eab",children:"\u786c\u53c2\u6570\u5171\u4eab"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import torch.nn as nn\n\nclass HardSharingMTL(nn.Module):\n    def __init__(self, input_dim, shared_dim, task_dims):\n        super().__init__()\n        # \u5171\u4eab\u5c42\n        self.shared = nn.Sequential(\n            nn.Linear(input_dim, shared_dim),\n            nn.ReLU(),\n            nn.Linear(shared_dim, shared_dim),\n            nn.ReLU()\n        )\n\n        # \u4efb\u52a1\u7279\u5b9a\u5c42\n        self.task_heads = nn.ModuleList([\n            nn.Linear(shared_dim, dim) for dim in task_dims\n        ])\n\n    def forward(self, x):\n        shared_repr = self.shared(x)\n        outputs = [head(shared_repr) for head in self.task_heads]\n        return outputs\n"})}),"\n",(0,r.jsx)(e.h2,{id:"\u8f6f\u53c2\u6570\u5171\u4eab",children:"\u8f6f\u53c2\u6570\u5171\u4eab"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class SoftSharingMTL(nn.Module):\n    def __init__(self, input_dim, hidden_dim, task_dims):\n        super().__init__()\n        # \u6bcf\u4e2a\u4efb\u52a1\u6709\u72ec\u7acb\u7684\u7f51\u7edc\n        self.task_networks = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, dim)\n            ) for dim in task_dims\n        ])\n\n    def forward(self, x):\n        return [net(x) for net in self.task_networks]\n\n    def regularization_loss(self):\n        # \u9f13\u52b1\u53c2\u6570\u76f8\u4f3c\n        reg = 0\n        for i in range(len(self.task_networks)):\n            for j in range(i + 1, len(self.task_networks)):\n                for p1, p2 in zip(self.task_networks[i].parameters(),\n                                  self.task_networks[j].parameters()):\n                    reg += torch.norm(p1 - p2, p=2)\n        return reg\n"})}),"\n",(0,r.jsx)(e.h2,{id:"\u635f\u5931\u51fd\u6570\u6743\u91cd",children:"\u635f\u5931\u51fd\u6570\u6743\u91cd"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# \u9759\u6001\u6743\u91cd\ndef static_weighted_loss(losses, weights):\n    return sum(w * l for w, l in zip(weights, losses))\n\n# \u4e0d\u786e\u5b9a\u6027\u6743\u91cd (Uncertainty Weighting)\nclass UncertaintyWeighting(nn.Module):\n    def __init__(self, num_tasks):\n        super().__init__()\n        self.log_vars = nn.Parameter(torch.zeros(num_tasks))\n\n    def forward(self, losses):\n        weighted = 0\n        for i, loss in enumerate(losses):\n            precision = torch.exp(-self.log_vars[i])\n            weighted += precision * loss + self.log_vars[i]\n        return weighted\n\n# GradNorm\nclass GradNorm:\n    def __init__(self, model, alpha=1.5):\n        self.weights = nn.Parameter(torch.ones(num_tasks))\n        self.alpha = alpha\n\n    def update_weights(self, losses, shared_params):\n        # \u8ba1\u7b97\u6bcf\u4e2a\u4efb\u52a1\u7684\u68af\u5ea6\u8303\u6570\n        grads = []\n        for loss in losses:\n            grad = torch.autograd.grad(loss, shared_params, retain_graph=True)\n            grads.append(torch.norm(torch.cat([g.flatten() for g in grad])))\n        # \u6839\u636e\u8bad\u7ec3\u901f\u5ea6\u8c03\u6574\u6743\u91cd\n        ...\n"})}),"\n",(0,r.jsx)(e.h2,{id:"\u5e94\u7528\u573a\u666f",children:"\u5e94\u7528\u573a\u666f"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"\u573a\u666f"}),(0,r.jsx)(e.th,{children:"\u4efb\u52a1\u7ec4\u5408"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u81ea\u52a8\u9a7e\u9a76"}),(0,r.jsx)(e.td,{children:"\u76ee\u6807\u68c0\u6d4b + \u8bed\u4e49\u5206\u5272 + \u6df1\u5ea6\u4f30\u8ba1"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u63a8\u8350\u7cfb\u7edf"}),(0,r.jsx)(e.td,{children:"\u70b9\u51fb\u9884\u6d4b + \u8f6c\u5316\u9884\u6d4b + \u65f6\u957f\u9884\u6d4b"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"NLP"}),(0,r.jsx)(e.td,{children:"\u60c5\u611f\u5206\u6790 + \u5b9e\u4f53\u8bc6\u522b + \u5173\u7cfb\u62bd\u53d6"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"CV"}),(0,r.jsx)(e.td,{children:"\u4eba\u8138\u68c0\u6d4b + \u5173\u952e\u70b9 + \u5c5e\u6027\u8bc6\u522b"})]})]})]})]})}function c(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(h,{...n})}):h(n)}}}]);