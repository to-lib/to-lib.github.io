---
sidebar_position: 10
title: "çŠ¶æ€ç®¡ç†"
description: "Flink çŠ¶æ€ç®¡ç†ä¸å®¹é”™æœºåˆ¶è¯¦è§£"
---

# Flink çŠ¶æ€ç®¡ç†

## æ¦‚è¿°

çŠ¶æ€ç®¡ç†æ˜¯ Flink çš„æ ¸å¿ƒèƒ½åŠ›ä¹‹ä¸€ï¼Œä½¿å¾— Flink èƒ½å¤Ÿå¤„ç†å¤æ‚çš„æœ‰çŠ¶æ€è®¡ç®—ï¼Œå¦‚èšåˆã€çª—å£ã€æœºå™¨å­¦ä¹ æ¨¡å‹ç­‰ã€‚

## çŠ¶æ€ç±»å‹

### Keyed State

åŸºäº KeyedStream çš„çŠ¶æ€ï¼Œæ¯ä¸ª Key ç»´æŠ¤ç‹¬ç«‹çš„çŠ¶æ€ï¼š

```java
public class CountFunction extends RichFlatMapFunction<Event, Result> {
    // å£°æ˜çŠ¶æ€
    private ValueState<Long> countState;

    @Override
    public void open(Configuration parameters) {
        // åˆ›å»ºçŠ¶æ€æè¿°ç¬¦
        ValueStateDescriptor<Long> descriptor =
            new ValueStateDescriptor<>("count", Long.class);
        // è·å–çŠ¶æ€
        countState = getRuntimeContext().getState(descriptor);
    }

    @Override
    public void flatMap(Event event, Collector<Result> out) throws Exception {
        Long count = countState.value();
        count = count == null ? 1L : count + 1;
        countState.update(count);
        out.collect(new Result(event.getKey(), count));
    }
}
```

### Keyed State ç±»å‹

| çŠ¶æ€ç±»å‹                        | æè¿°                          | é€‚ç”¨åœºæ™¯           |
| ------------------------------- | ----------------------------- | ------------------ |
| **ValueState\<T\>**             | å•ä¸ªå€¼                        | è®¡æ•°å™¨ã€ç´¯åŠ å™¨     |
| **ListState\<T\>**              | å…ƒç´ åˆ—è¡¨                      | äº‹ä»¶ç¼“å­˜ã€å†å²è®°å½• |
| **MapState\<K, V\>**            | é”®å€¼å¯¹æ˜ å°„                    | ç´¢å¼•ã€æŸ¥æ‰¾è¡¨       |
| **ReducingState\<T\>**          | èšåˆå€¼ï¼ˆéœ€è¦ ReduceFunctionï¼‰ | æ±‚å’Œã€æ±‚æœ€å¤§å€¼     |
| **AggregatingState\<IN, OUT\>** | å¤æ‚èšåˆ                      | å¹³å‡å€¼ã€è‡ªå®šä¹‰èšåˆ |

### ListState ç¤ºä¾‹

```java
private ListState<Event> eventBuffer;

@Override
public void open(Configuration parameters) {
    ListStateDescriptor<Event> descriptor =
        new ListStateDescriptor<>("events", Event.class);
    eventBuffer = getRuntimeContext().getListState(descriptor);
}

@Override
public void processElement(Event event, Context ctx, Collector<Result> out)
        throws Exception {
    eventBuffer.add(event);

    // æ‰¹é‡å¤„ç†
    if (shouldFlush()) {
        for (Event e : eventBuffer.get()) {
            out.collect(process(e));
        }
        eventBuffer.clear();
    }
}
```

### MapState ç¤ºä¾‹

```java
private MapState<String, Integer> wordCounts;

@Override
public void open(Configuration parameters) {
    MapStateDescriptor<String, Integer> descriptor =
        new MapStateDescriptor<>("wordCounts", String.class, Integer.class);
    wordCounts = getRuntimeContext().getMapState(descriptor);
}

@Override
public void processElement(String word, Context ctx, Collector<Result> out)
        throws Exception {
    Integer count = wordCounts.get(word);
    count = count == null ? 1 : count + 1;
    wordCounts.put(word, count);
    out.collect(new Result(word, count));
}
```

### Operator State

ç®—å­çº§åˆ«çš„çŠ¶æ€ï¼Œä¸æŒ‰ Key åˆ†åŒºï¼š

```java
public class BufferingSink implements SinkFunction<Event>,
        CheckpointedFunction {

    private List<Event> bufferedElements;
    private ListState<Event> checkpointedState;

    @Override
    public void snapshotState(FunctionSnapshotContext context) throws Exception {
        checkpointedState.clear();
        for (Event element : bufferedElements) {
            checkpointedState.add(element);
        }
    }

    @Override
    public void initializeState(FunctionInitializationContext context)
            throws Exception {
        ListStateDescriptor<Event> descriptor =
            new ListStateDescriptor<>("buffered-elements", Event.class);

        checkpointedState = context.getOperatorStateStore()
            .getListState(descriptor);

        if (context.isRestored()) {
            for (Event element : checkpointedState.get()) {
                bufferedElements.add(element);
            }
        }
    }
}
```

## çŠ¶æ€åç«¯

### HashMapStateBackend

å°†çŠ¶æ€ä¿å­˜åœ¨ TaskManager çš„ JVM å †å†…å­˜ä¸­ï¼š

```java
env.setStateBackend(new HashMapStateBackend());
env.getCheckpointConfig().setCheckpointStorage("file:///checkpoints");
```

**ç‰¹ç‚¹**ï¼š

- âœ… è®¿é—®é€Ÿåº¦å¿«
- âŒ çŠ¶æ€å¤§å°å—é™äºå†…å­˜
- é€‚ç”¨äºï¼šå°çŠ¶æ€ã€å¼€å‘æµ‹è¯•

### EmbeddedRocksDBStateBackend

å°†çŠ¶æ€ä¿å­˜åœ¨ RocksDB ä¸­ï¼š

```java
env.setStateBackend(new EmbeddedRocksDBStateBackend());
env.getCheckpointConfig().setCheckpointStorage("hdfs:///checkpoints");
```

**ç‰¹ç‚¹**ï¼š

- âœ… æ”¯æŒè¶…å¤§çŠ¶æ€ï¼ˆTB çº§ï¼‰
- âœ… æ”¯æŒå¢é‡æ£€æŸ¥ç‚¹
- âŒ è®¿é—®é€Ÿåº¦è¾ƒæ…¢
- é€‚ç”¨äºï¼šå¤§çŠ¶æ€ã€ç”Ÿäº§ç¯å¢ƒ

### RocksDB é…ç½®ä¼˜åŒ–

```java
EmbeddedRocksDBStateBackend rocksdb = new EmbeddedRocksDBStateBackend();
rocksdb.setDbStoragePath("/data/rocksdb");
rocksdb.setPredefinedOptions(PredefinedOptions.SPINNING_DISK_OPTIMIZED);
env.setStateBackend(rocksdb);
```

## æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰

### é…ç½®æ£€æŸ¥ç‚¹

```java
// å¯ç”¨æ£€æŸ¥ç‚¹ï¼Œé—´éš” 5 åˆ†é’Ÿ
env.enableCheckpointing(300000);

// ç²¾ç¡®ä¸€æ¬¡è¯­ä¹‰
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

// æ£€æŸ¥ç‚¹è¶…æ—¶æ—¶é—´
env.getCheckpointConfig().setCheckpointTimeout(600000);

// æ£€æŸ¥ç‚¹ä¹‹é—´æœ€å°é—´éš”
env.getCheckpointConfig().setMinPauseBetweenCheckpoints(60000);

// æœ€å¤§åŒæ—¶è¿›è¡Œçš„æ£€æŸ¥ç‚¹æ•°é‡
env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);

// ä½œä¸šå–æ¶ˆæ—¶ä¿ç•™æ£€æŸ¥ç‚¹
env.getCheckpointConfig().setExternalizedCheckpointCleanup(
    ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);
```

### æ£€æŸ¥ç‚¹å­˜å‚¨

```java
// æ–‡ä»¶ç³»ç»Ÿ
env.getCheckpointConfig().setCheckpointStorage("file:///checkpoints");

// HDFS
env.getCheckpointConfig().setCheckpointStorage("hdfs:///flink/checkpoints");

// S3
env.getCheckpointConfig().setCheckpointStorage("s3://bucket/checkpoints");
```

## ä¿å­˜ç‚¹ï¼ˆSavepointï¼‰

### è§¦å‘ä¿å­˜ç‚¹

```bash
# è§¦å‘ä¿å­˜ç‚¹
flink savepoint <jobId> hdfs:///savepoints

# å–æ¶ˆä½œä¸šå¹¶åˆ›å»ºä¿å­˜ç‚¹
flink cancel -s hdfs:///savepoints <jobId>
```

### ä»ä¿å­˜ç‚¹æ¢å¤

```bash
flink run -s hdfs:///savepoints/savepoint-xxx myJob.jar
```

## çŠ¶æ€ TTL

è®¾ç½®çŠ¶æ€è¿‡æœŸç­–ç•¥ï¼š

```java
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.days(7))  // 7 å¤©è¿‡æœŸ
    .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
    .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
    .cleanupFullSnapshot()  // æ£€æŸ¥ç‚¹æ—¶æ¸…ç†
    .build();

ValueStateDescriptor<String> stateDescriptor =
    new ValueStateDescriptor<>("myState", String.class);
stateDescriptor.enableTimeToLive(ttlConfig);
```

### TTL æ¸…ç†ç­–ç•¥

```java
// å¢é‡æ¸…ç†ï¼ˆæ¯è®¿é—® N æ¡è®°å½•æ¸…ç†ä¸€æ¬¡ï¼‰
.cleanupIncrementally(10, true)

// RocksDB å‹ç¼©æ—¶æ¸…ç†
.cleanupInRocksdbCompactFilter(1000)

// æ£€æŸ¥ç‚¹æ—¶å…¨é‡æ¸…ç†
.cleanupFullSnapshot()
```

## Broadcast State

å°†å°æ•°æ®é›†å¹¿æ’­åˆ°æ‰€æœ‰å¹¶è¡Œä»»åŠ¡ï¼š

```java
// å®šä¹‰å¹¿æ’­çŠ¶æ€æè¿°ç¬¦
MapStateDescriptor<String, Rule> ruleStateDescriptor =
    new MapStateDescriptor<>("rules", String.class, Rule.class);

// åˆ›å»ºå¹¿æ’­æµ
BroadcastStream<Rule> ruleBroadcastStream =
    ruleStream.broadcast(ruleStateDescriptor);

// è¿æ¥æ•°æ®æµå’Œå¹¿æ’­æµ
dataStream
    .connect(ruleBroadcastStream)
    .process(new BroadcastProcessFunction<Event, Rule, Result>() {
        @Override
        public void processElement(Event event, ReadOnlyContext ctx,
                Collector<Result> out) {
            // è¯»å–å¹¿æ’­çŠ¶æ€
            ReadOnlyBroadcastState<String, Rule> state =
                ctx.getBroadcastState(ruleStateDescriptor);
            Rule rule = state.get(event.getRuleId());
            // åº”ç”¨è§„åˆ™å¤„ç†äº‹ä»¶
        }

        @Override
        public void processBroadcastElement(Rule rule, Context ctx,
                Collector<Result> out) {
            // æ›´æ–°å¹¿æ’­çŠ¶æ€
            ctx.getBroadcastState(ruleStateDescriptor).put(rule.getId(), rule);
        }
    });
```

## ä¸‹ä¸€æ­¥

- ğŸ“Š [Table API & SQL](./table-sql.md) - å£°æ˜å¼å¤„ç†
- âš¡ [CEP å¤æ‚äº‹ä»¶å¤„ç†](./cep.md) - æ¨¡å¼åŒ¹é…
- ğŸš€ [æ€§èƒ½ä¼˜åŒ–](./performance-optimization.md) - è°ƒä¼˜æŒ‡å—
