---
sidebar_position: 15
title: "ç›‘æ§ä¸è¿ç»´"
description: "Flink ç”Ÿäº§ç¯å¢ƒç›‘æ§ä¸è¿ç»´å®è·µ"
---

# Flink ç›‘æ§ä¸è¿ç»´

> é€‚ç”¨ç‰ˆæœ¬ï¼šApache Flink v2.2.0

## å†…ç½® Metrics ç³»ç»Ÿ

### Metrics ç±»å‹

| ç±»å‹          | æè¿°     | ç¤ºä¾‹           |
| ------------- | -------- | -------------- |
| **Counter**   | è®¡æ•°å™¨   | å¤„ç†è®°å½•æ•°     |
| **Gauge**     | ç¬æ—¶å€¼   | å½“å‰é˜Ÿåˆ—å¤§å°   |
| **Meter**     | é€Ÿç‡     | æ¯ç§’å¤„ç†è®°å½•æ•° |
| **Histogram** | åˆ†å¸ƒç»Ÿè®¡ | å»¶è¿Ÿåˆ†å¸ƒ       |

### è‡ªå®šä¹‰ Metrics

```java
public class MetricsFunction extends RichMapFunction<Event, Result> {
    private transient Counter processedCounter;
    private transient Meter throughputMeter;
    private transient Histogram latencyHistogram;

    @Override
    public void open(Configuration parameters) {
        MetricGroup group = getRuntimeContext().getMetricGroup();

        // è®¡æ•°å™¨
        processedCounter = group.counter("processedEvents");

        // é€Ÿç‡
        throughputMeter = group.meter("throughput", new MeterView(60));

        // ç›´æ–¹å›¾
        latencyHistogram = group.histogram("latency",
            new DescriptiveStatisticsHistogram(1000));

        // ä»ªè¡¨ç›˜
        group.gauge("queueSize", () -> getQueueSize());
    }

    @Override
    public Result map(Event event) {
        long start = System.currentTimeMillis();
        Result result = process(event);

        processedCounter.inc();
        throughputMeter.markEvent();
        latencyHistogram.update(System.currentTimeMillis() - start);

        return result;
    }
}
```

## Prometheus é›†æˆ

### é…ç½® Metrics Reporter

```yaml
# flink-conf.yaml
metrics.reporter.promgateway.factory.class: org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporterFactory
metrics.reporter.promgateway.host: prometheus-pushgateway
metrics.reporter.promgateway.port: 9091
metrics.reporter.promgateway.jobName: flink-job
metrics.reporter.promgateway.randomJobNameSuffix: true
metrics.reporter.promgateway.deleteOnShutdown: false
metrics.reporter.promgateway.interval: 30 SECONDS

# æˆ–ä½¿ç”¨ Prometheus Pull æ¨¡å¼
metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
metrics.reporter.prom.port: 9999
```

### æ·»åŠ ä¾èµ–

```xml
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-metrics-prometheus</artifactId>
    <version>${flink.version}</version>
</dependency>
```

## Grafana Dashboard

### å…³é”®ç›‘æ§é¢æ¿

#### ä½œä¸šæ¦‚è§ˆ

```promql
# ä½œä¸šè¿è¡ŒçŠ¶æ€
flink_jobmanager_job_uptime{job_name="$job_name"}

# ä½œä¸šé‡å¯æ¬¡æ•°
flink_jobmanager_job_numRestarts{job_name="$job_name"}

# æ£€æŸ¥ç‚¹æˆåŠŸç‡
rate(flink_jobmanager_job_numberOfCompletedCheckpoints[5m]) /
rate(flink_jobmanager_job_numberOfInProgressCheckpoints[5m])
```

#### ååé‡ç›‘æ§

```promql
# æ¯ç§’è¾“å…¥è®°å½•æ•°
rate(flink_taskmanager_job_task_numRecordsIn[1m])

# æ¯ç§’è¾“å‡ºè®°å½•æ•°
rate(flink_taskmanager_job_task_numRecordsOut[1m])

# æ¯ç§’å¤„ç†å­—èŠ‚æ•°
rate(flink_taskmanager_job_task_numBytesIn[1m])
```

#### å»¶è¿Ÿç›‘æ§

```promql
# ç«¯åˆ°ç«¯å»¶è¿Ÿ
flink_taskmanager_job_latency_source_id_operator_id_operator_subtask_index_latency{
    quantile="0.99"
}

# æ°´å°å»¶è¿Ÿ
time() * 1000 - flink_taskmanager_job_task_currentInputWatermark
```

#### èƒŒå‹ç›‘æ§

```promql
# èƒŒå‹ç‡
flink_taskmanager_job_task_isBackPressured

# è¾“å‡ºç¼“å†²åŒºä½¿ç”¨ç‡
flink_taskmanager_job_task_buffers_outPoolUsage
```

### Dashboard JSON æ¨¡æ¿

```json
{
  "title": "Flink Job Monitoring",
  "panels": [
    {
      "title": "Records Throughput",
      "type": "graph",
      "targets": [
        {
          "expr": "rate(flink_taskmanager_job_task_numRecordsIn[1m])",
          "legendFormat": "{{task_name}} - In"
        },
        {
          "expr": "rate(flink_taskmanager_job_task_numRecordsOut[1m])",
          "legendFormat": "{{task_name}} - Out"
        }
      ]
    },
    {
      "title": "Checkpoint Duration",
      "type": "graph",
      "targets": [
        {
          "expr": "flink_jobmanager_job_lastCheckpointDuration",
          "legendFormat": "Duration (ms)"
        }
      ]
    }
  ]
}
```

## å‘Šè­¦é…ç½®

### Prometheus AlertManager è§„åˆ™

```yaml
groups:
  - name: flink-critical
    rules:
      # ä½œä¸šå¤±è´¥å‘Šè­¦
      - alert: FlinkJobFailed
        expr: flink_jobmanager_job_uptime == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Flink ä½œä¸š {{ $labels.job_name }} å¤±è´¥"
          description: "ä½œä¸šå·²ç»åœæ­¢è¿è¡Œè¶…è¿‡ 1 åˆ†é’Ÿ"

      # æ£€æŸ¥ç‚¹å¤±è´¥å‘Šè­¦
      - alert: FlinkCheckpointFailed
        expr: increase(flink_jobmanager_job_numberOfFailedCheckpoints[10m]) > 3
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Flink æ£€æŸ¥ç‚¹é¢‘ç¹å¤±è´¥"
          description: "10åˆ†é’Ÿå†…æ£€æŸ¥ç‚¹å¤±è´¥ {{ $value }} æ¬¡"

      # æ£€æŸ¥ç‚¹æ—¶é—´è¿‡é•¿
      - alert: FlinkCheckpointTooSlow
        expr: flink_jobmanager_job_lastCheckpointDuration > 600000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "æ£€æŸ¥ç‚¹è€—æ—¶è¿‡é•¿"
          description: "æ£€æŸ¥ç‚¹è€—æ—¶ {{ $value }}msï¼Œè¶…è¿‡ 10 åˆ†é’Ÿ"

  - name: flink-performance
    rules:
      # èƒŒå‹å‘Šè­¦
      - alert: FlinkHighBackpressure
        expr: flink_taskmanager_job_task_isBackPressured > 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "æ£€æµ‹åˆ°é«˜èƒŒå‹"
          description: "Task {{ $labels.task_name }} èƒŒå‹ç‡ {{ $value }}"

      # å»¶è¿Ÿå‘Šè­¦
      - alert: FlinkHighLatency
        expr: flink_taskmanager_job_latency_source_id_operator_id_latency{quantile="0.99"} > 10000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ç«¯åˆ°ç«¯å»¶è¿Ÿè¿‡é«˜"
          description: "P99 å»¶è¿Ÿ {{ $value }}ms"

      # æ¶ˆè´¹å»¶è¿Ÿå‘Šè­¦
      - alert: FlinkKafkaLag
        expr: flink_taskmanager_job_task_operator_KafkaSourceReader_KafkaConsumer_records_lag_max > 100000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Kafka æ¶ˆè´¹å»¶è¿Ÿè¿‡å¤§"
          description: "æ¶ˆè´¹å»¶è¿Ÿ {{ $value }} æ¡æ¶ˆæ¯"
```

## å¸¸è§è¿ç»´æ“ä½œ

### ä½œä¸šç®¡ç†

```bash
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨
flink list

# æŸ¥çœ‹ä½œä¸šè¯¦æƒ…
flink info <job-id>

# å–æ¶ˆä½œä¸š
flink cancel <job-id>

# åˆ›å»ºä¿å­˜ç‚¹
flink savepoint <job-id> hdfs:///savepoints

# ä»ä¿å­˜ç‚¹æ¢å¤
flink run -s hdfs:///savepoints/savepoint-xxx job.jar
```

### æ‰©ç¼©å®¹

```bash
# 1. åˆ›å»ºä¿å­˜ç‚¹
flink savepoint <job-id> hdfs:///savepoints

# 2. å–æ¶ˆä½œä¸š
flink cancel <job-id>

# 3. ä¿®æ”¹å¹¶è¡Œåº¦åæ¢å¤
flink run -p 8 -s hdfs:///savepoints/savepoint-xxx job.jar
```

### ç‰ˆæœ¬å‡çº§

```bash
# 1. åˆ›å»ºä¿å­˜ç‚¹
flink savepoint <job-id> hdfs:///savepoints

# 2. åœæ­¢æ—§ç‰ˆæœ¬ä½œä¸š
flink cancel <job-id>

# 3. éƒ¨ç½²æ–°ç‰ˆæœ¬
flink run -s hdfs:///savepoints/savepoint-xxx new-job.jar
```

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜è¯Šæ–­

| é—®é¢˜       | è¯Šæ–­æ–¹æ³•             | è§£å†³æ–¹æ¡ˆ                 |
| ---------- | -------------------- | ------------------------ |
| OOM        | æŸ¥çœ‹ GC æ—¥å¿—ã€å †è½¬å‚¨ | å¢åŠ å†…å­˜ã€ä¼˜åŒ–çŠ¶æ€       |
| èƒŒå‹       | Web UI èƒŒå‹æŒ‡æ ‡      | å¢åŠ å¹¶è¡Œåº¦ã€ä¼˜åŒ–ç®—å­     |
| æ£€æŸ¥ç‚¹è¶…æ—¶ | æ£€æŸ¥ç‚¹æ—¥å¿—           | ä½¿ç”¨å¢é‡æ£€æŸ¥ç‚¹ã€å¢å¤§è¶…æ—¶ |
| Kafka å»¶è¿Ÿ | Consumer Lag         | å¢åŠ å¹¶è¡Œåº¦ã€æ£€æŸ¥ç½‘ç»œ     |

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹ JobManager æ—¥å¿—
tail -f log/flink-*-jobmanager-*.log

# æŸ¥çœ‹ TaskManager æ—¥å¿—
tail -f log/flink-*-taskmanager-*.log

# æœç´¢å¼‚å¸¸
grep -r "Exception" log/

# æœç´¢æ£€æŸ¥ç‚¹æ—¥å¿—
grep -r "Checkpoint" log/flink-*-jobmanager-*.log
```

### å †è½¬å‚¨åˆ†æ

```bash
# ç”Ÿæˆå †è½¬å‚¨
jmap -dump:format=b,file=heap.hprof <pid>

# ä½¿ç”¨ MAT æˆ– VisualVM åˆ†æ
```

## Web UI ç›‘æ§

### å…³é”®é¡µé¢

| é¡µé¢         | ç”¨é€”                 |
| ------------ | -------------------- |
| Overview     | é›†ç¾¤æ¦‚è§ˆã€èµ„æºä½¿ç”¨   |
| Jobs         | ä½œä¸šåˆ—è¡¨ã€è¿è¡ŒçŠ¶æ€   |
| Job Details  | ç®—å­æ‹“æ‰‘ã€å„ç®—å­çŠ¶æ€ |
| Checkpoints  | æ£€æŸ¥ç‚¹å†å²ã€è€—æ—¶     |
| Metrics      | è¯¦ç»†æŒ‡æ ‡æŸ¥çœ‹         |
| Backpressure | èƒŒå‹çŠ¶æ€åˆ†æ         |

### REST API

```bash
# è·å–ä½œä¸šåˆ—è¡¨
curl http://localhost:8081/jobs

# è·å–ä½œä¸šè¯¦æƒ…
curl http://localhost:8081/jobs/<job-id>

# è·å–æ£€æŸ¥ç‚¹ç»Ÿè®¡
curl http://localhost:8081/jobs/<job-id>/checkpoints

# è§¦å‘ä¿å­˜ç‚¹
curl -X POST http://localhost:8081/jobs/<job-id>/savepoints \
  -d '{"target-directory": "hdfs:///savepoints"}'
```

## ä¸‹ä¸€æ­¥

- ğŸš€ [æ€§èƒ½ä¼˜åŒ–](/docs/flink/performance-optimization) - è°ƒä¼˜æŒ‡å—
- ğŸ“‹ [æœ€ä½³å®è·µ](/docs/flink/best-practices) - å¼€å‘è§„èŒƒ
- ğŸ”§ [éƒ¨ç½²ä¸è¿ç»´](/docs/flink/deployment) - éƒ¨ç½²é…ç½®
