---
sidebar_position: 17
title: "æœ€ä½³å®è·µ"
description: "Flink å¼€å‘ä¸ç”Ÿäº§æœ€ä½³å®è·µ"
---

# Flink æœ€ä½³å®è·µ

> é€‚ç”¨ç‰ˆæœ¬ï¼šApache Flink v2.2.0

## ä»£ç å¼€å‘

### ç®—å­è®¾è®¡

```java
// âœ… æ¨èï¼šä½¿ç”¨ RichFunction è®¿é—®è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
public class MyRichMapFunction extends RichMapFunction<Event, Result> {
    private transient Counter counter;

    @Override
    public void open(Configuration parameters) {
        counter = getRuntimeContext()
            .getMetricGroup()
            .counter("processedEvents");
    }

    @Override
    public Result map(Event event) {
        counter.inc();
        return process(event);
    }
}

// âŒ é¿å…ï¼šåœ¨ç®—å­ä¸­åˆ›å»ºä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
public class BadMapFunction implements MapFunction<Event, Result> {
    private Connection connection; // ä¸å¯åºåˆ—åŒ–ï¼
}
```

### çŠ¶æ€ä½¿ç”¨

```java
// âœ… æ¨èï¼šåœ¨ open() ä¸­åˆå§‹åŒ–çŠ¶æ€
@Override
public void open(Configuration parameters) {
    ValueStateDescriptor<Long> descriptor =
        new ValueStateDescriptor<>("count", Long.class);
    countState = getRuntimeContext().getState(descriptor);
}

// âœ… æ¨èï¼šä½¿ç”¨çŠ¶æ€ TTL é˜²æ­¢çŠ¶æ€æ— é™å¢é•¿
StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.days(7))
    .setUpdateType(UpdateType.OnCreateAndWrite)
    .cleanupIncrementally(10, true)
    .build();
descriptor.enableTimeToLive(ttlConfig);
```

### æ—¶é—´å¤„ç†

```java
// âœ… æ¨èï¼šä½¿ç”¨äº‹ä»¶æ—¶é—´ï¼ˆæ— éœ€æ˜¾å¼è®¾ç½® TimeCharacteristicï¼‰
// âœ… æ¨èï¼šæ­£ç¡®è®¾ç½®æ°´å°
DataStream<Event> stream = source.assignTimestampsAndWatermarks(
    WatermarkStrategy
        .<Event>forBoundedOutOfOrderness(Duration.ofSeconds(5))
        .withTimestampAssigner((event, ts) -> event.getTimestamp())
        .withIdleness(Duration.ofMinutes(1))  // å¤„ç†ç©ºé—²åˆ†åŒº
);
```

### å¼‚å¸¸å¤„ç†

```java
// âœ… æ¨èï¼šä½¿ç”¨ä¾§è¾“å‡ºå¤„ç†å¼‚å¸¸æ•°æ®
OutputTag<Event> errorTag = new OutputTag<Event>("errors"){};

SingleOutputStreamOperator<Result> result = stream
    .process(new ProcessFunction<Event, Result>() {
        @Override
        public void processElement(Event event, Context ctx,
                Collector<Result> out) {
            try {
                out.collect(process(event));
            } catch (Exception e) {
                ctx.output(errorTag, event);
            }
        }
    });

// è·å–å¼‚å¸¸æ•°æ®
DataStream<Event> errors = result.getSideOutput(errorTag);
```

## ç”Ÿäº§é…ç½®

### æ£€æŸ¥ç‚¹é…ç½®

```java
// ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®
env.enableCheckpointing(60000);  // 1 åˆ†é’Ÿ

CheckpointConfig config = env.getCheckpointConfig();
config.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
config.setMinPauseBetweenCheckpoints(30000);  // æœ€å°é—´éš”
config.setCheckpointTimeout(600000);  // 10 åˆ†é’Ÿè¶…æ—¶
config.setMaxConcurrentCheckpoints(1);
config.setExternalizedCheckpointCleanup(
    ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);

// å¯¹äºå¤§çŠ¶æ€ï¼Œä½¿ç”¨éå¯¹é½æ£€æŸ¥ç‚¹
config.enableUnalignedCheckpoints();
```

### é‡å¯ç­–ç•¥

```java
// å›ºå®šå»¶è¿Ÿé‡å¯
env.setRestartStrategy(RestartStrategies.fixedDelayRestart(
    3,  // æœ€å¤šé‡å¯ 3 æ¬¡
    Time.seconds(30)  // é‡å¯é—´éš”
));

// å¤±è´¥ç‡é‡å¯
env.setRestartStrategy(RestartStrategies.failureRateRestart(
    3,  // æ—¶é—´çª—å£å†…æœ€å¤§å¤±è´¥æ¬¡æ•°
    Time.minutes(5),  // æ—¶é—´çª—å£
    Time.seconds(10)  // é‡å¯é—´éš”
));

// æŒ‡æ•°å»¶è¿Ÿé‡å¯
env.setRestartStrategy(RestartStrategies.exponentialDelayRestart(
    Time.seconds(1),  // åˆå§‹å»¶è¿Ÿ
    Time.minutes(5),  // æœ€å¤§å»¶è¿Ÿ
    2.0,  // å»¶è¿Ÿå€æ•°
    Time.hours(1),  // é‡ç½®çª—å£
    0.1  // æŠ–åŠ¨å› å­
));
```

### èµ„æºé…ç½®

```yaml
# ç”Ÿäº§ç¯å¢ƒ flink-conf.yaml
jobmanager.memory.process.size: 4096m
taskmanager.memory.process.size: 8192m
taskmanager.numberOfTaskSlots: 4

# çŠ¶æ€åç«¯
state.backend: rocksdb
state.backend.incremental: true
state.checkpoints.dir: hdfs:///flink/checkpoints
state.savepoints.dir: hdfs:///flink/savepoints

# é«˜å¯ç”¨
high-availability: zookeeper
high-availability.storageDir: hdfs:///flink/ha
high-availability.zookeeper.quorum: zk1:2181,zk2:2181,zk3:2181
```

## ç›‘æ§å‘Šè­¦

### å…³é”®ç›‘æ§æŒ‡æ ‡

```yaml
# Prometheus å‘Šè­¦è§„åˆ™
groups:
  - name: flink-alerts
    rules:
      - alert: FlinkJobFailed
        expr: flink_jobmanager_job_uptime == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Flink job failed"

      - alert: FlinkCheckpointFailed
        expr: increase(flink_jobmanager_job_numberOfFailedCheckpoints[5m]) > 0
        for: 5m
        labels:
          severity: warning

      - alert: FlinkHighBackpressure
        expr: flink_taskmanager_job_task_isBackPressured > 0.5
        for: 10m
        labels:
          severity: warning
```

### æ—¥å¿—è§„èŒƒ

```java
// âœ… æ¨èï¼šä½¿ç”¨ SLF4J å¹¶é¿å…åœ¨çƒ­è·¯å¾„æ‰“å°æ—¥å¿—
private static final Logger LOG = LoggerFactory.getLogger(MyFunction.class);

@Override
public void processElement(Event event, Context ctx, Collector<Result> out) {
    // é¿å…åœ¨æ¯æ¡è®°å½•ä¸Šæ‰“å°æ—¥å¿—
    if (LOG.isDebugEnabled()) {
        LOG.debug("Processing event: {}", event.getId());
    }
}
```

## ç‰ˆæœ¬å‡çº§

### å‡çº§æ­¥éª¤

1. **åˆ›å»ºä¿å­˜ç‚¹**

   ```bash
   flink savepoint <jobId> hdfs:///savepoints
   ```

2. **å–æ¶ˆæ—§ä½œä¸š**

   ```bash
   flink cancel <jobId>
   ```

3. **éƒ¨ç½²æ–°ç‰ˆæœ¬**

4. **ä»ä¿å­˜ç‚¹æ¢å¤**
   ```bash
   flink run -s hdfs:///savepoints/savepoint-xxx newJob.jar
   ```

### çŠ¶æ€å…¼å®¹æ€§

```java
// âœ… æ¨èï¼šä½¿ç”¨æ˜ç¡®çš„çŠ¶æ€åç§°
ValueStateDescriptor<Long> descriptor =
    new ValueStateDescriptor<>("counter-v1", Long.class);

// âœ… æ¨èï¼šä½¿ç”¨ Avro/Protobuf ç­‰å¯æ¼”è¿›çš„åºåˆ—åŒ–æ ¼å¼
```

## æµ‹è¯•å»ºè®®

### å•å…ƒæµ‹è¯•

```java
@Test
public void testMapFunction() throws Exception {
    MyMapFunction function = new MyMapFunction();
    function.open(new Configuration());

    Result result = function.map(new Event("test", 100));

    assertEquals("expected", result.getValue());
}
```

### é›†æˆæµ‹è¯•

```java
@Test
public void testPipeline() throws Exception {
    StreamExecutionEnvironment env =
        StreamExecutionEnvironment.getExecutionEnvironment();

    DataStream<Event> input = env.fromElements(
        new Event("a", 1),
        new Event("b", 2)
    );

    DataStream<Result> output = MyPipeline.build(input);

    List<Result> results = new ArrayList<>();
    output.executeAndCollect().forEachRemaining(results::add);

    assertEquals(2, results.size());
}
```

### ä½¿ç”¨ MiniCluster

```java
@ClassRule
public static MiniClusterResource flinkCluster =
    new MiniClusterResource(
        new MiniClusterResourceConfiguration.Builder()
            .setNumberSlotsPerTaskManager(2)
            .setNumberTaskManagers(1)
            .build()
    );
```

## å¸¸è§åæ¨¡å¼

| åæ¨¡å¼         | é—®é¢˜                | è§£å†³æ–¹æ¡ˆ                       |
| -------------- | ------------------- | ------------------------------ |
| ç®—å­ä¸­åˆ›å»ºè¿æ¥ | ä¸å¯åºåˆ—åŒ–/èµ„æºæ³„æ¼ | ä½¿ç”¨ RichFunction + open/close |
| çƒ­è·¯å¾„æ‰“å°æ—¥å¿— | æ€§èƒ½ä¸‹é™            | ä½¿ç”¨é‡‡æ ·æˆ– debug çº§åˆ«          |
| å¿½ç•¥èƒŒå‹       | å»¶è¿Ÿå¢åŠ             | ç›‘æ§å¹¶ä¼˜åŒ–                     |
| æ— é™çŠ¶æ€å¢é•¿   | OOM                 | ä½¿ç”¨çŠ¶æ€ TTL                   |
| ä¸è®¾ç½®æ°´å°     | çª—å£ä¸è§¦å‘          | æ­£ç¡®é…ç½®æ°´å°ç­–ç•¥               |

## ä¸‹ä¸€æ­¥

- ğŸ”§ [éƒ¨ç½²ä¸è¿ç»´](/docs/flink/deployment) - ç”Ÿäº§éƒ¨ç½²
- ğŸš€ [æ€§èƒ½ä¼˜åŒ–](/docs/flink/performance-optimization) - è°ƒä¼˜æŒ‡å—
- ğŸ’¼ [é¢è¯•é¢˜ç²¾é€‰](/docs/interview/flink-interview-questions) - é¢è¯•å‡†å¤‡
