---
sidebar_position: 9
title: ğŸ§ª Fine-tuningï¼ˆå¾®è°ƒï¼‰
---

# Fine-tuningï¼ˆå¾®è°ƒï¼‰

Fine-tuningï¼ˆå¾®è°ƒï¼‰æ˜¯ç”¨ä½ çš„æ•°æ®å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œå†è®­ç»ƒï¼Œä½¿å…¶æ›´ç¬¦åˆç‰¹å®šä»»åŠ¡ã€æ ¼å¼æˆ–é£æ ¼ã€‚å®ƒå¸¸ç”¨äº"è®©æ¨¡å‹æ›´åƒä½ çš„äº§å“"ï¼Œè€Œä¸æ˜¯"è®©æ¨¡å‹çŸ¥é“æ›´å¤šäº‹å®"ã€‚

## ä»€ä¹ˆæ—¶å€™é€‚åˆå¾®è°ƒ

### é€‚åˆå¾®è°ƒçš„åœºæ™¯

| åœºæ™¯             | è¯´æ˜                                   |
| ---------------- | -------------------------------------- |
| **ç¨³å®šè¾“å‡ºæ ¼å¼** | å›ºå®š JSON/SQL/å‡½æ•°å‚æ•°ç»“æ„             |
| **ä»»åŠ¡ä¸“ç²¾**     | åˆ†ç±»ã€ä¿¡æ¯æŠ½å–ã€å®¢æœæ„å›¾è¯†åˆ«ã€ä»£ç è¡¥å…¨ |
| **è¯­æ°”é£æ ¼ç»Ÿä¸€** | å“ç‰Œå£å»ã€å†™ä½œé£æ ¼ä¸€è‡´                 |
| **å‡å°‘ Prompt**  | æŠŠå¤æ‚æŒ‡ä»¤"å†…åŒ–"åˆ°æ¨¡å‹ä¸­               |

### ä¸å¤ªé€‚åˆå¾®è°ƒçš„åœºæ™¯

- **éœ€è¦æœ€æ–°çŸ¥è¯†/ç§æœ‰çŸ¥è¯†**ï¼šä¼˜å…ˆç”¨ RAG
- **é¢‘ç¹å˜åŒ–çš„çŸ¥è¯†**ï¼šå¾®è°ƒç»´æŠ¤æˆæœ¬é«˜
- **ç®€å•ä»»åŠ¡**ï¼šFew-shot Prompting å¯èƒ½å°±å¤Ÿäº†

## RAG vs Fine-tuning çš„é€‰æ‹©

| ç›®æ ‡                   | æ¨èæ–¹æ¡ˆ                           |
| ---------------------- | ---------------------------------- |
| è¡¥å……å¯å˜çŸ¥è¯†/ç§æœ‰çŸ¥è¯†  | RAG                                |
| æ”¹å˜æ¨¡å‹è¡Œä¸º/æ ¼å¼/é£æ ¼ | Fine-tuning                        |
| ä¸¤è€…éƒ½éœ€è¦             | RAG + Fine-tuningï¼ˆæˆ– RAG + æŒ‡ä»¤ä¼˜åŒ–ï¼‰ |

```mermaid
graph TD
    A[éœ€æ±‚åˆ†æ] --> B{éœ€è¦å¤–éƒ¨çŸ¥è¯†?}
    B -->|æ˜¯| C{çŸ¥è¯†é¢‘ç¹å˜åŒ–?}
    B -->|å¦| D{éœ€è¦ç‰¹å®šæ ¼å¼/é£æ ¼?}
    C -->|æ˜¯| E[RAG]
    C -->|å¦| F[RAG æˆ– Fine-tuning]
    D -->|æ˜¯| G[Fine-tuning]
    D -->|å¦| H[Prompt Engineering]
```

## æ•°æ®å‡†å¤‡

### æ•°æ®è´¨é‡åŸåˆ™

- **æ ·æœ¬è´¨é‡ > æ•°é‡**ï¼šå…ˆåš 100-500 æ¡é«˜è´¨é‡"é»„é‡‘æ ·æœ¬"
- **è¦†ç›–è¾¹ç•Œæƒ…å†µ**ï¼šé”™è¯¯è¾“å…¥ã€ç¼ºå­—æ®µã€æ­§ä¹‰é—®é¢˜ã€é•¿æ–‡æœ¬
- **å»é‡ä¸ä¸€è‡´æ€§**ï¼šåŒç±»é—®é¢˜ç­”æ¡ˆä¸è¦äº’ç›¸çŸ›ç›¾
- **å®‰å…¨ä¸åˆè§„**ï¼šç§»é™¤æ•æ„Ÿä¿¡æ¯ï¼ˆPIIã€å¯†é’¥ã€å†…éƒ¨æœºå¯†ï¼‰

### æ•°æ®æ ¼å¼

#### OpenAI æ ¼å¼ï¼ˆå¯¹è¯ï¼‰

```json
{"messages": [
  {"role": "system", "content": "ä½ æ˜¯ä¼ä¸šå®¢æœåŠ©æ‰‹ã€‚"},
  {"role": "user", "content": "æ€ä¹ˆé‡ç½®å¯†ç ï¼Ÿ"},
  {"role": "assistant", "content": "ä½ å¯ä»¥åœ¨ç™»å½•é¡µç‚¹å‡»"å¿˜è®°å¯†ç "ï¼Œç„¶åæŒ‰ç…§é‚®ä»¶æç¤ºæ“ä½œã€‚"}
]}
```

#### åˆ†ç±»ä»»åŠ¡æ ¼å¼

```json
{"messages": [
  {"role": "system", "content": "å¯¹ç”¨æˆ·åé¦ˆè¿›è¡Œåˆ†ç±»ï¼Œç±»åˆ«ï¼šbug/feature/question/other"},
  {"role": "user", "content": "ç™»å½•æŒ‰é’®ç‚¹å‡»æ²¡ååº”"},
  {"role": "assistant", "content": "bug"}
]}
```

#### ä¿¡æ¯æŠ½å–æ ¼å¼

```json
{"messages": [
  {"role": "system", "content": "ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œè¾“å‡º JSON"},
  {"role": "user", "content": "å¼ ä¸‰ï¼Œç”·ï¼Œ1990å¹´å‡ºç”Ÿï¼Œç°å±…åŒ—äº¬"},
  {"role": "assistant", "content": "{\"name\": \"å¼ ä¸‰\", \"gender\": \"ç”·\", \"birth_year\": 1990, \"city\": \"åŒ—äº¬\"}"}
]}
```

### æ•°æ®å‡†å¤‡è„šæœ¬

```python
import json
from pathlib import Path

def prepare_training_data(raw_data: list[dict], output_path: str):
    """å°†åŸå§‹æ•°æ®è½¬æ¢ä¸º OpenAI å¾®è°ƒæ ¼å¼"""
    formatted_data = []
    
    for item in raw_data:
        formatted_item = {
            "messages": [
                {"role": "system", "content": item.get("system_prompt", "")},
                {"role": "user", "content": item["input"]},
                {"role": "assistant", "content": item["output"]}
            ]
        }
        formatted_data.append(formatted_item)
    
    # å†™å…¥ JSONL æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in formatted_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"å·²ç”Ÿæˆ {len(formatted_data)} æ¡è®­ç»ƒæ•°æ®")
    return formatted_data

def validate_data(file_path: str) -> dict:
    """éªŒè¯è®­ç»ƒæ•°æ®æ ¼å¼"""
    errors = []
    total = 0
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f, 1):
            total += 1
            try:
                data = json.loads(line)
                if "messages" not in data:
                    errors.append(f"Line {i}: missing 'messages' field")
                else:
                    for msg in data["messages"]:
                        if "role" not in msg or "content" not in msg:
                            errors.append(f"Line {i}: invalid message format")
            except json.JSONDecodeError as e:
                errors.append(f"Line {i}: JSON parse error - {e}")
    
    return {
        "total": total,
        "valid": total - len(errors),
        "errors": errors[:10]  # åªè¿”å›å‰ 10 ä¸ªé”™è¯¯
    }
```

## OpenAI Fine-tuning å®æˆ˜

### 1. ä¸Šä¼ è®­ç»ƒæ•°æ®

```python
from openai import OpenAI

client = OpenAI()

# ä¸Šä¼ è®­ç»ƒæ–‡ä»¶
training_file = client.files.create(
    file=open("training_data.jsonl", "rb"),
    purpose="fine-tune"
)

print(f"File ID: {training_file.id}")
```

### 2. åˆ›å»ºå¾®è°ƒä»»åŠ¡

```python
# åˆ›å»ºå¾®è°ƒä»»åŠ¡
fine_tune_job = client.fine_tuning.jobs.create(
    training_file=training_file.id,
    model="gpt-4o-mini-2024-07-18",  # åŸºç¡€æ¨¡å‹
    hyperparameters={
        "n_epochs": 3,  # è®­ç»ƒè½®æ•°
        "batch_size": "auto",
        "learning_rate_multiplier": "auto"
    },
    suffix="my-custom-model"  # æ¨¡å‹åç§°åç¼€
)

print(f"Job ID: {fine_tune_job.id}")
print(f"Status: {fine_tune_job.status}")
```

### 3. ç›‘æ§è®­ç»ƒè¿›åº¦

```python
import time

def monitor_fine_tuning(job_id: str):
    """ç›‘æ§å¾®è°ƒä»»åŠ¡è¿›åº¦"""
    while True:
        job = client.fine_tuning.jobs.retrieve(job_id)
        print(f"Status: {job.status}")
        
        if job.status == "succeeded":
            print(f"âœ… è®­ç»ƒå®Œæˆï¼æ¨¡å‹ ID: {job.fine_tuned_model}")
            return job.fine_tuned_model
        elif job.status == "failed":
            print(f"âŒ è®­ç»ƒå¤±è´¥: {job.error}")
            return None
        
        # è·å–æœ€æ–°äº‹ä»¶
        events = client.fine_tuning.jobs.list_events(job_id, limit=5)
        for event in events.data:
            print(f"  [{event.created_at}] {event.message}")
        
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

# ç›‘æ§è®­ç»ƒ
model_id = monitor_fine_tuning(fine_tune_job.id)
```

### 4. ä½¿ç”¨å¾®è°ƒæ¨¡å‹

```python
# ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹
response = client.chat.completions.create(
    model=model_id,  # ä½¿ç”¨å¾®è°ƒæ¨¡å‹ ID
    messages=[
        {"role": "user", "content": "æ€ä¹ˆä¿®æ”¹æ”¶è´§åœ°å€ï¼Ÿ"}
    ],
    temperature=0.7
)

print(response.choices[0].message.content)
```

## è®­ç»ƒå‚æ•°è°ƒä¼˜

### å…³é”®è¶…å‚æ•°

| å‚æ•°                       | è¯´æ˜                 | å»ºè®®å€¼       |
| -------------------------- | -------------------- | ------------ |
| `n_epochs`                 | è®­ç»ƒè½®æ•°             | 2-4          |
| `batch_size`               | æ‰¹æ¬¡å¤§å°             | auto æˆ– 4-32 |
| `learning_rate_multiplier` | å­¦ä¹ ç‡å€æ•°           | 0.5-2.0      |

### å‚æ•°é€‰æ‹©å»ºè®®

```python
# å°æ•°æ®é›† (< 100 æ¡)
hyperparameters = {
    "n_epochs": 4,
    "learning_rate_multiplier": 0.5  # é™ä½å­¦ä¹ ç‡é˜²æ­¢è¿‡æ‹Ÿåˆ
}

# ä¸­ç­‰æ•°æ®é›† (100-1000 æ¡)
hyperparameters = {
    "n_epochs": 3,
    "learning_rate_multiplier": "auto"
}

# å¤§æ•°æ®é›† (> 1000 æ¡)
hyperparameters = {
    "n_epochs": 2,
    "learning_rate_multiplier": 1.0
}
```

## è¯„ä¼°ä¸éªŒè¯

### åˆ›å»ºè¯„ä¼°é›†

```python
def split_data(data: list, train_ratio: float = 0.9):
    """åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†"""
    import random
    random.shuffle(data)
    split_idx = int(len(data) * train_ratio)
    return data[:split_idx], data[split_idx:]

# ä½¿ç”¨éªŒè¯é›†
fine_tune_job = client.fine_tuning.jobs.create(
    training_file=training_file.id,
    validation_file=validation_file.id,  # æ·»åŠ éªŒè¯é›†
    model="gpt-4o-mini-2024-07-18"
)
```

### è¯„ä¼°æŒ‡æ ‡

```python
def evaluate_model(model_id: str, test_data: list) -> dict:
    """è¯„ä¼°å¾®è°ƒæ¨¡å‹"""
    correct = 0
    total = len(test_data)
    
    for item in test_data:
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": item["system"]},
                {"role": "user", "content": item["input"]}
            ],
            temperature=0
        )
        
        predicted = response.choices[0].message.content.strip()
        expected = item["expected"].strip()
        
        if predicted == expected:
            correct += 1
    
    return {
        "accuracy": correct / total,
        "correct": correct,
        "total": total
    }
```

## ç”Ÿäº§è½åœ°å»ºè®®

### ç‰ˆæœ¬ç®¡ç†

```python
# è®°å½•æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯
model_registry = {
    "v1.0": {
        "model_id": "ft:gpt-4o-mini:org::abc123",
        "training_file": "training_v1.jsonl",
        "metrics": {"accuracy": 0.92},
        "created_at": "2024-01-15",
        "status": "deprecated"
    },
    "v1.1": {
        "model_id": "ft:gpt-4o-mini:org::def456",
        "training_file": "training_v1.1.jsonl",
        "metrics": {"accuracy": 0.95},
        "created_at": "2024-02-01",
        "status": "production"
    }
}
```

### ç°åº¦å‘å¸ƒ

```python
import random

def get_model_for_request(user_id: str, rollout_percentage: float = 0.1):
    """ç°åº¦å‘å¸ƒï¼šéƒ¨åˆ†æµé‡ä½¿ç”¨æ–°æ¨¡å‹"""
    if random.random() < rollout_percentage:
        return "ft:gpt-4o-mini:org::new_model"  # æ–°æ¨¡å‹
    return "ft:gpt-4o-mini:org::stable_model"   # ç¨³å®šæ¨¡å‹
```

### å›æ»šç­–ç•¥

```python
class ModelManager:
    def __init__(self):
        self.current_model = "ft:gpt-4o-mini:org::v1.1"
        self.fallback_model = "ft:gpt-4o-mini:org::v1.0"
        self.error_count = 0
        self.error_threshold = 10
    
    def get_model(self):
        if self.error_count > self.error_threshold:
            print("âš ï¸ é”™è¯¯è¿‡å¤šï¼Œå›æ»šåˆ°ç¨³å®šç‰ˆæœ¬")
            return self.fallback_model
        return self.current_model
    
    def report_error(self):
        self.error_count += 1
    
    def reset_errors(self):
        self.error_count = 0
```

## æˆæœ¬ä¼°ç®—

| æ¨¡å‹              | è®­ç»ƒæˆæœ¬        | æ¨ç†æˆæœ¬ï¼ˆè¾“å…¥ï¼‰ | æ¨ç†æˆæœ¬ï¼ˆè¾“å‡ºï¼‰ |
| ----------------- | --------------- | ---------------- | ---------------- |
| gpt-4o-mini       | $3.00 / 1M tokens | $0.30 / 1M       | $1.20 / 1M       |
| gpt-4o            | $25.00 / 1M tokens | $5.00 / 1M       | $15.00 / 1M      |

:::tip æˆæœ¬ä¼˜åŒ–
- å…ˆç”¨å°æ¨¡å‹ (gpt-4o-mini) éªŒè¯æ•ˆæœ
- ç²¾ç®€è®­ç»ƒæ•°æ®ï¼Œå»é™¤å†—ä½™æ ·æœ¬
- ä½¿ç”¨éªŒè¯é›†åŠæ—©åœæ­¢ï¼Œé¿å…è¿‡åº¦è®­ç»ƒ
:::

## å¸¸è§é—®é¢˜

### 1. è¿‡æ‹Ÿåˆ

**ç—‡çŠ¶**ï¼šè®­ç»ƒé›†è¡¨ç°å¥½ï¼Œæµ‹è¯•é›†è¡¨ç°å·®

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å¢åŠ è®­ç»ƒæ•°æ®å¤šæ ·æ€§
- å‡å°‘è®­ç»ƒè½®æ•°
- é™ä½å­¦ä¹ ç‡

### 2. æ¬ æ‹Ÿåˆ

**ç—‡çŠ¶**ï¼šè®­ç»ƒé›†å’Œæµ‹è¯•é›†è¡¨ç°éƒ½ä¸å¥½

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å¢åŠ è®­ç»ƒæ•°æ®é‡
- å¢åŠ è®­ç»ƒè½®æ•°
- æ£€æŸ¥æ•°æ®è´¨é‡

### 3. æ ¼å¼ä¸ç¨³å®š

**ç—‡çŠ¶**ï¼šè¾“å‡ºæ ¼å¼æ—¶å¥½æ—¶å

**è§£å†³æ–¹æ¡ˆ**ï¼š
- åœ¨è®­ç»ƒæ•°æ®ä¸­å¢åŠ æ ¼å¼ç¤ºä¾‹
- ä½¿ç”¨ JSON Mode
- æ·»åŠ æ ¼å¼éªŒè¯åå¤„ç†

## å»¶ä¼¸é˜…è¯»

- [OpenAI Fine-tuning æ–‡æ¡£](https://platform.openai.com/docs/guides/fine-tuning)
- [LoRA Fine-tuning å®æˆ˜](./lora-fine-tuning) - æœ¬åœ°å¾®è°ƒå¼€æºæ¨¡å‹
