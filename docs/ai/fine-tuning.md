---
sidebar_position: 9
title: 🧪 Fine-tuning（微调）
---

# Fine-tuning（微调）

Fine-tuning（微调）是用你的数据对基础模型进行再训练，使其更符合特定任务、格式或风格。它常用于“让模型更像你的产品”，而不是“让模型知道更多事实”。

## 什么时候适合微调

- **稳定输出格式**：比如固定 JSON/SQL/函数参数结构。
- **任务专精**：分类、信息抽取、客服意图识别、代码补全等。
- **语气与风格一致**：品牌口吻、写作风格统一。

不太适合：

- **需要最新知识/私有知识**：优先用 RAG。
- **频繁变化的知识**：微调维护成本高。

## RAG vs Fine-tuning 的选择

| 目标 | 更推荐 |
| --- | --- |
| 补充可变知识/私有知识 | RAG |
| 改变模型行为/格式/风格 | Fine-tuning |
| 两者都需要 | RAG + Fine-tuning（或 RAG + 指令优化） |

## 数据准备

- **样本质量 > 数量**：先做 100-500 条高质量“黄金样本”。
- **覆盖边界情况**：错误输入、缺字段、歧义问题、长文本。
- **去重与一致性**：同类问题答案不要互相矛盾。
- **安全与合规**：移除敏感信息（PII、密钥、内部机密）。

## 常见数据格式（以对话为例）

很多平台采用“多轮消息”的样本结构：

```json
{"messages": [
  {"role": "system", "content": "你是企业客服助手。"},
  {"role": "user", "content": "怎么重置密码？"},
  {"role": "assistant", "content": "你可以在登录页点击…"}
]}
```

## 训练与评估要点

- **先做离线评估集**：从真实流量抽样、人工标注。
- **训练后做 A/B**：线上对比满意度、解决率、人工转接率。
- **防止过拟合**：样本过少时容易“背答案”。
- **与提示工程联动**：很多“微调诉求”可以用更好的 Prompt/工具约束解决。

## 生产落地建议

- **版本化**：模型版本、数据版本、评估集版本都要可追溯。
- **灰度发布**：先小流量验证，再逐步扩量。
- **回滚策略**：出现质量波动能快速切回旧版本。

## 延伸阅读

- https://platform.openai.com/docs/guides/fine-tuning
