---
sidebar_position: 29
title: ğŸ•¸ï¸ GraphRAG
---

# GraphRAGï¼ˆçŸ¥è¯†å›¾è°±å¢å¼ºæ£€ç´¢ï¼‰

GraphRAG ç»“åˆçŸ¥è¯†å›¾è°±å’Œå‘é‡æ£€ç´¢ï¼Œæä¾›æ›´å‡†ç¡®ã€æ›´æœ‰ä¸Šä¸‹æ–‡çš„æ£€ç´¢ç»“æœã€‚ç‰¹åˆ«é€‚åˆéœ€è¦ç†è§£å®ä½“å…³ç³»çš„å¤æ‚æŸ¥è¯¢ã€‚

## ä¼ ç»Ÿ RAG vs GraphRAG

| ç‰¹æ€§ | ä¼ ç»Ÿ RAG | GraphRAG |
|------|---------|----------|
| æ£€ç´¢æ–¹å¼ | å‘é‡ç›¸ä¼¼åº¦ | å›¾éå† + å‘é‡ |
| å…³ç³»ç†è§£ | å¼± | å¼º |
| å¤šè·³æ¨ç† | å›°éš¾ | è‡ªç„¶æ”¯æŒ |
| å…¨å±€æ‘˜è¦ | ä¸æ”¯æŒ | æ”¯æŒ |
| æ„å»ºæˆæœ¬ | ä½ | é«˜ |

## å·¥ä½œåŸç†

```
æ–‡æ¡£ â”€â”€> å®ä½“æå– â”€â”€> å…³ç³»æŠ½å– â”€â”€> çŸ¥è¯†å›¾è°±
                                    â”‚
æŸ¥è¯¢ â”€â”€> å®ä½“è¯†åˆ« â”€â”€> å›¾æ£€ç´¢ â”€â”€> å­å›¾ â”€â”€> LLM â”€â”€> ç­”æ¡ˆ
                        â”‚
                    å‘é‡æ£€ç´¢ â”€â”€> ç›¸å…³æ–‡æ¡£
```

## å¾®è½¯ GraphRAG

### å®‰è£…

```bash
pip install graphrag
```

### åˆå§‹åŒ–é¡¹ç›®

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir my_graphrag
cd my_graphrag

# åˆå§‹åŒ–
python -m graphrag.index --init --root .
```

### é…ç½®

```yaml
# settings.yaml
llm:
  api_key: ${OPENAI_API_KEY}
  model: gpt-4o
  
embeddings:
  api_key: ${OPENAI_API_KEY}
  model: text-embedding-3-small

chunks:
  size: 1200
  overlap: 100

entity_extraction:
  max_gleanings: 1

community_reports:
  max_length: 2000
```

### æ„å»ºç´¢å¼•

```bash
# å°†æ–‡æ¡£æ”¾å…¥ input ç›®å½•
cp documents/*.txt ./input/

# æ„å»ºç´¢å¼•
python -m graphrag.index --root .
```

### æŸ¥è¯¢

```bash
# å…¨å±€æŸ¥è¯¢ï¼ˆé€‚åˆæ‘˜è¦æ€§é—®é¢˜ï¼‰
python -m graphrag.query --root . --method global "æ–‡æ¡£çš„ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ"

# å±€éƒ¨æŸ¥è¯¢ï¼ˆé€‚åˆå…·ä½“é—®é¢˜ï¼‰
python -m graphrag.query --root . --method local "å¼ ä¸‰å’Œæå››æ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ"
```

## æ‰‹åŠ¨å®ç° GraphRAG

### 1. å®ä½“å’Œå…³ç³»æå–

```python
from openai import OpenAI
import json
from dataclasses import dataclass

client = OpenAI()

@dataclass
class Entity:
    name: str
    type: str
    description: str

@dataclass
class Relationship:
    source: str
    target: str
    relation: str
    description: str

def extract_entities_and_relations(text: str) -> tuple[list[Entity], list[Relationship]]:
    """ä»æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»"""
    prompt = f"""
ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ã€‚

æ–‡æœ¬ï¼š
{text}

è¿”å› JSON æ ¼å¼ï¼š
{{
    "entities": [
        {{"name": "å®ä½“å", "type": "ç±»å‹(äººç‰©/ç»„ç»‡/åœ°ç‚¹/æ¦‚å¿µ)", "description": "æè¿°"}}
    ],
    "relationships": [
        {{"source": "æºå®ä½“", "target": "ç›®æ ‡å®ä½“", "relation": "å…³ç³»ç±»å‹", "description": "å…³ç³»æè¿°"}}
    ]
}}
"""
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )
    
    data = json.loads(response.choices[0].message.content)
    
    entities = [Entity(**e) for e in data.get("entities", [])]
    relationships = [Relationship(**r) for r in data.get("relationships", [])]
    
    return entities, relationships
```

### 2. æ„å»ºçŸ¥è¯†å›¾è°±

```python
import networkx as nx
from langchain_openai import OpenAIEmbeddings
import numpy as np

class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°±"""
    
    def __init__(self):
        self.graph = nx.DiGraph()
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.entity_embeddings = {}
    
    def add_entity(self, entity: Entity):
        """æ·»åŠ å®ä½“"""
        self.graph.add_node(
            entity.name,
            type=entity.type,
            description=entity.description
        )
        # è®¡ç®—åµŒå…¥
        self.entity_embeddings[entity.name] = self.embeddings.embed_query(
            f"{entity.name}: {entity.description}"
        )
    
    def add_relationship(self, rel: Relationship):
        """æ·»åŠ å…³ç³»"""
        self.graph.add_edge(
            rel.source,
            rel.target,
            relation=rel.relation,
            description=rel.description
        )
    
    def build_from_documents(self, documents: list[str]):
        """ä»æ–‡æ¡£æ„å»ºå›¾è°±"""
        for doc in documents:
            entities, relationships = extract_entities_and_relations(doc)
            
            for entity in entities:
                self.add_entity(entity)
            
            for rel in relationships:
                if rel.source in self.graph and rel.target in self.graph:
                    self.add_relationship(rel)
    
    def find_similar_entities(self, query: str, top_k: int = 5) -> list[str]:
        """æ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸ä¼¼çš„å®ä½“"""
        query_embedding = self.embeddings.embed_query(query)
        
        similarities = []
        for entity, embedding in self.entity_embeddings.items():
            sim = np.dot(query_embedding, embedding)
            similarities.append((entity, sim))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return [e[0] for e in similarities[:top_k]]
    
    def get_subgraph(self, entities: list[str], hops: int = 2) -> nx.DiGraph:
        """è·å–å®ä½“å‘¨å›´çš„å­å›¾"""
        nodes = set(entities)
        
        for _ in range(hops):
            new_nodes = set()
            for node in nodes:
                if node in self.graph:
                    new_nodes.update(self.graph.predecessors(node))
                    new_nodes.update(self.graph.successors(node))
            nodes.update(new_nodes)
        
        return self.graph.subgraph(nodes)
    
    def subgraph_to_text(self, subgraph: nx.DiGraph) -> str:
        """å°†å­å›¾è½¬æ¢ä¸ºæ–‡æœ¬æè¿°"""
        lines = []
        
        # å®ä½“æè¿°
        lines.append("å®ä½“ï¼š")
        for node in subgraph.nodes():
            data = self.graph.nodes[node]
            lines.append(f"- {node} ({data.get('type', 'æœªçŸ¥')}): {data.get('description', '')}")
        
        # å…³ç³»æè¿°
        lines.append("\nå…³ç³»ï¼š")
        for source, target, data in subgraph.edges(data=True):
            lines.append(f"- {source} --[{data.get('relation', '')}]--> {target}")
        
        return "\n".join(lines)
```


### 3. GraphRAG æŸ¥è¯¢

```python
class GraphRAG:
    """GraphRAG æŸ¥è¯¢ç³»ç»Ÿ"""
    
    def __init__(self, knowledge_graph: KnowledgeGraph):
        self.kg = knowledge_graph
        self.client = OpenAI()
    
    def query(self, question: str) -> str:
        """æŸ¥è¯¢"""
        # 1. æ‰¾åˆ°ç›¸å…³å®ä½“
        relevant_entities = self.kg.find_similar_entities(question, top_k=5)
        
        # 2. è·å–å­å›¾
        subgraph = self.kg.get_subgraph(relevant_entities, hops=2)
        
        # 3. è½¬æ¢ä¸ºä¸Šä¸‹æ–‡
        context = self.kg.subgraph_to_text(subgraph)
        
        # 4. ç”Ÿæˆç­”æ¡ˆ
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": f"æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”é—®é¢˜ã€‚\n\n{context}"
                },
                {"role": "user", "content": question}
            ]
        )
        
        return response.choices[0].message.content

# ä½¿ç”¨
kg = KnowledgeGraph()
kg.build_from_documents(documents)

rag = GraphRAG(kg)
answer = rag.query("å¼ ä¸‰å’Œæå››æ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ")
```

## æ··åˆæ£€ç´¢

ç»“åˆå‘é‡æ£€ç´¢å’Œå›¾æ£€ç´¢ã€‚

```python
from langchain_community.vectorstores import Chroma

class HybridGraphRAG:
    """æ··åˆ GraphRAG"""
    
    def __init__(self, documents: list[str]):
        # å‘é‡å­˜å‚¨
        self.vectorstore = Chroma.from_texts(
            texts=documents,
            embedding=OpenAIEmbeddings(model="text-embedding-3-small")
        )
        
        # çŸ¥è¯†å›¾è°±
        self.kg = KnowledgeGraph()
        self.kg.build_from_documents(documents)
        
        self.client = OpenAI()
    
    def query(self, question: str) -> str:
        # å‘é‡æ£€ç´¢
        vector_docs = self.vectorstore.similarity_search(question, k=3)
        vector_context = "\n".join([d.page_content for d in vector_docs])
        
        # å›¾æ£€ç´¢
        entities = self.kg.find_similar_entities(question, top_k=3)
        subgraph = self.kg.get_subgraph(entities, hops=1)
        graph_context = self.kg.subgraph_to_text(subgraph)
        
        # åˆå¹¶ä¸Šä¸‹æ–‡
        combined_context = f"""
æ–‡æ¡£ç‰‡æ®µï¼š
{vector_context}

çŸ¥è¯†å›¾è°±ï¼š
{graph_context}
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": f"æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ã€‚\n\n{combined_context}"
                },
                {"role": "user", "content": question}
            ]
        )
        
        return response.choices[0].message.content
```

## LlamaIndex GraphRAG

```python
from llama_index.core import KnowledgeGraphIndex, SimpleDirectoryReader
from llama_index.core import StorageContext
from llama_index.graph_stores.neo4j import Neo4jGraphStore

# é…ç½® Neo4j
graph_store = Neo4jGraphStore(
    username="neo4j",
    password="password",
    url="bolt://localhost:7687",
    database="neo4j"
)

storage_context = StorageContext.from_defaults(graph_store=graph_store)

# åŠ è½½æ–‡æ¡£
documents = SimpleDirectoryReader("./data").load_data()

# æ„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•
index = KnowledgeGraphIndex.from_documents(
    documents,
    storage_context=storage_context,
    max_triplets_per_chunk=10,
    include_embeddings=True
)

# æŸ¥è¯¢
query_engine = index.as_query_engine(
    include_text=True,
    response_mode="tree_summarize"
)

response = query_engine.query("ä¸»è¦äººç‰©ä¹‹é—´çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ")
```

## ç¤¾åŒºæ£€æµ‹ä¸æ‘˜è¦

```python
from networkx.algorithms import community

def detect_communities(kg: KnowledgeGraph) -> list[set]:
    """æ£€æµ‹ç¤¾åŒº"""
    # è½¬æ¢ä¸ºæ— å‘å›¾è¿›è¡Œç¤¾åŒºæ£€æµ‹
    undirected = kg.graph.to_undirected()
    communities = community.louvain_communities(undirected)
    return communities

def summarize_community(kg: KnowledgeGraph, nodes: set) -> str:
    """ç”Ÿæˆç¤¾åŒºæ‘˜è¦"""
    subgraph = kg.graph.subgraph(nodes)
    context = kg.subgraph_to_text(subgraph)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å›¾è°±ç‰‡æ®µï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ã€‚"
            },
            {"role": "user", "content": context}
        ],
        max_tokens=500
    )
    
    return response.choices[0].message.content

# å…¨å±€æŸ¥è¯¢ï¼šä½¿ç”¨ç¤¾åŒºæ‘˜è¦
def global_query(kg: KnowledgeGraph, question: str) -> str:
    communities = detect_communities(kg)
    summaries = [summarize_community(kg, c) for c in communities[:5]]
    
    combined = "\n\n".join([f"ä¸»é¢˜ {i+1}ï¼š{s}" for i, s in enumerate(summaries)])
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": f"æ ¹æ®ä»¥ä¸‹ä¸»é¢˜æ‘˜è¦å›ç­”é—®é¢˜ã€‚\n\n{combined}"
            },
            {"role": "user", "content": question}
        ]
    )
    
    return response.choices[0].message.content
```

## æœ€ä½³å®è·µ

1. **é€‰æ‹©åˆé€‚çš„åœºæ™¯**ï¼šå…³ç³»å¯†é›†çš„æ•°æ®æ›´é€‚åˆ GraphRAG
2. **æ§åˆ¶å›¾è§„æ¨¡**ï¼šå¤§å›¾éœ€è¦åˆ†åŒºæˆ–é‡‡æ ·
3. **æ··åˆä½¿ç”¨**ï¼šç»“åˆå‘é‡æ£€ç´¢å’Œå›¾æ£€ç´¢
4. **å¢é‡æ›´æ–°**ï¼šæ”¯æŒå›¾è°±çš„å¢é‡æ„å»º
5. **è´¨é‡æ§åˆ¶**ï¼šéªŒè¯æå–çš„å®ä½“å’Œå…³ç³»

## å»¶ä¼¸é˜…è¯»

- [Microsoft GraphRAG](https://github.com/microsoft/graphrag)
- [LlamaIndex Knowledge Graph](https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/)
- [Neo4j + LLM](https://neo4j.com/developer/genai/)