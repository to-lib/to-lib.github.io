---
sidebar_position: 11
title: 🚀 Production（生产化与部署）
---

# Production（生产化与部署）

把 Demo 变成可用的生产系统，关键是“稳定、可观测、可控成本”。本页从延迟、稳定性、缓存、观测与发布策略总结常用做法。

## 典型生产架构

- **API Gateway**：鉴权、限流、配额。
- **LLM Service**：封装模型调用、工具调用、重试与降级。
- **RAG Service**（可选）：索引、检索、重排序。
- **Observability**：日志、指标、追踪、评估回放。

## 延迟优化

- **模型选择**：默认用小模型，必要时升级大模型（分层路由）。
- **流式输出**：前端体验显著提升。
- **并行化**：检索、工具调用、补充查询并行执行。
- **减少 token**：压缩上下文、摘要历史、只带必要字段。

## 稳定性与容错

- **重试策略**：对 429/5xx 做指数退避；避免无脑重试。
- **超时与取消**：所有外部依赖（模型/向量库/搜索）都要超时。
- **幂等与去重**：对相同请求做请求 ID，避免重复扣费。
- **降级**：
  - 关闭 RAG（只用基础回答）
  - 降级到小模型
  - 返回可解释的 fallback 文案

## 成本控制

- **缓存**：
  - Prompt + 参数 + 关键上下文 hash 作为 key
  - 对检索结果缓存（短 TTL）
- **批处理**：适用于离线任务。
- **分层路由**：简单问题小模型回答，复杂问题升级。
- **预算与配额**：按用户/租户/业务线设置日预算。

## 可观测性（Observability）

建议至少记录：

- 请求链路：request_id、user_id、model、token 使用、耗时
- RAG：query、Top-K 文档 id、重排序结果
- 工具调用：工具名、参数（脱敏）、结果摘要、耗时
- 输出：脱敏后保存（便于回放与评估）

## 发布与回滚

- **灰度发布**：新版本先 1%-5% 流量。
- **开关（Feature Flag）**：prompt、检索策略、工具集可动态切换。
- **一键回滚**：版本/配置分离，避免紧急时重新发版。

## 延伸阅读

- https://platform.openai.com/docs/guides/latency-optimization
