---
sidebar_position: 8
title: ğŸ“‹ å¿«é€Ÿå‚è€ƒ
---

# AI å¼€å‘å¿«é€Ÿå‚è€ƒ

æœ¬æ–‡æ±‡æ€» AI å¼€å‘ä¸­å¸¸ç”¨çš„ APIã€å‚æ•°ã€å‘½ä»¤å’Œä»£ç ç‰‡æ®µï¼Œä¾¿äºå¿«é€ŸæŸ¥é˜…ã€‚

## æ¨¡å‹å‚æ•°é€ŸæŸ¥

### é€šç”¨ç”Ÿæˆå‚æ•°

| å‚æ•°                | èŒƒå›´         | æ¨èå€¼   | è¯´æ˜                   |
| ------------------- | ------------ | -------- | ---------------------- |
| `temperature`       | 0.0 - 2.0    | 0.7      | æ§åˆ¶éšæœºæ€§ï¼Œè¶Šé«˜è¶Šéšæœº |
| `top_p`             | 0.0 - 1.0    | 0.9      | æ ¸é‡‡æ ·é˜ˆå€¼             |
| `max_tokens`        | 1 - æ¨¡å‹ä¸Šé™ | æŒ‰éœ€è®¾ç½® | æœ€å¤§è¾“å‡º token æ•°      |
| `frequency_penalty` | -2.0 - 2.0   | 0        | æƒ©ç½šé‡å¤ token         |
| `presence_penalty`  | -2.0 - 2.0   | 0        | æƒ©ç½šé‡å¤ä¸»é¢˜           |

### åœºæ™¯æ¨èé…ç½®

| åœºæ™¯     | temperature | top_p | è¯´æ˜             |
| -------- | ----------- | ----- | ---------------- |
| ä»£ç ç”Ÿæˆ | 0.0 - 0.2   | 0.9   | ç¡®å®šæ€§ï¼Œå‡å°‘é”™è¯¯ |
| æ–‡æ¡£å†™ä½œ | 0.5 - 0.7   | 0.9   | å¹³è¡¡å‡†ç¡®ä¸æµç•…   |
| åˆ›æ„å†™ä½œ | 0.8 - 1.0   | 0.95  | å¢åŠ åˆ›æ„         |
| æ•°æ®æå– | 0.0         | 1.0   | ä¸¥æ ¼ç¡®å®šæ€§       |
| èŠå¤©å¯¹è¯ | 0.7         | 0.9   | è‡ªç„¶å¯¹è¯         |

## API ç«¯ç‚¹é€ŸæŸ¥

### OpenAI

| åŠŸèƒ½        | ç«¯ç‚¹                            |
| ----------- | ------------------------------- |
| Chat        | `POST /v1/chat/completions`     |
| Embeddings  | `POST /v1/embeddings`           |
| Images      | `POST /v1/images/generations`   |
| Audio (TTS) | `POST /v1/audio/speech`         |
| Audio (STT) | `POST /v1/audio/transcriptions` |

### Anthropic

| åŠŸèƒ½     | ç«¯ç‚¹                |
| -------- | ------------------- |
| Messages | `POST /v1/messages` |

## å¸¸ç”¨ä»£ç ç‰‡æ®µ

### OpenAI Chat Completion

```python
from openai import OpenAI

client = OpenAI(api_key="your-key")

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    temperature=0.7,
    max_tokens=500
)

print(response.choices[0].message.content)
```

### OpenAI Embedding

```python
response = client.embeddings.create(
    model="text-embedding-3-small",
    input="Your text here"
)

embedding = response.data[0].embedding  # 1536 ç»´å‘é‡
```

### Anthropic Messages

```python
import anthropic

client = anthropic.Anthropic(api_key="your-key")

message = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)

print(message.content[0].text)
```

### LangChain åŸºç¡€

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

llm = ChatOpenAI(model="gpt-4o", temperature=0.7)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="Hello!")
]

response = llm.invoke(messages)
print(response.content)
```

### LangChain RAG ç®€åŒ–ç‰ˆ

```python
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. åˆ‡åˆ†æ–‡æ¡£
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_documents(documents)

# 2. å­˜å…¥å‘é‡åº“
vectorstore = Chroma.from_documents(chunks, OpenAIEmbeddings())

# 3. æ£€ç´¢
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
docs = retriever.invoke("your question")

# 4. ç”Ÿæˆå›ç­”
llm = ChatOpenAI(model="gpt-4o")
context = "\n".join([doc.page_content for doc in docs])
prompt = f"Context:\n{context}\n\nQuestion: your question\n\nAnswer:"
response = llm.invoke(prompt)
```

## Embedding æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹                   | æä¾›å•† | ç»´åº¦ | æœ€å¤§ Token | ç‰¹ç‚¹         |
| ---------------------- | ------ | ---- | ---------- | ------------ |
| text-embedding-3-small | OpenAI | 1536 | 8191       | ç»æµå®æƒ      |
| text-embedding-3-large | OpenAI | 3072 | 8191       | é«˜ç²¾åº¦       |
| text-embedding-ada-002 | OpenAI | 1536 | 8191       | æ—§ç‰ˆæœ¬       |
| bge-large-zh           | BAAI   | 1024 | 512        | ä¸­æ–‡æœ€ä½³å¼€æº |
| m3e-base               | Moka   | 768  | 512        | ä¸­æ–‡å¼€æº     |

## å‘é‡æ•°æ®åº“å¯¹æ¯”

| æ•°æ®åº“            | ç±»å‹ | ç‰¹ç‚¹            |
| ----------------- | ---- | --------------- |
| **Pinecone**      | æ‰˜ç®¡ | æ˜“ç”¨ï¼Œè‡ªåŠ¨æ‰©å±•  |
| **Chroma**        | å¼€æº | è½»é‡ï¼Œå¼€å‘å‹å¥½  |
| **Milvus**        | å¼€æº | é«˜æ€§èƒ½ï¼Œç”Ÿäº§çº§  |
| **Qdrant**        | å¼€æº | Rust å®ç°ï¼Œå¿«é€Ÿ |
| **pgvector**      | æ‰©å±• | PostgreSQL æ’ä»¶ |
| **Elasticsearch** | æ‰©å±• | æ··åˆæ£€ç´¢        |

## Prompt æ¨¡æ¿

### é€šç”¨åŠ©æ‰‹

```
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ {é¢†åŸŸ} åŠ©æ‰‹ã€‚
è¯·ä»¥ç®€æ´ã€å‡†ç¡®çš„æ–¹å¼å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
å¦‚æœä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯šå®è¯´æ˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}
```

### RAG é—®ç­”

```
è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚åªä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„ä¿¡æ¯ï¼Œä¸è¦ç¼–é€ ã€‚
å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´"æˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

å›ç­”ï¼š
```

### ç»“æ„åŒ–è¾“å‡º

```
è¯·åˆ†æä»¥ä¸‹å†…å®¹å¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºç»“æœã€‚

å†…å®¹ï¼š
{content}

è¾“å‡ºæ ¼å¼ï¼š
{format_schema}
```

## å¸¸ç”¨å‘½ä»¤

### å®‰è£…ä¾èµ–

```bash
# OpenAI
pip install openai

# Anthropic
pip install anthropic

# LangChain
pip install langchain langchain-openai langchain-community

# å‘é‡æ•°æ®åº“
pip install chromadb
pip install pinecone-client
```

### ç¯å¢ƒå˜é‡

```bash
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
```

## Token è®¡ç®—

```python
import tiktoken

def count_tokens(text: str, model: str = "gpt-4o") -> int:
    enc = tiktoken.encoding_for_model(model)
    return len(enc.encode(text))

# ä½¿ç”¨
tokens = count_tokens("Hello, world!")
print(f"Token æ•°é‡: {tokens}")
```

## æˆæœ¬ä¼°ç®—

| æ¨¡å‹              | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼  |
| ----------------- | -------- | --------- |
| GPT-4o            | $2.50/1M | $10.00/1M |
| GPT-4o-mini       | $0.15/1M | $0.60/1M  |
| Claude 3.5 Sonnet | $3.00/1M | $15.00/1M |
| Claude 3.5 Haiku  | $0.25/1M | $1.25/1M  |

_ä»·æ ¼å•ä½ï¼šç¾å…ƒ/ç™¾ä¸‡ tokenï¼Œæ•°æ®æ›´æ–°äº 2024 å¹´_
