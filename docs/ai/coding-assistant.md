---
sidebar_position: 33
title: ğŸ’» AI ç¼–ç åŠ©æ‰‹å¼€å‘
---

# AI ç¼–ç åŠ©æ‰‹å¼€å‘

æ„å»ºç±»ä¼¼ GitHub Copilot çš„ AI ç¼–ç åŠ©æ‰‹ï¼ŒåŒ…æ‹¬ä»£ç è¡¥å…¨ã€ä»£ç ç”Ÿæˆã€ä»£ç è§£é‡Šç­‰åŠŸèƒ½ã€‚

## æ ¸å¿ƒåŠŸèƒ½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AI ç¼–ç åŠ©æ‰‹                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ä»£ç è¡¥å…¨ï¼šæ ¹æ®ä¸Šä¸‹æ–‡è‡ªåŠ¨è¡¥å…¨ä»£ç                         â”‚
â”‚  ä»£ç ç”Ÿæˆï¼šæ ¹æ®æ³¨é‡Š/æè¿°ç”Ÿæˆä»£ç                         â”‚
â”‚  ä»£ç è§£é‡Šï¼šè§£é‡Šä»£ç åŠŸèƒ½å’Œé€»è¾‘                           â”‚
â”‚  ä»£ç é‡æ„ï¼šä¼˜åŒ–å’Œé‡æ„ç°æœ‰ä»£ç                            â”‚
â”‚  Bug ä¿®å¤ï¼šè¯†åˆ«å¹¶ä¿®å¤ä»£ç é—®é¢˜                           â”‚
â”‚  æµ‹è¯•ç”Ÿæˆï¼šè‡ªåŠ¨ç”Ÿæˆå•å…ƒæµ‹è¯•                             â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ä»£ç è¡¥å…¨

### åŸºç¡€å®ç°

````python
from openai import OpenAI

client = OpenAI()

def code_completion(
    prefix: str,
    suffix: str = "",
    language: str = "python",
    max_tokens: int = 150
) -> str:
    """ä»£ç è¡¥å…¨"""
    prompt = f"""Complete the following {language} code. Only return the completion, no explanation.

```{language}
{prefix}<CURSOR>{suffix}
```

Completion:"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=max_tokens,
        temperature=0
    )

    return response.choices[0].message.content


# ä½¿ç”¨ Fill-in-the-Middle (FIM)
def fim_completion(prefix: str, suffix: str) -> str:
    """FIM æ¨¡å¼è¡¥å…¨"""
    response = client.completions.create(
        model="gpt-3.5-turbo-instruct",
        prompt=f"<|fim_prefix|>{prefix}<|fim_suffix|>{suffix}<|fim_middle|>",
        max_tokens=150,
        temperature=0
    )
    return response.choices[0].text
````

### ä¸Šä¸‹æ–‡æ”¶é›†

```python
import os
from pathlib import Path

class CodeContext:
    """ä»£ç ä¸Šä¸‹æ–‡æ”¶é›†å™¨"""

    def __init__(self, workspace_path: str):
        self.workspace = Path(workspace_path)

    def get_file_content(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶å†…å®¹"""
        full_path = self.workspace / file_path
        if full_path.exists():
            return full_path.read_text()
        return ""

    def get_related_files(self, current_file: str, max_files: int = 5) -> list:
        """è·å–ç›¸å…³æ–‡ä»¶"""
        current = Path(current_file)
        related = []

        # åŒç›®å½•æ–‡ä»¶
        for f in current.parent.glob(f"*{current.suffix}"):
            if f != current and len(related) < max_files:
                related.append(str(f))

        return related

    def build_context(
        self,
        current_file: str,
        cursor_line: int,
        cursor_col: int
    ) -> dict:
        """æ„å»ºè¡¥å…¨ä¸Šä¸‹æ–‡"""
        content = self.get_file_content(current_file)
        lines = content.split("\n")

        # åˆ†å‰²å‰ç¼€å’Œåç¼€
        prefix_lines = lines[:cursor_line]
        suffix_lines = lines[cursor_line:]

        if prefix_lines:
            prefix_lines[-1] = prefix_lines[-1][:cursor_col]
        if suffix_lines:
            suffix_lines[0] = suffix_lines[0][cursor_col:]

        prefix = "\n".join(prefix_lines)
        suffix = "\n".join(suffix_lines)

        # è·å–ç›¸å…³æ–‡ä»¶ä½œä¸ºé¢å¤–ä¸Šä¸‹æ–‡
        related = self.get_related_files(current_file)
        related_content = []
        for f in related[:3]:
            related_content.append({
                "file": f,
                "content": self.get_file_content(f)[:2000]  # é™åˆ¶é•¿åº¦
            })

        return {
            "prefix": prefix,
            "suffix": suffix,
            "related_files": related_content,
            "language": self._detect_language(current_file)
        }

    def _detect_language(self, file_path: str) -> str:
        """æ£€æµ‹ç¼–ç¨‹è¯­è¨€"""
        ext_map = {
            ".py": "python",
            ".js": "javascript",
            ".ts": "typescript",
            ".java": "java",
            ".go": "go",
            ".rs": "rust"
        }
        ext = Path(file_path).suffix
        return ext_map.get(ext, "text")
```

## ä»£ç ç”Ÿæˆ

```python
def generate_code(
    description: str,
    language: str = "python",
    context: str = ""
) -> str:
    """æ ¹æ®æè¿°ç”Ÿæˆä»£ç """
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ {language} å¼€å‘è€…ã€‚
æ ¹æ®ç”¨æˆ·æè¿°ç”Ÿæˆé«˜è´¨é‡ä»£ç ã€‚

è¦æ±‚ï¼š
1. ä»£ç ç®€æ´ã€é«˜æ•ˆ
2. æ·»åŠ å¿…è¦çš„æ³¨é‡Š
3. éµå¾ª {language} æœ€ä½³å®è·µ
4. å¤„ç†è¾¹ç•Œæƒ…å†µ"""

    user_prompt = f"æè¿°ï¼š{description}"
    if context:
        user_prompt = f"ä¸Šä¸‹æ–‡ï¼š\n{context}\n\n{user_prompt}"

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.2
    )

    return response.choices[0].message.content

def generate_from_comment(code_with_comment: str) -> str:
    """æ ¹æ®æ³¨é‡Šç”Ÿæˆä»£ç """
    prompt = f"""æ ¹æ®æ³¨é‡Šç”Ÿæˆä»£ç å®ç°ï¼š

```

{code_with_comment}

```

åªè¿”å›å®Œæ•´çš„ä»£ç ï¼ŒåŒ…å«æ³¨é‡Šã€‚"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    return response.choices[0].message.content
```

## ä»£ç è§£é‡Š

````python
def explain_code(code: str, detail_level: str = "medium") -> str:
    """è§£é‡Šä»£ç """
    detail_prompts = {
        "brief": "ç”¨ä¸€ä¸¤å¥è¯ç®€è¦è¯´æ˜è¿™æ®µä»£ç çš„åŠŸèƒ½ã€‚",
        "medium": "è§£é‡Šè¿™æ®µä»£ç çš„åŠŸèƒ½ã€ä¸»è¦é€»è¾‘å’Œå…³é”®æ­¥éª¤ã€‚",
        "detailed": "è¯¦ç»†è§£é‡Šè¿™æ®µä»£ç ï¼ŒåŒ…æ‹¬æ¯ä¸ªå‡½æ•°ã€å˜é‡çš„ä½œç”¨ï¼Œç®—æ³•é€»è¾‘ï¼Œä»¥åŠå¯èƒ½çš„æ”¹è¿›ç‚¹ã€‚"
    }

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": f"ä½ æ˜¯ä¸€ä¸ªä»£ç è§£é‡Šä¸“å®¶ã€‚{detail_prompts[detail_level]}"
            },
            {"role": "user", "content": f"```\n{code}\n```"}
        ]
    )

    return response.choices[0].message.content

def explain_error(code: str, error_message: str) -> str:
    """è§£é‡Šé”™è¯¯"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "åˆ†æä»£ç é”™è¯¯ï¼Œè§£é‡ŠåŸå› å¹¶æä¾›ä¿®å¤æ–¹æ¡ˆã€‚"
            },
            {
                "role": "user",
                "content": f"ä»£ç ï¼š\n```\n{code}\n```\n\né”™è¯¯ä¿¡æ¯ï¼š\n{error_message}"
            }
        ]
    )

    return response.choices[0].message.content
````

## ä»£ç é‡æ„

````python
def refactor_code(
    code: str,
    refactor_type: str = "general"
) -> str:
    """ä»£ç é‡æ„"""
    refactor_prompts = {
        "general": "ä¼˜åŒ–ä»£ç ç»“æ„ã€å¯è¯»æ€§å’Œæ€§èƒ½",
        "performance": "ä¸“æ³¨äºæ€§èƒ½ä¼˜åŒ–",
        "readability": "æé«˜ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§",
        "security": "ä¿®å¤å®‰å…¨é—®é¢˜",
        "modern": "ä½¿ç”¨ç°ä»£è¯­æ³•å’Œæœ€ä½³å®è·µé‡å†™"
    }

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": f"ä½ æ˜¯ä»£ç é‡æ„ä¸“å®¶ã€‚ä»»åŠ¡ï¼š{refactor_prompts[refactor_type]}ã€‚è¿”å›é‡æ„åçš„ä»£ç å’Œæ”¹åŠ¨è¯´æ˜ã€‚"
            },
            {"role": "user", "content": f"```\n{code}\n```"}
        ]
    )

    return response.choices[0].message.content
````

## æµ‹è¯•ç”Ÿæˆ

````python
def generate_tests(
    code: str,
    framework: str = "pytest"
) -> str:
    """ç”Ÿæˆå•å…ƒæµ‹è¯•"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": f"""ä¸ºä»£ç ç”Ÿæˆå…¨é¢çš„å•å…ƒæµ‹è¯•ã€‚
ä½¿ç”¨ {framework} æ¡†æ¶ã€‚
åŒ…å«ï¼šæ­£å¸¸æƒ…å†µã€è¾¹ç•Œæƒ…å†µã€å¼‚å¸¸æƒ…å†µã€‚"""
            },
            {"role": "user", "content": f"```\n{code}\n```"}
        ]
    )

    return response.choices[0].message.content
````

## å®Œæ•´ç¼–ç åŠ©æ‰‹

```python
class CodingAssistant:
    """AI ç¼–ç åŠ©æ‰‹"""

    def __init__(self, workspace: str = "."):
        self.client = OpenAI()
        self.context = CodeContext(workspace)
        self.conversation = []

    def complete(self, file_path: str, line: int, col: int) -> str:
        """ä»£ç è¡¥å…¨"""
        ctx = self.context.build_context(file_path, line, col)

        # æ„å»ºå¸¦ä¸Šä¸‹æ–‡çš„æç¤º
        related_context = ""
        for f in ctx["related_files"]:
            related_context += f"\n// {f['file']}\n{f['content'][:500]}\n"

        prompt = f"""Language: {ctx['language']}
Related files:{related_context}

Complete the code at <CURSOR>:
```

{ctx['prefix']}<CURSOR>{ctx['suffix']}

````"""

        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0
        )

        return response.choices[0].message.content

    def chat(self, message: str, code_context: str = "") -> str:
        """å¯¹è¯å¼ç¼–ç¨‹åŠ©æ‰‹"""
        self.conversation.append({"role": "user", "content": message})

        system = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ã€‚
å¸®åŠ©ç”¨æˆ·ç¼–å†™ã€è°ƒè¯•ã€ä¼˜åŒ–ä»£ç ã€‚
å›ç­”è¦ç®€æ´ã€å‡†ç¡®ã€å®ç”¨ã€‚"""

        if code_context:
            system += f"\n\nå½“å‰ä»£ç ä¸Šä¸‹æ–‡ï¼š\n```\n{code_context}\n```"

        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system},
                *self.conversation[-10:]  # ä¿ç•™æœ€è¿‘ 10 è½®
            ]
        )

        assistant_msg = response.choices[0].message.content
        self.conversation.append({"role": "assistant", "content": assistant_msg})

        return assistant_msg

    def fix_bug(self, code: str, bug_description: str) -> str:
        """ä¿®å¤ Bug"""
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ Bug ä¿®å¤ä¸“å®¶ã€‚åˆ†æé—®é¢˜ï¼Œæä¾›ä¿®å¤æ–¹æ¡ˆå’Œä¿®å¤åçš„ä»£ç ã€‚"
                },
                {
                    "role": "user",
                    "content": f"ä»£ç ï¼š\n```\n{code}\n```\n\né—®é¢˜æè¿°ï¼š{bug_description}"
                }
            ]
        )

        return response.choices[0].message.content

# ä½¿ç”¨
assistant = CodingAssistant("./my_project")
completion = assistant.complete("src/main.py", 10, 0)
answer = assistant.chat("å¦‚ä½•ä¼˜åŒ–è¿™ä¸ªå‡½æ•°çš„æ€§èƒ½ï¼Ÿ", code_context)
````

## æœ€ä½³å®è·µ

1. **ä¸Šä¸‹æ–‡å¾ˆé‡è¦**ï¼šæä¾›è¶³å¤Ÿçš„ä»£ç ä¸Šä¸‹æ–‡
2. **æµå¼è¾“å‡º**ï¼šè¡¥å…¨æ—¶ä½¿ç”¨æµå¼æå‡ä½“éªŒ
3. **ç¼“å­˜ç»“æœ**ï¼šç›¸ä¼¼è¯·æ±‚å¤ç”¨ç»“æœ
4. **æœ¬åœ°æ¨¡å‹**ï¼šè€ƒè™‘ä½¿ç”¨æœ¬åœ°æ¨¡å‹é™ä½å»¶è¿Ÿ
5. **å®‰å…¨è¿‡æ»¤**ï¼šè¿‡æ»¤æ•æ„Ÿä»£ç å’Œå‡­è¯

## å»¶ä¼¸é˜…è¯»

- [GitHub Copilot](https://github.com/features/copilot)
- [Continue.dev](https://continue.dev/)
- [Cursor](https://cursor.sh/)
