---
sidebar_position: 17
title: ğŸ“ ç»“æ„åŒ–è¾“å‡º
---

# ç»“æ„åŒ–è¾“å‡º (Structured Output)

ç»“æ„åŒ–è¾“å‡ºæ˜¯è®© LLM æŒ‰ç…§æŒ‡å®šçš„æ ¼å¼ï¼ˆå¦‚ JSONã€XMLï¼‰è¿”å›æ•°æ®çš„æŠ€æœ¯ã€‚è¿™å¯¹äºéœ€è¦ç¨‹åºè§£æ LLM è¾“å‡ºçš„åœºæ™¯è‡³å…³é‡è¦ã€‚

## ä¸ºä»€ä¹ˆéœ€è¦ç»“æ„åŒ–è¾“å‡ºï¼Ÿ

| é—®é¢˜           | è¯´æ˜                                   |
| -------------- | -------------------------------------- |
| **è§£æå›°éš¾**   | è‡ªç”±æ–‡æœ¬éš¾ä»¥å¯é åœ°æå–ç»“æ„åŒ–ä¿¡æ¯       |
| **æ ¼å¼ä¸ç¨³å®š** | åŒæ ·çš„ prompt å¯èƒ½è¿”å›ä¸åŒæ ¼å¼         |
| **ç±»å‹ä¸å®‰å…¨** | æ— æ³•ä¿è¯å­—æ®µç±»å‹æ­£ç¡®                   |
| **ç¼ºå¤±å­—æ®µ**   | æ¨¡å‹å¯èƒ½é—æ¼å¿…è¦å­—æ®µ                   |

## OpenAI JSON Mode

### åŸºç¡€ç”¨æ³•

```python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®æå–åŠ©æ‰‹ã€‚è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœã€‚"
        },
        {
            "role": "user",
            "content": "æå–ä»¥ä¸‹æ–‡æœ¬ä¸­çš„äººç‰©ä¿¡æ¯ï¼šå¼ ä¸‰ï¼Œç”·ï¼Œ30å²ï¼ŒåŒ—äº¬äººï¼Œè½¯ä»¶å·¥ç¨‹å¸ˆ"
        }
    ],
    response_format={"type": "json_object"}
)

import json
data = json.loads(response.choices[0].message.content)
print(data)
# {"name": "å¼ ä¸‰", "gender": "ç”·", "age": 30, "city": "åŒ—äº¬", "occupation": "è½¯ä»¶å·¥ç¨‹å¸ˆ"}
```

### æŒ‡å®š JSON Schema

```python
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {
            "role": "system",
            "content": """æå–äººç‰©ä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON Schema è¿”å›ï¼š
{
  "name": "string",
  "age": "number",
  "city": "string",
  "skills": ["string"]
}"""
        },
        {"role": "user", "content": "æå››ï¼Œ25å²ï¼Œä¸Šæµ·ï¼Œä¼š Python å’Œ Java"}
    ],
    response_format={"type": "json_object"}
)
```

## OpenAI Structured Outputsï¼ˆæ¨èï¼‰

OpenAI çš„ Structured Outputs åŠŸèƒ½å¯ä»¥ä¿è¯è¾“å‡ºä¸¥æ ¼ç¬¦åˆæŒ‡å®šçš„ JSON Schemaã€‚

### ä½¿ç”¨ Pydantic å®šä¹‰ Schema

```python
from openai import OpenAI
from pydantic import BaseModel
from typing import List, Optional

client = OpenAI()

# å®šä¹‰æ•°æ®æ¨¡å‹
class Person(BaseModel):
    name: str
    age: int
    city: str
    skills: List[str]
    email: Optional[str] = None

class ExtractionResult(BaseModel):
    people: List[Person]
    summary: str

# ä½¿ç”¨ parse æ–¹æ³•
completion = client.beta.chat.completions.parse(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ä»æ–‡æœ¬ä¸­æå–äººç‰©ä¿¡æ¯"},
        {"role": "user", "content": "å¼ ä¸‰30å²åœ¨åŒ—äº¬ä¼šPythonï¼›æå››25å²åœ¨ä¸Šæµ·ä¼šJavaå’ŒGo"}
    ],
    response_format=ExtractionResult
)

result = completion.choices[0].message.parsed
print(result.people[0].name)  # å¼ ä¸‰
print(result.summary)
```

### å¤æ‚åµŒå¥—ç»“æ„

```python
from pydantic import BaseModel, Field
from typing import List, Literal
from enum import Enum

class Priority(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"

class Task(BaseModel):
    title: str = Field(description="ä»»åŠ¡æ ‡é¢˜")
    description: str = Field(description="ä»»åŠ¡æè¿°")
    priority: Priority = Field(description="ä¼˜å…ˆçº§")
    estimated_hours: float = Field(ge=0, le=100, description="é¢„ä¼°å·¥æ—¶")

class ProjectPlan(BaseModel):
    project_name: str
    tasks: List[Task]
    total_hours: float
    risks: List[str]

completion = client.beta.chat.completions.parse(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯é¡¹ç›®è§„åˆ’åŠ©æ‰‹"},
        {"role": "user", "content": "å¸®æˆ‘è§„åˆ’ä¸€ä¸ªç”µå•†ç½‘ç«™é¡¹ç›®ï¼ŒåŒ…å«ç”¨æˆ·ç³»ç»Ÿã€å•†å“ç®¡ç†ã€è®¢å•ç³»ç»Ÿ"}
    ],
    response_format=ProjectPlan
)

plan = completion.choices[0].message.parsed
for task in plan.tasks:
    print(f"[{task.priority.value}] {task.title}: {task.estimated_hours}h")
```

## Anthropic ç»“æ„åŒ–è¾“å‡º

### ä½¿ç”¨ Tool Use å®ç°

```python
import anthropic
import json

client = anthropic.Anthropic()

# å®šä¹‰å·¥å…·ä½œä¸ºè¾“å‡ºæ ¼å¼
tools = [
    {
        "name": "extract_person",
        "description": "æå–äººç‰©ä¿¡æ¯",
        "input_schema": {
            "type": "object",
            "properties": {
                "name": {"type": "string", "description": "å§“å"},
                "age": {"type": "integer", "description": "å¹´é¾„"},
                "city": {"type": "string", "description": "åŸå¸‚"},
                "occupation": {"type": "string", "description": "èŒä¸š"}
            },
            "required": ["name", "age", "city"]
        }
    }
]

message = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    tools=tools,
    tool_choice={"type": "tool", "name": "extract_person"},  # å¼ºåˆ¶ä½¿ç”¨å·¥å…·
    messages=[
        {"role": "user", "content": "æå–ä¿¡æ¯ï¼šç‹äº”ï¼Œ28å²ï¼Œæ·±åœ³ï¼Œäº§å“ç»ç†"}
    ]
)

# è·å–ç»“æ„åŒ–è¾“å‡º
tool_use = next(block for block in message.content if block.type == "tool_use")
result = tool_use.input
print(result)
# {"name": "ç‹äº”", "age": 28, "city": "æ·±åœ³", "occupation": "äº§å“ç»ç†"}
```

## LangChain ç»“æ„åŒ–è¾“å‡º

### ä½¿ç”¨ with_structured_output

```python
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from typing import List

class MovieReview(BaseModel):
    """ç”µå½±è¯„è®ºåˆ†æç»“æœ"""
    movie_name: str = Field(description="ç”µå½±åç§°")
    sentiment: str = Field(description="æƒ…æ„Ÿå€¾å‘ï¼špositive/negative/neutral")
    score: float = Field(ge=0, le=10, description="è¯„åˆ†")
    keywords: List[str] = Field(description="å…³é”®è¯")
    summary: str = Field(description="ä¸€å¥è¯æ€»ç»“")

llm = ChatOpenAI(model="gpt-4o", temperature=0)
structured_llm = llm.with_structured_output(MovieReview)

result = structured_llm.invoke("è¿™éƒ¨ç”µå½±å¤ªç²¾å½©äº†ï¼å‰§æƒ…ç´§å‡‘ï¼Œæ¼”å‘˜æ¼”æŠ€åœ¨çº¿ï¼Œç‰¹æ•ˆéœ‡æ’¼ï¼Œå¼ºçƒˆæ¨èï¼")
print(f"æƒ…æ„Ÿ: {result.sentiment}, è¯„åˆ†: {result.score}")
```

### ä½¿ç”¨ PydanticOutputParser

```python
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate

parser = PydanticOutputParser(pydantic_object=MovieReview)

prompt = PromptTemplate(
    template="åˆ†æä»¥ä¸‹ç”µå½±è¯„è®ºï¼š\n{review}\n\n{format_instructions}",
    input_variables=["review"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

chain = prompt | llm | parser

result = chain.invoke({"review": "å‰§æƒ…æ‹–æ²“ï¼Œæ¼”æŠ€å°´å°¬ï¼Œæµªè´¹æ—¶é—´"})
```

## å®æˆ˜åº”ç”¨

### 1. ä¿¡æ¯æŠ½å–

```python
from pydantic import BaseModel
from typing import List, Optional

class ContactInfo(BaseModel):
    name: str
    phone: Optional[str] = None
    email: Optional[str] = None
    company: Optional[str] = None
    position: Optional[str] = None

class ExtractionResult(BaseModel):
    contacts: List[ContactInfo]
    raw_text: str

def extract_contacts(text: str) -> ExtractionResult:
    completion = client.beta.chat.completions.parse(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä»æ–‡æœ¬ä¸­æå–è”ç³»äººä¿¡æ¯"},
            {"role": "user", "content": text}
        ],
        response_format=ExtractionResult
    )
    return completion.choices[0].message.parsed

# ä½¿ç”¨
text = """
è¯·è”ç³»å¼ ç»ç†ï¼ˆæ‰‹æœºï¼š13800138000ï¼Œé‚®ç®±ï¼šzhang@example.comï¼‰
æˆ–è€…ææ€»ï¼ˆABCå…¬å¸CEOï¼Œç”µè¯ï¼š13900139000ï¼‰
"""
result = extract_contacts(text)
for contact in result.contacts:
    print(f"{contact.name}: {contact.phone}")
```

### 2. åˆ†ç±»ä»»åŠ¡

```python
from pydantic import BaseModel
from typing import Literal, List

class ClassificationResult(BaseModel):
    category: Literal["bug", "feature", "question", "other"]
    confidence: float
    reasoning: str
    suggested_labels: List[str]

def classify_issue(title: str, description: str) -> ClassificationResult:
    completion = client.beta.chat.completions.parse(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "å¯¹ GitHub Issue è¿›è¡Œåˆ†ç±»"},
            {"role": "user", "content": f"æ ‡é¢˜: {title}\næè¿°: {description}"}
        ],
        response_format=ClassificationResult
    )
    return completion.choices[0].message.parsed

# ä½¿ç”¨
result = classify_issue(
    "ç™»å½•æŒ‰é’®ç‚¹å‡»æ— å“åº”",
    "åœ¨ Chrome æµè§ˆå™¨ä¸Šç‚¹å‡»ç™»å½•æŒ‰é’®æ²¡æœ‰ä»»ä½•ååº”ï¼Œæ§åˆ¶å°æ˜¾ç¤º TypeError"
)
print(f"åˆ†ç±»: {result.category}, ç½®ä¿¡åº¦: {result.confidence}")
```

### 3. æ•°æ®è½¬æ¢

```python
from pydantic import BaseModel
from typing import List

class TableRow(BaseModel):
    date: str
    product: str
    quantity: int
    price: float
    total: float

class TableData(BaseModel):
    headers: List[str]
    rows: List[TableRow]

def text_to_table(text: str) -> TableData:
    """å°†éç»“æ„åŒ–æ–‡æœ¬è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®"""
    completion = client.beta.chat.completions.parse(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "å°†æ–‡æœ¬ä¸­çš„æ•°æ®è½¬æ¢ä¸ºè¡¨æ ¼æ ¼å¼"},
            {"role": "user", "content": text}
        ],
        response_format=TableData
    )
    return completion.choices[0].message.parsed

# ä½¿ç”¨
text = """
1æœˆ5æ—¥å–äº†10ä¸ªè‹¹æœï¼Œå•ä»·5å…ƒï¼›
1æœˆ6æ—¥å–äº†20ä¸ªæ©™å­ï¼Œå•ä»·3å…ƒï¼›
1æœˆ7æ—¥å–äº†15ä¸ªé¦™è•‰ï¼Œå•ä»·2å…ƒã€‚
"""
table = text_to_table(text)
for row in table.rows:
    print(f"{row.date}: {row.product} x {row.quantity} = {row.total}")
```

### 4. API å“åº”æ ¼å¼åŒ–

```python
from pydantic import BaseModel
from typing import List, Optional, Generic, TypeVar
from datetime import datetime

T = TypeVar('T')

class APIResponse(BaseModel, Generic[T]):
    success: bool
    data: Optional[T] = None
    error: Optional[str] = None
    timestamp: str

class UserProfile(BaseModel):
    id: int
    username: str
    email: str
    created_at: str

def generate_api_response(query: str) -> APIResponse[UserProfile]:
    """ç”Ÿæˆç¬¦åˆ API è§„èŒƒçš„å“åº”"""
    completion = client.beta.chat.completions.parse(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ç”Ÿæˆæ¨¡æ‹Ÿçš„ç”¨æˆ·æ•°æ® API å“åº”"},
            {"role": "user", "content": query}
        ],
        response_format=APIResponse[UserProfile]
    )
    return completion.choices[0].message.parsed
```

## é”™è¯¯å¤„ç†

```python
from openai import OpenAI
from pydantic import BaseModel, ValidationError

client = OpenAI()

class Output(BaseModel):
    name: str
    age: int

def safe_parse(text: str) -> Output | None:
    try:
        completion = client.beta.chat.completions.parse(
            model="gpt-4o",
            messages=[{"role": "user", "content": text}],
            response_format=Output
        )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ refusal
        if completion.choices[0].message.refusal:
            print(f"æ¨¡å‹æ‹’ç»: {completion.choices[0].message.refusal}")
            return None
        
        return completion.choices[0].message.parsed
        
    except ValidationError as e:
        print(f"éªŒè¯é”™è¯¯: {e}")
        return None
    except Exception as e:
        print(f"å…¶ä»–é”™è¯¯: {e}")
        return None
```

## æœ€ä½³å®è·µ

1. **Schema è®¾è®¡**
   - ä½¿ç”¨ Pydantic çš„ Field æ·»åŠ æè¿°
   - è®¾ç½®åˆç†çš„çº¦æŸï¼ˆgeã€leã€max_length ç­‰ï¼‰
   - ä½¿ç”¨ Optional æ ‡è®°å¯é€‰å­—æ®µ

2. **Prompt ä¼˜åŒ–**
   - åœ¨ system prompt ä¸­è¯´æ˜è¾“å‡ºæ ¼å¼è¦æ±‚
   - æä¾›ç¤ºä¾‹å¸®åŠ©æ¨¡å‹ç†è§£

3. **é”™è¯¯å¤„ç†**
   - å¤„ç† refusal æƒ…å†µ
   - æ·»åŠ é‡è¯•é€»è¾‘
   - éªŒè¯è¾“å‡ºæ•°æ®

4. **æ€§èƒ½è€ƒè™‘**
   - ç»“æ„åŒ–è¾“å‡ºå¯èƒ½å¢åŠ å»¶è¿Ÿ
   - å¤æ‚ Schema å¯èƒ½å½±å“å‡†ç¡®æ€§

## å»¶ä¼¸é˜…è¯»

- [OpenAI Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
- [LangChain Output Parsers](https://python.langchain.com/docs/modules/model_io/output_parsers/)
- [Pydantic æ–‡æ¡£](https://docs.pydantic.dev/)
