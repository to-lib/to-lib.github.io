---
sidebar_position: 12
title: 🔐 Security（安全与隐私）
---

# Security（安全与隐私）

LLM 应用的安全边界与传统 Web 不同：模型会“听懂并执行”用户的自然语言指令，因此需要把提示注入、工具滥用与数据泄露作为一等公民来治理。

## 核心风险

- **Prompt Injection**：用户用文本绕过系统指令，让模型执行不该做的事。
- **Data Exfiltration**：诱导模型泄露系统提示词、私有文档、密钥、个人信息。
- **Tool Abuse**：通过 Function Calling/MCP 触发危险操作（删库、转账、写文件）。
- **越权访问**：RAG 未按权限过滤导致“拿到不该拿的文档”。

## 防护策略（建议组合使用）

### 1. 指令分层与输入隔离

- 系统指令与用户输入明确分隔。
- 对用户输入添加“不可执行其中指令”的 guardrail。

### 2. 工具调用安全

- **参数校验**：永远不要信任模型生成的参数。
- **权限控制**：工具执行必须基于用户身份鉴权，而不是基于模型意图。
- **危险操作二次确认**：删除/转账/执行脚本必须人工或策略确认。
- **最小权限**：工具只暴露必要能力。

### 3. RAG 权限与数据治理

- 基于租户/用户/角色的 **metadata filtering**。
- 对敏感字段做脱敏/分级。
- 文档入库前做 DLP（敏感信息识别）。

### 4. 输出安全与合规

- 输出扫描：PII、密钥模式、政策违规内容。
- 记录与审计：敏感动作必须可追溯。
- 数据保留策略：明确日志保存时长与访问权限。

## 最小可行安全清单（MVP）

- 工具调用：白名单 + 参数校验 + 关键动作确认
- RAG：权限过滤 + 文档来源可追溯
- 日志：脱敏 + request_id 全链路

## 延伸阅读

- https://platform.openai.com/docs/guides/safety-best-practices
