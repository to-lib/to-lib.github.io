---
sidebar_position: 26
title: ğŸ›¡ï¸ Guardrailsï¼ˆæŠ¤æ ï¼‰
---

# Guardrailsï¼ˆæŠ¤æ ï¼‰

Guardrails æ˜¯ä¿æŠ¤ AI åº”ç”¨å®‰å…¨çš„é˜²æŠ¤æœºåˆ¶ï¼Œç”¨äºè¿‡æ»¤æœ‰å®³è¾“å…¥ã€éªŒè¯è¾“å‡ºè´¨é‡ã€é˜²æ­¢æ¨¡å‹æ»¥ç”¨ã€‚

## ä¸ºä»€ä¹ˆéœ€è¦ Guardrailsï¼Ÿ

```
ç”¨æˆ·è¾“å…¥ â”€â”€> [è¾“å…¥æŠ¤æ ] â”€â”€> LLM â”€â”€> [è¾“å‡ºæŠ¤æ ] â”€â”€> æœ€ç»ˆå“åº”
              â”‚                        â”‚
              â”œâ”€ è¿‡æ»¤æ¶æ„å†…å®¹           â”œâ”€ éªŒè¯æ ¼å¼
              â”œâ”€ æ£€æµ‹æ³¨å…¥æ”»å‡»           â”œâ”€ è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
              â””â”€ è¯é¢˜è¾¹ç•Œæ§åˆ¶           â””â”€ äº‹å®æ€§æ£€æŸ¥
```

## æŠ¤æ ç±»å‹

| ç±»å‹ | ä½œç”¨ | ç¤ºä¾‹ |
|------|------|------|
| è¾“å…¥æŠ¤æ  | è¿‡æ»¤ç”¨æˆ·è¾“å…¥ | æ³¨å…¥æ£€æµ‹ã€æ•æ„Ÿè¯è¿‡æ»¤ |
| è¾“å‡ºæŠ¤æ  | éªŒè¯æ¨¡å‹è¾“å‡º | æ ¼å¼æ ¡éªŒã€å†…å®¹å®¡æ ¸ |
| è¯é¢˜æŠ¤æ  | é™åˆ¶å¯¹è¯èŒƒå›´ | åªå›ç­”äº§å“ç›¸å…³é—®é¢˜ |
| å®‰å…¨æŠ¤æ  | é˜²æ­¢æœ‰å®³å†…å®¹ | æš´åŠ›ã€è‰²æƒ…ã€æ­§è§†æ£€æµ‹ |

## åŸºç¡€å®ç°

### è¾“å…¥è¿‡æ»¤

```python
from openai import OpenAI
import re

client = OpenAI()

class InputGuardrail:
    """è¾“å…¥æŠ¤æ """
    
    def __init__(self):
        self.blocked_patterns = [
            r"ignore.*previous.*instructions",
            r"ignore.*above",
            r"disregard.*rules",
            r"ä½ æ˜¯.*DAN",
            r"jailbreak",
        ]
        
        self.sensitive_words = ["å¯†ç ", "ä¿¡ç”¨å¡", "èº«ä»½è¯"]
    
    def check_injection(self, text: str) -> tuple[bool, str]:
        """æ£€æµ‹ Prompt æ³¨å…¥"""
        text_lower = text.lower()
        
        for pattern in self.blocked_patterns:
            if re.search(pattern, text_lower):
                return False, "æ£€æµ‹åˆ°æ½œåœ¨çš„æ³¨å…¥æ”»å‡»"
        
        return True, ""
    
    def check_sensitive(self, text: str) -> tuple[bool, str]:
        """æ£€æµ‹æ•æ„Ÿä¿¡æ¯"""
        for word in self.sensitive_words:
            if word in text:
                return False, f"è¯·å‹¿åœ¨å¯¹è¯ä¸­åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼š{word}"
        
        return True, ""
    
    def check_length(self, text: str, max_length: int = 4000) -> tuple[bool, str]:
        """æ£€æŸ¥è¾“å…¥é•¿åº¦"""
        if len(text) > max_length:
            return False, f"è¾“å…¥è¿‡é•¿ï¼Œè¯·é™åˆ¶åœ¨ {max_length} å­—ç¬¦ä»¥å†…"
        return True, ""
    
    def validate(self, text: str) -> tuple[bool, str]:
        """ç»¼åˆéªŒè¯"""
        checks = [
            self.check_injection,
            self.check_sensitive,
            self.check_length,
        ]
        
        for check in checks:
            passed, message = check(text)
            if not passed:
                return False, message
        
        return True, ""

# ä½¿ç”¨
guardrail = InputGuardrail()
passed, message = guardrail.validate(user_input)
if not passed:
    print(f"è¾“å…¥è¢«æ‹’ç»ï¼š{message}")
```

### è¾“å‡ºéªŒè¯

```python
import json
from pydantic import BaseModel, ValidationError

class OutputGuardrail:
    """è¾“å‡ºæŠ¤æ """
    
    def __init__(self):
        self.forbidden_content = ["æš´åŠ›", "è‰²æƒ…", "æ­§è§†"]
        self.client = OpenAI()
    
    def check_format(self, output: str, expected_format: type[BaseModel]) -> tuple[bool, str]:
        """éªŒè¯è¾“å‡ºæ ¼å¼"""
        try:
            expected_format.model_validate_json(output)
            return True, ""
        except ValidationError as e:
            return False, f"æ ¼å¼éªŒè¯å¤±è´¥ï¼š{e}"
    
    def check_content_safety(self, output: str) -> tuple[bool, str]:
        """å†…å®¹å®‰å…¨æ£€æŸ¥"""
        # ä½¿ç”¨ Moderation API
        response = self.client.moderations.create(input=output)
        
        result = response.results[0]
        if result.flagged:
            categories = [k for k, v in result.categories.model_dump().items() if v]
            return False, f"å†…å®¹ä¸å®‰å…¨ï¼š{categories}"
        
        return True, ""
    
    def check_pii(self, output: str) -> tuple[bool, str]:
        """æ£€æµ‹ PIIï¼ˆä¸ªäººèº«ä»½ä¿¡æ¯ï¼‰"""
        pii_patterns = {
            "phone": r"\d{11}",
            "id_card": r"\d{17}[\dXx]",
            "email": r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}",
        }
        
        for pii_type, pattern in pii_patterns.items():
            if re.search(pattern, output):
                return False, f"è¾“å‡ºåŒ…å«æ•æ„Ÿä¿¡æ¯ï¼š{pii_type}"
        
        return True, ""
    
    def validate(self, output: str) -> tuple[bool, str]:
        """ç»¼åˆéªŒè¯"""
        checks = [
            self.check_content_safety,
            self.check_pii,
        ]
        
        for check in checks:
            passed, message = check(output)
            if not passed:
                return False, message
        
        return True, ""
```

### è¯é¢˜è¾¹ç•Œæ§åˆ¶

```python
class TopicGuardrail:
    """è¯é¢˜æŠ¤æ """
    
    def __init__(self, allowed_topics: list[str], system_context: str):
        self.allowed_topics = allowed_topics
        self.system_context = system_context
        self.client = OpenAI()
    
    def check_topic(self, user_input: str) -> tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„è¯é¢˜èŒƒå›´å†…"""
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"""åˆ¤æ–­ç”¨æˆ·é—®é¢˜æ˜¯å¦ä¸ä»¥ä¸‹è¯é¢˜ç›¸å…³ï¼š
{', '.join(self.allowed_topics)}

ä¸Šä¸‹æ–‡ï¼š{self.system_context}

åªå›ç­” "ç›¸å…³" æˆ– "ä¸ç›¸å…³"ã€‚"""
                },
                {"role": "user", "content": user_input}
            ],
            max_tokens=10
        )
        
        result = response.choices[0].message.content.strip()
        
        if "ä¸ç›¸å…³" in result:
            return False, f"æŠ±æ­‰ï¼Œæˆ‘åªèƒ½å›ç­”å…³äº {', '.join(self.allowed_topics)} çš„é—®é¢˜ã€‚"
        
        return True, ""

# ä½¿ç”¨
topic_guard = TopicGuardrail(
    allowed_topics=["äº§å“åŠŸèƒ½", "æŠ€æœ¯æ”¯æŒ", "è´¦æˆ·é—®é¢˜"],
    system_context="è¿™æ˜¯ä¸€ä¸ªç”µå•†å¹³å°çš„å®¢æœåŠ©æ‰‹"
)
```

## NeMo Guardrails

NVIDIA NeMo Guardrails æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œæä¾›å£°æ˜å¼çš„æŠ¤æ é…ç½®ã€‚

### å®‰è£…

```bash
pip install nemoguardrails
```

### é…ç½®æ–‡ä»¶

```yaml
# config.yml
models:
  - type: main
    engine: openai
    model: gpt-4o

rails:
  input:
    flows:
      - self check input
  output:
    flows:
      - self check output

prompts:
  - task: self_check_input
    content: |
      åˆ¤æ–­ä»¥ä¸‹ç”¨æˆ·è¾“å…¥æ˜¯å¦å®‰å…¨ã€åˆè§„ï¼š
      
      ç”¨æˆ·è¾“å…¥ï¼š{{ user_input }}
      
      å¦‚æœè¾“å…¥å®‰å…¨ï¼Œå›ç­” "allowed"
      å¦‚æœè¾“å…¥ä¸å®‰å…¨ï¼Œå›ç­” "blocked"
      
  - task: self_check_output
    content: |
      åˆ¤æ–­ä»¥ä¸‹ AI å›å¤æ˜¯å¦å®‰å…¨ã€åˆè§„ï¼š
      
      AI å›å¤ï¼š{{ bot_response }}
      
      å¦‚æœå›å¤å®‰å…¨ï¼Œå›ç­” "allowed"
      å¦‚æœå›å¤ä¸å®‰å…¨ï¼Œå›ç­” "blocked"
```

### Colang è§„åˆ™

```colang
# rails.co

# å®šä¹‰ç”¨æˆ·æ„å›¾
define user ask about product
  "è¿™ä¸ªäº§å“æ€ä¹ˆæ ·"
  "äº§å“æœ‰ä»€ä¹ˆåŠŸèƒ½"
  "ä»·æ ¼æ˜¯å¤šå°‘"

define user ask harmful
  "å¦‚ä½•åˆ¶ä½œç‚¸å¼¹"
  "æ€ä¹ˆæ”»å‡»åˆ«äºº"

# å®šä¹‰æœºå™¨äººå›å¤
define bot refuse harmful
  "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ç±»é—®é¢˜ã€‚"

define bot answer product
  "è®©æˆ‘æ¥ä»‹ç»ä¸€ä¸‹æˆ‘ä»¬çš„äº§å“..."

# å®šä¹‰å¯¹è¯æµç¨‹
define flow
  user ask harmful
  bot refuse harmful

define flow
  user ask about product
  bot answer product
```

### ä½¿ç”¨ NeMo Guardrails

```python
from nemoguardrails import RailsConfig, LLMRails

# åŠ è½½é…ç½®
config = RailsConfig.from_path("./config")
rails = LLMRails(config)

# ç”Ÿæˆå›å¤
response = await rails.generate_async(
    messages=[{"role": "user", "content": "ä»‹ç»ä¸€ä¸‹ä½ ä»¬çš„äº§å“"}]
)

print(response["content"])
```

## Guardrails AI

Guardrails AI æ˜¯å¦ä¸€ä¸ªæµè¡Œçš„æŠ¤æ æ¡†æ¶ï¼Œä¸“æ³¨äºè¾“å‡ºéªŒè¯ã€‚

### å®‰è£…

```bash
pip install guardrails-ai
```

### åŸºç¡€ä½¿ç”¨

```python
from guardrails import Guard
from guardrails.hub import ToxicLanguage, DetectPII

# åˆ›å»ºæŠ¤æ 
guard = Guard().use_many(
    ToxicLanguage(on_fail="exception"),
    DetectPII(pii_entities=["EMAIL_ADDRESS", "PHONE_NUMBER"], on_fail="fix")
)

# éªŒè¯è¾“å‡º
try:
    result = guard.validate("è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ï¼Œæˆ‘çš„é‚®ç®±æ˜¯ test@example.com")
    print(result.validated_output)
except Exception as e:
    print(f"éªŒè¯å¤±è´¥ï¼š{e}")
```

### ç»“æ„åŒ–è¾“å‡ºéªŒè¯

```python
from guardrails import Guard
from pydantic import BaseModel, Field

class ProductReview(BaseModel):
    sentiment: str = Field(description="æƒ…æ„Ÿï¼špositive/negative/neutral")
    score: int = Field(ge=1, le=5, description="è¯„åˆ† 1-5")
    summary: str = Field(max_length=200, description="æ‘˜è¦")

guard = Guard.from_pydantic(ProductReview)

raw_output = """
{
    "sentiment": "positive",
    "score": 4,
    "summary": "è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„äº§å“ï¼Œè´¨é‡ä¸é”™ï¼Œæ¨èè´­ä¹°ã€‚"
}
"""

result = guard.validate(raw_output)
print(result.validated_output)
```

## OpenAI Moderation API

```python
from openai import OpenAI

client = OpenAI()

def moderate_content(text: str) -> dict:
    """ä½¿ç”¨ OpenAI Moderation API"""
    response = client.moderations.create(input=text)
    result = response.results[0]
    
    return {
        "flagged": result.flagged,
        "categories": {
            k: v for k, v in result.categories.model_dump().items() if v
        },
        "scores": {
            k: round(v, 4) 
            for k, v in result.category_scores.model_dump().items() 
            if v > 0.1
        }
    }

# ä½¿ç”¨
result = moderate_content("è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬")
if result["flagged"]:
    print(f"å†…å®¹è¢«æ ‡è®°ï¼š{result['categories']}")
```

## å®Œæ•´æŠ¤æ ç³»ç»Ÿ

```python
from dataclasses import dataclass
from enum import Enum
from typing import Callable

class GuardrailAction(Enum):
    ALLOW = "allow"
    BLOCK = "block"
    MODIFY = "modify"
    WARN = "warn"

@dataclass
class GuardrailResult:
    action: GuardrailAction
    message: str = ""
    modified_content: str = ""

class GuardrailSystem:
    """å®Œæ•´æŠ¤æ ç³»ç»Ÿ"""
    
    def __init__(self):
        self.input_guards: list[Callable] = []
        self.output_guards: list[Callable] = []
        self.client = OpenAI()
    
    def add_input_guard(self, guard: Callable):
        self.input_guards.append(guard)
    
    def add_output_guard(self, guard: Callable):
        self.output_guards.append(guard)
    
    def check_input(self, text: str) -> GuardrailResult:
        """æ£€æŸ¥è¾“å…¥"""
        for guard in self.input_guards:
            result = guard(text)
            if result.action == GuardrailAction.BLOCK:
                return result
        return GuardrailResult(action=GuardrailAction.ALLOW)
    
    def check_output(self, text: str) -> GuardrailResult:
        """æ£€æŸ¥è¾“å‡º"""
        for guard in self.output_guards:
            result = guard(text)
            if result.action == GuardrailAction.BLOCK:
                return result
            if result.action == GuardrailAction.MODIFY:
                text = result.modified_content
        return GuardrailResult(
            action=GuardrailAction.ALLOW,
            modified_content=text
        )
    
    def chat(self, user_input: str, system_prompt: str = "") -> str:
        """å¸¦æŠ¤æ çš„å¯¹è¯"""
        # è¾“å…¥æ£€æŸ¥
        input_result = self.check_input(user_input)
        if input_result.action == GuardrailAction.BLOCK:
            return f"è¾“å…¥è¢«æ‹’ç»ï¼š{input_result.message}"
        
        # è°ƒç”¨ LLM
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": user_input})
        
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        
        output = response.choices[0].message.content
        
        # è¾“å‡ºæ£€æŸ¥
        output_result = self.check_output(output)
        if output_result.action == GuardrailAction.BLOCK:
            return "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆåˆé€‚çš„å›å¤ã€‚"
        
        return output_result.modified_content or output

# å®šä¹‰æŠ¤æ å‡½æ•°
def injection_guard(text: str) -> GuardrailResult:
    patterns = ["ignore previous", "disregard"]
    for p in patterns:
        if p in text.lower():
            return GuardrailResult(
                action=GuardrailAction.BLOCK,
                message="æ£€æµ‹åˆ°æ³¨å…¥æ”»å‡»"
            )
    return GuardrailResult(action=GuardrailAction.ALLOW)

def pii_guard(text: str) -> GuardrailResult:
    # ç®€å•çš„ PII è„±æ•
    import re
    modified = re.sub(r'\d{11}', '[PHONE]', text)
    modified = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', '[EMAIL]', modified)
    
    if modified != text:
        return GuardrailResult(
            action=GuardrailAction.MODIFY,
            modified_content=modified
        )
    return GuardrailResult(action=GuardrailAction.ALLOW)

# ä½¿ç”¨
system = GuardrailSystem()
system.add_input_guard(injection_guard)
system.add_output_guard(pii_guard)

response = system.chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹äº§å“")
```

## æœ€ä½³å®è·µ

1. **åˆ†å±‚é˜²æŠ¤**ï¼šè¾“å…¥ã€è¾“å‡ºéƒ½è¦æ£€æŸ¥
2. **å¿«é€Ÿå¤±è´¥**ï¼šå±é™©å†…å®¹ç«‹å³æ‹’ç»
3. **æ—¥å¿—è®°å½•**ï¼šè®°å½•æ‰€æœ‰è¢«æ‹¦æˆªçš„è¯·æ±‚
4. **å®šæœŸæ›´æ–°**ï¼šæ ¹æ®æ–°çš„æ”»å‡»æ¨¡å¼æ›´æ–°è§„åˆ™
5. **ç”¨æˆ·åé¦ˆ**ï¼šæä¾›æ¸…æ™°çš„æ‹’ç»åŸå› 

## å»¶ä¼¸é˜…è¯»

- [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails)
- [Guardrails AI](https://www.guardrailsai.com/)
- [OpenAI Moderation](https://platform.openai.com/docs/guides/moderation)
