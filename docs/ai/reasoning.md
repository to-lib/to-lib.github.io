---
sidebar_position: 25
title: ğŸ§© Reasoning æ¨¡å‹
---

# Reasoning æ¨¡å‹ï¼ˆæ¨ç†æ¨¡å‹ï¼‰

Reasoning æ¨¡å‹ï¼ˆå¦‚ OpenAI o1/o3 ç³»åˆ—ï¼‰æ˜¯ä¸“é—¨ä¸ºå¤æ‚æ¨ç†ä»»åŠ¡è®¾è®¡çš„æ¨¡å‹ï¼Œé€šè¿‡"æ€è€ƒ"è¿‡ç¨‹æ¥è§£å†³æ•°å­¦ã€ç¼–ç¨‹ã€ç§‘å­¦ç­‰éœ€è¦æ·±åº¦æ¨ç†çš„é—®é¢˜ã€‚

## ä»€ä¹ˆæ˜¯ Reasoning æ¨¡å‹ï¼Ÿ

ä¼ ç»Ÿ LLM ç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼Œè€Œ Reasoning æ¨¡å‹ä¼šå…ˆè¿›è¡Œå†…éƒ¨æ¨ç†ï¼ˆChain of Thoughtï¼‰ï¼Œç„¶åç»™å‡ºç­”æ¡ˆã€‚

```
ä¼ ç»Ÿæ¨¡å‹ï¼š
é—®é¢˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> ç­”æ¡ˆ

Reasoning æ¨¡å‹ï¼š
é—®é¢˜ â”€â”€â”€> [å†…éƒ¨æ¨ç†è¿‡ç¨‹] â”€â”€â”€> ç­”æ¡ˆ
          (ä¸å¯è§/éƒ¨åˆ†å¯è§)
```

## æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹    | ç‰¹ç‚¹                     | é€‚ç”¨åœºæ™¯           | ä»·æ ¼ï¼ˆè¾“å…¥/è¾“å‡ºï¼‰  |
| ------- | ------------------------ | ------------------ | ------------------ |
| o1      | æœ€å¼ºæ¨ç†èƒ½åŠ›             | å¤æ‚æ•°å­¦ã€ç§‘å­¦ç ”ç©¶ | $15/$60 per 1M     |
| o1-mini | å¹³è¡¡æ¨ç†èƒ½åŠ›å’Œé€Ÿåº¦       | ç¼–ç¨‹ã€ä¸€èˆ¬æ¨ç†     | $3/$12 per 1M      |
| o1-pro  | æ›´é•¿æ€è€ƒæ—¶é—´ï¼Œæ›´é«˜å‡†ç¡®ç‡ | æœ€å¤æ‚é—®é¢˜         | æŒ‰éœ€å®šä»·           |
| o3      | ä¸‹ä¸€ä»£æ¨ç†æ¨¡å‹           | å‰æ²¿ç ”ç©¶           | å¾…å‘å¸ƒ             |

## åŸºç¡€ä½¿ç”¨

### OpenAI o1 API

```python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
    model="o1",  # æˆ– "o1-mini"
    messages=[
        {
            "role": "user",
            "content": "è¯æ˜ï¼šå¯¹äºä»»æ„æ­£æ•´æ•° nï¼ŒnÂ³ - n èƒ½è¢« 6 æ•´é™¤ã€‚"
        }
    ]
    # æ³¨æ„ï¼šo1 ä¸æ”¯æŒ temperatureã€top_p ç­‰å‚æ•°
    # ä¹Ÿä¸æ”¯æŒ system message
)

print(response.choices[0].message.content)
```

### æŸ¥çœ‹æ¨ç† Token

```python
response = client.chat.completions.create(
    model="o1",
    messages=[{"role": "user", "content": "è§£å†³è¿™ä¸ªé—®é¢˜..."}]
)

# æŸ¥çœ‹ token ä½¿ç”¨
usage = response.usage
print(f"è¾“å…¥ tokens: {usage.prompt_tokens}")
print(f"è¾“å‡º tokens: {usage.completion_tokens}")
print(f"æ¨ç† tokens: {usage.completion_tokens_details.reasoning_tokens}")
```

## o1 ä¸ GPT-4o çš„åŒºåˆ«

| ç‰¹æ€§           | o1                 | GPT-4o             |
| -------------- | ------------------ | ------------------ |
| System Message | âŒ ä¸æ”¯æŒ          | âœ… æ”¯æŒ            |
| Temperature    | âŒ å›ºå®šä¸º 1        | âœ… å¯è°ƒèŠ‚          |
| Streaming      | âŒ ä¸æ”¯æŒ          | âœ… æ”¯æŒ            |
| Function Call  | âœ… æ”¯æŒ            | âœ… æ”¯æŒ            |
| å›¾åƒè¾“å…¥       | âœ… æ”¯æŒï¼ˆo1ï¼‰      | âœ… æ”¯æŒ            |
| å“åº”é€Ÿåº¦       | è¾ƒæ…¢ï¼ˆéœ€è¦æ€è€ƒï¼‰   | è¾ƒå¿«               |
| æ¨ç†èƒ½åŠ›       | å¼º                 | ä¸€èˆ¬               |
| æˆæœ¬           | é«˜                 | ä¸­                 |

## é€‚ç”¨åœºæ™¯

### âœ… é€‚åˆä½¿ç”¨ o1 çš„åœºæ™¯

1. **å¤æ‚æ•°å­¦é—®é¢˜**
```python
response = client.chat.completions.create(
    model="o1",
    messages=[{
        "role": "user",
        "content": """
        æ±‚è§£å¾®åˆ†æ–¹ç¨‹ï¼šy'' + 4y' + 4y = e^(-2x)
        ç»™å‡ºé€šè§£å’Œç‰¹è§£ã€‚
        """
    }]
)
```

2. **ç®—æ³•è®¾è®¡**
```python
response = client.chat.completions.create(
    model="o1-mini",
    messages=[{
        "role": "user",
        "content": """
        è®¾è®¡ä¸€ä¸ªç®—æ³•ï¼Œåœ¨ O(n log n) æ—¶é—´å¤æ‚åº¦å†…æ‰¾å‡ºæ•°ç»„ä¸­
        æ‰€æœ‰å’Œä¸ºç›®æ ‡å€¼çš„ä¸‰å…ƒç»„ï¼Œä¸èƒ½æœ‰é‡å¤ã€‚
        """
    }]
)
```

3. **ä»£ç è°ƒè¯•ä¸ä¼˜åŒ–**
```python
response = client.chat.completions.create(
    model="o1-mini",
    messages=[{
        "role": "user",
        "content": f"""
        è¿™æ®µä»£ç æœ‰ä¸€ä¸ªå¾®å¦™çš„ bugï¼Œè¯·æ‰¾å‡ºå¹¶ä¿®å¤ï¼š
        
        ```python
        {buggy_code}
        ```
        
        é”™è¯¯ç°è±¡ï¼š{error_description}
        """
    }]
)
```

4. **ç§‘å­¦æ¨ç†**
```python
response = client.chat.completions.create(
    model="o1",
    messages=[{
        "role": "user",
        "content": """
        åˆ†æä»¥ä¸‹å®éªŒæ•°æ®ï¼Œæ¨æ–­å¯èƒ½çš„åŒ–å­¦ååº”æœºç†ï¼š
        [å®éªŒæ•°æ®...]
        """
    }]
)
```

### âŒ ä¸é€‚åˆä½¿ç”¨ o1 çš„åœºæ™¯

- ç®€å•é—®ç­”ï¼ˆç”¨ GPT-4o-miniï¼‰
- åˆ›æ„å†™ä½œï¼ˆç”¨ GPT-4oï¼‰
- éœ€è¦æµå¼è¾“å‡ºçš„åœºæ™¯
- æˆæœ¬æ•æ„Ÿçš„åœºæ™¯
- éœ€è¦å¿«é€Ÿå“åº”çš„åœºæ™¯

## æœ€ä½³å®è·µ

### 1. æä¾›æ¸…æ™°çš„é—®é¢˜æè¿°

```python
# âœ… å¥½çš„æç¤º
prompt = """
é—®é¢˜ï¼šä¸€ä¸ªè¢‹å­é‡Œæœ‰ 5 ä¸ªçº¢çƒå’Œ 3 ä¸ªè“çƒã€‚
ä¸æ”¾å›åœ°æŠ½å– 3 ä¸ªçƒï¼Œæ±‚è‡³å°‘æœ‰ 2 ä¸ªçº¢çƒçš„æ¦‚ç‡ã€‚

è¯·ï¼š
1. åˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„æƒ…å†µ
2. è®¡ç®—æ¯ç§æƒ…å†µçš„æ¦‚ç‡
3. ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
"""

# âŒ ä¸å¥½çš„æç¤º
prompt = "ç®—ä¸€ä¸‹æ¦‚ç‡"
```

### 2. åˆ†æ­¥éª¤è¦æ±‚

```python
prompt = """
è¯·è§£å†³ä»¥ä¸‹ç¼–ç¨‹é—®é¢˜ï¼š

é—®é¢˜ï¼šå®ç°ä¸€ä¸ª LRU ç¼“å­˜

è¦æ±‚ï¼š
1. é¦–å…ˆåˆ†æé—®é¢˜ï¼Œç¡®å®šæ•°æ®ç»“æ„
2. è®¾è®¡ç®—æ³•ï¼Œè¯´æ˜æ—¶é—´å¤æ‚åº¦
3. ç¼–å†™ä»£ç 
4. ç»™å‡ºæµ‹è¯•ç”¨ä¾‹
5. åˆ†æè¾¹ç•Œæƒ…å†µ
"""
```

### 3. æä¾›çº¦æŸæ¡ä»¶

```python
prompt = """
è®¾è®¡ä¸€ä¸ªåˆ†å¸ƒå¼é”çš„å®ç°æ–¹æ¡ˆã€‚

çº¦æŸæ¡ä»¶ï¼š
- å¿…é¡»ä¿è¯äº’æ–¥æ€§
- éœ€è¦å¤„ç†æ­»é”æƒ…å†µ
- æ”¯æŒå¯é‡å…¥
- è€ƒè™‘ç½‘ç»œåˆ†åŒºåœºæ™¯
- ä½¿ç”¨ Redis ä½œä¸ºå­˜å‚¨

è¯·ç»™å‡ºè¯¦ç»†çš„è®¾è®¡æ–¹æ¡ˆå’Œä¼ªä»£ç ã€‚
"""
```

## ä¸å…¶ä»–æ¨¡å‹é…åˆ

### è·¯ç”±ç­–ç•¥

```python
def route_to_model(query: str) -> str:
    """æ ¹æ®é—®é¢˜å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
    
    # ä½¿ç”¨å°æ¨¡å‹åˆ¤æ–­å¤æ‚åº¦
    complexity_check = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "user",
            "content": f"""åˆ¤æ–­ä»¥ä¸‹é—®é¢˜çš„å¤æ‚åº¦ï¼ˆ1-5åˆ†ï¼‰ï¼š
            
é—®é¢˜ï¼š{query}

åªè¿”å›æ•°å­—ã€‚"""
        }],
        max_tokens=10
    )
    
    try:
        complexity = int(complexity_check.choices[0].message.content.strip())
    except:
        complexity = 3
    
    if complexity >= 4:
        return "o1"
    elif complexity >= 3:
        return "o1-mini"
    else:
        return "gpt-4o-mini"

# ä½¿ç”¨
model = route_to_model(user_query)
response = client.chat.completions.create(
    model=model,
    messages=[{"role": "user", "content": user_query}]
)
```

### ä¸¤é˜¶æ®µå¤„ç†

```python
def two_stage_reasoning(problem: str) -> str:
    """ä¸¤é˜¶æ®µå¤„ç†ï¼šo1 æ¨ç† + GPT-4o æ¶¦è‰²"""
    
    # é˜¶æ®µ 1ï¼šä½¿ç”¨ o1 è¿›è¡Œæ¨ç†
    reasoning_response = client.chat.completions.create(
        model="o1-mini",
        messages=[{"role": "user", "content": problem}]
    )
    
    raw_answer = reasoning_response.choices[0].message.content
    
    # é˜¶æ®µ 2ï¼šä½¿ç”¨ GPT-4o æ¶¦è‰²è¾“å‡º
    polished_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "è¯·å°†ä»¥ä¸‹æŠ€æœ¯å†…å®¹æ•´ç†æˆæ¸…æ™°ã€æ˜“è¯»çš„æ ¼å¼ï¼Œä¿æŒå‡†ç¡®æ€§ã€‚"
            },
            {"role": "user", "content": raw_answer}
        ]
    )
    
    return polished_response.choices[0].message.content
```

## æˆæœ¬ä¼˜åŒ–

### 1. é—®é¢˜é¢„ç­›é€‰

```python
def needs_reasoning(query: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æ¨ç†æ¨¡å‹"""
    keywords = ["è¯æ˜", "æ¨å¯¼", "ç®—æ³•", "ä¼˜åŒ–", "åˆ†æ", "è®¾è®¡", "debug"]
    return any(kw in query for kw in keywords)

def smart_query(query: str) -> str:
    if needs_reasoning(query):
        model = "o1-mini"
    else:
        model = "gpt-4o-mini"
    
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": query}]
    )
    return response.choices[0].message.content
```

### 2. ç¼“å­˜æ¨ç†ç»“æœ

```python
import hashlib
import json

class ReasoningCache:
    def __init__(self):
        self.cache = {}
    
    def _hash_query(self, query: str) -> str:
        return hashlib.md5(query.encode()).hexdigest()
    
    def get(self, query: str) -> str | None:
        key = self._hash_query(query)
        return self.cache.get(key)
    
    def set(self, query: str, response: str):
        key = self._hash_query(query)
        self.cache[key] = response
    
    def query(self, query: str) -> str:
        # æ£€æŸ¥ç¼“å­˜
        cached = self.get(query)
        if cached:
            return cached
        
        # è°ƒç”¨ API
        response = client.chat.completions.create(
            model="o1-mini",
            messages=[{"role": "user", "content": query}]
        )
        
        result = response.choices[0].message.content
        self.set(query, result)
        return result
```

## å®æˆ˜ç¤ºä¾‹

### ä»£ç å®¡æŸ¥

```python
def code_review_with_reasoning(code: str, language: str = "Python") -> str:
    """ä½¿ç”¨æ¨ç†æ¨¡å‹è¿›è¡Œæ·±åº¦ä»£ç å®¡æŸ¥"""
    
    prompt = f"""
è¯·å¯¹ä»¥ä¸‹ {language} ä»£ç è¿›è¡Œæ·±åº¦å®¡æŸ¥ï¼š

```{language.lower()}
{code}
```

è¯·åˆ†æï¼š
1. æ½œåœ¨çš„ bug å’Œè¾¹ç•Œæƒ…å†µ
2. æ€§èƒ½é—®é¢˜å’Œä¼˜åŒ–å»ºè®®
3. å®‰å…¨æ¼æ´
4. ä»£ç é£æ ¼å’Œæœ€ä½³å®è·µ
5. å¯èƒ½çš„é‡æ„æ–¹å‘

å¯¹äºæ¯ä¸ªé—®é¢˜ï¼Œè¯·è¯´æ˜åŸå› å’Œä¿®å¤å»ºè®®ã€‚
"""
    
    response = client.chat.completions.create(
        model="o1-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.choices[0].message.content
```

### æ•°å­¦è¯æ˜

```python
def mathematical_proof(statement: str) -> str:
    """æ•°å­¦è¯æ˜"""
    
    prompt = f"""
è¯·è¯æ˜ä»¥ä¸‹æ•°å­¦å‘½é¢˜ï¼š

{statement}

è¦æ±‚ï¼š
1. ç»™å‡ºä¸¥æ ¼çš„æ•°å­¦è¯æ˜
2. è¯´æ˜ä½¿ç”¨çš„å®šç†å’Œå¼•ç†
3. å¦‚æœæœ‰å¤šç§è¯æ˜æ–¹æ³•ï¼Œç»™å‡ºæœ€ä¼˜é›…çš„ä¸€ç§
4. è§£é‡Šè¯æ˜çš„å…³é”®æ­¥éª¤
"""
    
    response = client.chat.completions.create(
        model="o1",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.choices[0].message.content
```

## å»¶ä¼¸é˜…è¯»

- [OpenAI o1 æ–‡æ¡£](https://platform.openai.com/docs/guides/reasoning)
- [o1 System Card](https://openai.com/index/openai-o1-system-card/)
