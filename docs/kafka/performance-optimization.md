---
sidebar_position: 8
title: "æ€§èƒ½ä¼˜åŒ–"
description: "Kafka æ€§èƒ½è°ƒä¼˜å’Œä¼˜åŒ–ç­–ç•¥"
---

# Kafka æ€§èƒ½ä¼˜åŒ–

## æ€§èƒ½æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡         | è¯´æ˜                     | ç›®æ ‡å€¼              |
| ------------ | ------------------------ | ------------------- |
| **ååé‡**   | æ¯ç§’æ¶ˆæ¯æ•°/å­—èŠ‚æ•°        | æ ¹æ®ä¸šåŠ¡éœ€æ±‚        |
| **å»¶è¿Ÿ**     | ç«¯åˆ°ç«¯å»¶è¿Ÿ               | < 10ms (ä½å»¶è¿Ÿåœºæ™¯) |
| **å¯ç”¨æ€§**   | é›†ç¾¤å¯ç”¨æ—¶é—´æ¯”ä¾‹         | 99.99%              |
| **å¤åˆ¶å»¶è¿Ÿ** | Leader-Follower åŒæ­¥å»¶è¿Ÿ | < 100ms             |

### ç›‘æ§å‘½ä»¤

```bash
# æŸ¥çœ‹ Topic ååé‡
kafka-consumer-groups.sh --describe \
  --group my-group \
  --bootstrap-server localhost:9092

# æ¶ˆè´¹è€…å»¶è¿Ÿ
kafka-consumer-groups.sh --describe \
  --group my-group \
  --bootstrap-server localhost:9092 | grep -E "LAG"
```

## ç”Ÿäº§è€…ä¼˜åŒ–

### æ‰¹é‡å‘é€é…ç½®

```java
Properties props = new Properties();

// æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ 16KBï¼‰
props.put("batch.size", 65536);  // 64KB

// ç­‰å¾…æ—¶é—´ï¼ˆé»˜è®¤ 0msï¼‰
props.put("linger.ms", 20);  // ç­‰å¾… 20ms å‡‘æ‰¹

// ç¼“å†²åŒºå¤§å°
props.put("buffer.memory", 67108864);  // 64MB

// å‹ç¼©ç±»å‹
props.put("compression.type", "lz4");
```

### å‹ç¼©å¯¹æ¯”

| å‹ç¼©ç±»å‹   | å‹ç¼©ç‡ | CPU æ¶ˆè€— | æ¨èåœºæ™¯         |
| ---------- | ------ | -------- | ---------------- |
| **none**   | æ—      | æ—        | ä½å»¶è¿Ÿï¼ŒCPU æ•æ„Ÿ |
| **gzip**   | æœ€é«˜   | é«˜       | å¸¦å®½å—é™         |
| **snappy** | ä¸­ç­‰   | ä½       | å¹³è¡¡é€‰æ‹©         |
| **lz4**    | ä¸­ç­‰   | æœ€ä½     | **ç”Ÿäº§æ¨è**     |
| **zstd**   | é«˜     | ä¸­       | å­˜å‚¨ä¼˜åŒ–         |

### å¼‚æ­¥å‘é€æœ€ä½³å®è·µ

```java
// å¼‚æ­¥å‘é€ + å›è°ƒ
for (int i = 0; i < 10000; i++) {
    ProducerRecord<String, String> record =
        new ProducerRecord<>("topic", "key-" + i, "value-" + i);

    producer.send(record, (metadata, exception) -> {
        if (exception != null) {
            // è®°å½•å¤±è´¥ï¼Œåç»­é‡è¯•
            logger.error("å‘é€å¤±è´¥", exception);
        }
    });

    // æ¯ 1000 æ¡è®°å½• flush ä¸€æ¬¡ï¼ˆå¯é€‰ï¼‰
    if (i % 1000 == 0) {
        producer.flush();
    }
}
```

## æ¶ˆè´¹è€…ä¼˜åŒ–

### æ‰¹é‡æ‹‰å–é…ç½®

```java
Properties props = new Properties();

// å•æ¬¡æ‹‰å–æœ€å¤§è®°å½•æ•°
props.put("max.poll.records", 500);

// æ‹‰å–æœ€å°å­—èŠ‚æ•°
props.put("fetch.min.bytes", 50000);  // 50KB

// æ‹‰å–æœ€å¤§ç­‰å¾…æ—¶é—´
props.put("fetch.max.wait.ms", 500);  // 500ms

// å•æ¬¡æ‹‰å–æœ€å¤§å­—èŠ‚æ•°
props.put("fetch.max.bytes", 52428800);  // 50MB
```

### å¤šçº¿ç¨‹æ¶ˆè´¹

```java
// æ–¹æ¡ˆä¸€ï¼šå¤šçº¿ç¨‹å¤„ç†æ¶ˆæ¯
ExecutorService executor = Executors.newFixedThreadPool(10);

while (running) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));

    for (ConsumerRecord<String, String> record : records) {
        executor.submit(() -> processRecord(record));
    }

    consumer.commitAsync();
}

// æ–¹æ¡ˆäºŒï¼šå¤šæ¶ˆè´¹è€…å®ä¾‹
int numConsumers = 3;
for (int i = 0; i < numConsumers; i++) {
    new Thread(new ConsumerRunnable(props, "topic")).start();
}
```

### æ¶ˆè´¹è€…ç§¯å‹å¤„ç†

```java
// è·³è¿‡æ—§æ¶ˆæ¯ï¼Œç›´æ¥æ¶ˆè´¹æœ€æ–°
props.put("auto.offset.reset", "latest");

// æˆ–è€…ä½¿ç”¨ seekToEnd
consumer.seekToEnd(consumer.assignment());
```

## Broker ä¼˜åŒ–

### æ—¥å¿—é…ç½®

```properties
# æ—¥å¿—æ®µå¤§å°ï¼ˆé»˜è®¤ 1GBï¼‰
log.segment.bytes=1073741824

# æ—¥å¿—ä¿ç•™æ—¶é—´
log.retention.hours=168

# æ—¥å¿—æ¸…ç†ç­–ç•¥
log.cleanup.policy=delete

# æ—¥å¿—åˆ·æ–°ç­–ç•¥
log.flush.interval.messages=10000
log.flush.interval.ms=1000
```

### ç½‘ç»œé…ç½®

```properties
# ç½‘ç»œçº¿ç¨‹æ•°
num.network.threads=8

# IO çº¿ç¨‹æ•°
num.io.threads=16

# Socket ç¼“å†²åŒº
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
```

### å‰¯æœ¬é…ç½®

```properties
# å‰¯æœ¬æ‹‰å–çº¿ç¨‹æ•°
num.replica.fetchers=4

# å‰¯æœ¬æ‹‰å–æœ€å¤§å­—èŠ‚æ•°
replica.fetch.max.bytes=10485760

# å‰¯æœ¬æ‹‰å–ç­‰å¾…æ—¶é—´
replica.fetch.wait.max.ms=500
```

## åˆ†åŒºä¼˜åŒ–

### åˆ†åŒºæ•°è®¡ç®—

```
åˆ†åŒºæ•° = max(ç”Ÿäº§ç«¯ååé‡/å•åˆ†åŒºç”Ÿäº§ååé‡, æ¶ˆè´¹ç«¯ååé‡/å•åˆ†åŒºæ¶ˆè´¹ååé‡)

ç¤ºä¾‹ï¼š
- ç›®æ ‡ååé‡: 1000 MB/s
- å•åˆ†åŒºç”Ÿäº§ååé‡: 100 MB/s
- å•åˆ†åŒºæ¶ˆè´¹ååé‡: 50 MB/s
- æ¨èåˆ†åŒºæ•° = max(10, 20) = 20
```

### åˆ†åŒºåˆ†é…ç­–ç•¥

```java
// æ¶ˆè´¹è€…åˆ†åŒºåˆ†é…ç­–ç•¥
props.put("partition.assignment.strategy",
    "org.apache.kafka.clients.consumer.CooperativeStickyAssignor");
```

## æ“ä½œç³»ç»Ÿä¼˜åŒ–

### æ–‡ä»¶ç³»ç»Ÿ

```bash
# ä½¿ç”¨ XFS æ–‡ä»¶ç³»ç»Ÿ
mkfs.xfs /dev/sdb

# æŒ‚è½½é€‰é¡¹
mount -o noatime,nodiratime /dev/sdb /data/kafka
```

### å†…æ ¸å‚æ•°

```bash
# /etc/sysctl.conf

# è™šæ‹Ÿå†…å­˜
vm.swappiness=1
vm.dirty_ratio=60
vm.dirty_background_ratio=5

# ç½‘ç»œ
net.core.wmem_max=2097152
net.core.rmem_max=2097152
net.ipv4.tcp_wmem=4096 65536 2048000
net.ipv4.tcp_rmem=4096 65536 2048000
net.core.netdev_max_backlog=50000

# åº”ç”¨é…ç½®
sysctl -p
```

### æ–‡ä»¶æè¿°ç¬¦

```bash
# /etc/security/limits.conf
* soft nofile 100000
* hard nofile 100000
```

## JVM ä¼˜åŒ–

### G1GC é…ç½®

```bash
export KAFKA_HEAP_OPTS="-Xms6g -Xmx6g"
export KAFKA_JVM_PERFORMANCE_OPTS="-server \
  -XX:+UseG1GC \
  -XX:MaxGCPauseMillis=20 \
  -XX:InitiatingHeapOccupancyPercent=35 \
  -XX:G1HeapRegionSize=16M \
  -XX:MinMetaspaceFreeRatio=50 \
  -XX:MaxMetaspaceFreeRatio=80"
```

### å †å†…å­˜å»ºè®®

| OS å†…å­˜ | Kafka å †å†…å­˜ | é¡µç¼“å­˜ |
| ------- | ------------ | ------ |
| 32 GB   | 6 GB         | 26 GB  |
| 64 GB   | 8 GB         | 56 GB  |
| 128 GB  | 12 GB        | 116 GB |

## æ€§èƒ½æµ‹è¯•

### ç”Ÿäº§è€…æµ‹è¯•

```bash
kafka-producer-perf-test.sh \
  --topic test-topic \
  --num-records 1000000 \
  --record-size 1000 \
  --throughput -1 \
  --producer-props \
    bootstrap.servers=localhost:9092 \
    batch.size=65536 \
    linger.ms=20 \
    compression.type=lz4
```

### æ¶ˆè´¹è€…æµ‹è¯•

```bash
kafka-consumer-perf-test.sh \
  --topic test-topic \
  --messages 1000000 \
  --threads 4 \
  --bootstrap-server localhost:9092
```

### ç«¯åˆ°ç«¯å»¶è¿Ÿæµ‹è¯•

```bash
kafka-run-class.sh kafka.tools.EndToEndLatency \
  localhost:9092 \
  test-topic \
  10000 \
  all \
  1024
```

## æ€§èƒ½ä¼˜åŒ–æ¸…å•

### ç”Ÿäº§è€…

- [ ] é…ç½®åˆé€‚çš„ `batch.size`ï¼ˆ32-64KBï¼‰
- [ ] è®¾ç½® `linger.ms`ï¼ˆ10-20msï¼‰
- [ ] å¯ç”¨å‹ç¼©ï¼ˆæ¨è lz4ï¼‰
- [ ] ä½¿ç”¨å¼‚æ­¥å‘é€ + å›è°ƒ

### æ¶ˆè´¹è€…

- [ ] å¢åŠ  `max.poll.records`
- [ ] é…ç½® `fetch.min.bytes`
- [ ] ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†
- [ ] åˆç†è®¾ç½®æ¶ˆè´¹è€…æ•°é‡

### Broker

- [ ] å¢åŠ ç½‘ç»œå’Œ IO çº¿ç¨‹
- [ ] é…ç½®æ—¥å¿—æ®µå¤§å°
- [ ] è°ƒæ•´å‰¯æœ¬æ‹‰å–å‚æ•°
- [ ] ä½¿ç”¨ SSD å­˜å‚¨

### æ“ä½œç³»ç»Ÿ

- [ ] è°ƒæ•´æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
- [ ] ä¼˜åŒ–è™šæ‹Ÿå†…å­˜è®¾ç½®
- [ ] é…ç½®ç½‘ç»œå‚æ•°
- [ ] ä½¿ç”¨ XFS æ–‡ä»¶ç³»ç»Ÿ

## ä¸‹ä¸€æ­¥

- ğŸ”§ [é›†ç¾¤ç®¡ç†](/docs/kafka/cluster-management) - é›†ç¾¤éƒ¨ç½²å’Œç®¡ç†
- ğŸ”’ [æœ€ä½³å®è·µ](/docs/kafka/best-practices) - ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ
- ğŸ“Š [ç›‘æ§ä¸è¿ç»´](/docs/kafka/monitoring) - ç›‘æ§å’Œå‘Šè­¦

## å‚è€ƒèµ„æ–™

- [Kafka æ€§èƒ½è°ƒä¼˜æŒ‡å—](https://kafka.apache.org/documentation/#prodconfig)
- [LinkedIn Kafka è°ƒä¼˜å®è·µ](https://engineering.linkedin.com/kafka)
