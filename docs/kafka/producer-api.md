---
sidebar_position: 5
title: "ç”Ÿäº§è€… API"
description: "æ·±å…¥å­¦ä¹  Kafka ç”Ÿäº§è€… API"
---

# Kafka ç”Ÿäº§è€… API

## ç”Ÿäº§è€…æ¦‚è¿°

Kafka Producer è´Ÿè´£å°†æ¶ˆæ¯å‘å¸ƒåˆ° Kafka Topicã€‚ç”Ÿäº§è€…ä¼šå°†æ¶ˆæ¯å‘é€åˆ°æŒ‡å®šçš„åˆ†åŒºï¼Œå¹¶å¯ä»¥é…ç½®å„ç§å‚æ•°æ¥æ§åˆ¶æ€§èƒ½å’Œå¯é æ€§ã€‚

## åŸºæœ¬é…ç½®

### å¿…éœ€é…ç½®

```java
Properties props = new Properties();

// Kafka é›†ç¾¤åœ°å€
props.put("bootstrap.servers", "localhost:9092");

// Key åºåˆ—åŒ–å™¨
props.put("key.serializer",
    "org.apache.kafka.common.serialization.StringSerializer");

// Value åºåˆ—åŒ–å™¨
props.put("value.serializer",
    "org.apache.kafka.common.serialization.StringSerializer");
```

### åˆ›å»ºç”Ÿäº§è€…

```java
KafkaProducer<String, String> producer = new KafkaProducer<>(props);
```

## å‘é€æ¶ˆæ¯çš„æ–¹å¼

### 1. å‘é€å¹¶å¿˜è®°ï¼ˆFire-and-Forgetï¼‰

```java
public void fireAndForget() {
    ProducerRecord<String, String> record =
        new ProducerRecord<>("my-topic", "key", "value");

    try {
        producer.send(record); // ä¸å…³å¿ƒç»“æœ
    } catch (Exception e) {
        // åªä¼šæ•è·ä¸å¯é‡è¯•çš„å¼‚å¸¸
        e.printStackTrace();
    }
}
```

**ç‰¹ç‚¹ï¼š**

- âœ… æœ€é«˜æ€§èƒ½
- âŒ å¯èƒ½ä¸¢å¤±æ¶ˆæ¯
- âŒ ä¸çŸ¥é“å‘é€ç»“æœ

### 2. åŒæ­¥å‘é€

```java
public void sendSync() throws Exception {
    ProducerRecord<String, String> record =
        new ProducerRecord<>("my-topic", "key", "value");

    try {
        // get() ä¼šé˜»å¡ç­‰å¾…ç»“æœ
        RecordMetadata metadata = producer.send(record).get();
        System.out.printf("å‘é€æˆåŠŸ: topic=%s, partition=%d, offset=%d%n",
            metadata.topic(), metadata.partition(), metadata.offset());
    } catch (ExecutionException e) {
        // å¤„ç†å‘é€å¤±è´¥
        e.printStackTrace();
    }
}
```

**ç‰¹ç‚¹ï¼š**

- âœ… å¯é æ€§é«˜
- âœ… çŸ¥é“å‘é€ç»“æœ
- âŒ æ€§èƒ½è¾ƒä½ï¼ˆé˜»å¡ç­‰å¾…ï¼‰

### 3. å¼‚æ­¥å‘é€ï¼ˆæ¨èï¼‰

```java
public void sendAsync() {
    ProducerRecord<String, String> record =
        new ProducerRecord<>("my-topic", "key", "value");

    producer.send(record, new Callback() {
        @Override
        public void onCompletion(RecordMetadata metadata, Exception exception) {
            if (exception == null) {
                System.out.printf("å‘é€æˆåŠŸ: topic=%s, partition=%d, offset=%d%n",
                    metadata.topic(), metadata.partition(), metadata.offset());
            } else {
                exception.printStackTrace();
            }
        }
    });
}

// ä½¿ç”¨ Lambda è¡¨è¾¾å¼
public void sendAsyncLambda() {
    ProducerRecord<String, String> record =
        new ProducerRecord<>("my-topic", "key", "value");

    producer.send(record, (metadata, exception) -> {
        if (exception == null) {
            System.out.println("å‘é€æˆåŠŸ: " + metadata.offset());
        } else {
            exception.printStackTrace();
        }
    });
}
```

**ç‰¹ç‚¹ï¼š**

- âœ… é«˜æ€§èƒ½
- âœ… çŸ¥é“å‘é€ç»“æœ
- âœ… ä¸é˜»å¡ï¼ˆæ¨èä½¿ç”¨ï¼‰

## é‡è¦é…ç½®å‚æ•°

### æ€§èƒ½ç›¸å…³

```java
// æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ 16KBï¼‰
props.put("batch.size", 16384);

// ç­‰å¾…æ—¶é—´ï¼ˆé»˜è®¤ 0msï¼‰
props.put("linger.ms", 10);

// ç¼“å†²åŒºå¤§å°ï¼ˆé»˜è®¤ 32MBï¼‰
props.put("buffer.memory", 33554432);

// å‹ç¼©ç±»å‹
props.put("compression.type", "lz4");  // none, gzip, snappy, lz4, zstd

// æœ€å¤§è¯·æ±‚å¤§å°
props.put("max.request.size", 1048576);
```

### å¯é æ€§ç›¸å…³

```java
// ACK ç¡®è®¤æœºåˆ¶
props.put("acks", "all");  // 0, 1, all(-1)

// é‡è¯•æ¬¡æ•°
props.put("retries", Integer.MAX_VALUE);

// é‡è¯•é—´éš”
props.put("retry.backoff.ms", 100);

// å¹‚ç­‰æ€§ï¼ˆé˜²æ­¢é‡å¤ï¼‰
props.put("enable.idempotence", "true");

// äº‹åŠ¡ IDï¼ˆç”¨äºäº‹åŠ¡æ€§å‘é€ï¼‰
props.put("transactional.id", "my-transactional-id");

// æœ€å¤§é£è¡Œä¸­è¯·æ±‚æ•°ï¼ˆä¿è¯é¡ºåºï¼‰
props.put("max.in.flight.requests.per.connection", 5);
```

## ACK ç¡®è®¤æœºåˆ¶è¯¦è§£

| acks        | è¯´æ˜                  | å»¶è¿Ÿ | ååé‡ | å¯é æ€§ | ä½¿ç”¨åœºæ™¯             |
| ----------- | --------------------- | ---- | ------ | ------ | -------------------- |
| **0**       | ä¸ç­‰å¾…ä»»ä½•ç¡®è®¤        | æœ€ä½ | æœ€é«˜   | æœ€ä½   | æ—¥å¿—æ”¶é›†ã€éå…³é”®æ•°æ® |
| **1**       | ç­‰å¾… Leader ç¡®è®¤      | ä¸­ç­‰ | ä¸­ç­‰   | ä¸­ç­‰   | ä¸€èˆ¬ä¸šåŠ¡æ¶ˆæ¯         |
| **all(-1)** | ç­‰å¾…æ‰€æœ‰ ISR å‰¯æœ¬ç¡®è®¤ | æœ€é«˜ | æœ€ä½   | æœ€é«˜   | é‡‘èäº¤æ˜“ã€å…³é”®æ•°æ®   |

```java
// acks=0: å‘é€åç«‹å³è¿”å›
props.put("acks", "0");

// acks=1: Leader å†™å…¥æˆåŠŸåè¿”å›
props.put("acks", "1");

// acks=all: æ‰€æœ‰ ISR å‰¯æœ¬å†™å…¥æˆåŠŸåè¿”å›
props.put("acks", "all");
props.put("min.insync.replicas", "2");  // è‡³å°‘ 2 ä¸ªå‰¯æœ¬ç¡®è®¤
```

## åˆ†åŒºç­–ç•¥

### é»˜è®¤åˆ†åŒºå™¨

```java
// 1. æŒ‡å®šåˆ†åŒº
ProducerRecord<String, String> record =
    new ProducerRecord<>("my-topic", 0, "key", "value");

// 2. æŒ‡å®š keyï¼ˆæ ¹æ® key çš„å“ˆå¸Œå€¼åˆ†é…åˆ†åŒºï¼‰
ProducerRecord<String, String> record =
    new ProducerRecord<>("my-topic", "key", "value");

// 3. ä¸æŒ‡å®š keyï¼ˆè½®è¯¢åˆ†é…ï¼‰
ProducerRecord<String, String> record =
    new ProducerRecord<>("my-topic", "value");
```

### è‡ªå®šä¹‰åˆ†åŒºå™¨

```java
public class CustomPartitioner implements Partitioner {

    @Override
    public int partition(String topic, Object key, byte[] keyBytes,
                        Object value, byte[] valueBytes, Cluster cluster) {
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();

        if (key == null) {
            // æ²¡æœ‰ key æ—¶çš„å¤„ç†
            return ThreadLocalRandom.current().nextInt(numPartitions);
        }

        // è‡ªå®šä¹‰åˆ†åŒºé€»è¾‘
        if (key.toString().startsWith("VIP")) {
            return 0; // VIP ç”¨æˆ·å‘é€åˆ°åˆ†åŒº 0
        }

        return Math.abs(key.hashCode()) % numPartitions;
    }

    @Override
    public void close() {}

    @Override
    public void configure(Map<String, ?> configs) {}
}

// ä½¿ç”¨è‡ªå®šä¹‰åˆ†åŒºå™¨
props.put("partitioner.class", "com.example.CustomPartitioner");
```

## åºåˆ—åŒ–å™¨

### å†…ç½®åºåˆ—åŒ–å™¨

```java
// String åºåˆ—åŒ–å™¨
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

// Integer åºåˆ—åŒ–å™¨
props.put("value.serializer", "org.apache.kafka.common.serialization.IntegerSerializer");

// Long åºåˆ—åŒ–å™¨
props.put("value.serializer", "org.apache.kafka.common.serialization.LongSerializer");

// ByteArray åºåˆ—åŒ–å™¨
props.put("value.serializer", "org.apache.kafka.common.serialization.ByteArraySerializer");
```

### JSON åºåˆ—åŒ–å™¨

```java
import com.fasterxml.jackson.databind.ObjectMapper;

public class JsonSerializer<T> implements Serializer<T> {
    private final ObjectMapper objectMapper = new ObjectMapper();

    @Override
    public byte[] serialize(String topic, T data) {
        if (data == null) {
            return null;
        }
        try {
            return objectMapper.writeValueAsBytes(data);
        } catch (Exception e) {
            throw new SerializationException("Error serializing JSON message", e);
        }
    }
}

// ä½¿ç”¨
props.put("value.serializer", "com.example.JsonSerializer");
```

### Avro åºåˆ—åŒ–å™¨

```java
// ä½¿ç”¨ Confluent Schema Registry
props.put("value.serializer",
    "io.confluent.kafka.serializers.KafkaAvroSerializer");
props.put("schema.registry.url", "http://localhost:8081");
```

## æ¶ˆæ¯å¤´ï¼ˆHeadersï¼‰

```java
ProducerRecord<String, String> record =
    new ProducerRecord<>("my-topic", "key", "value");

// æ·»åŠ æ¶ˆæ¯å¤´
record.headers()
    .add("correlation-id", "12345".getBytes())
    .add("source", "payment-service".getBytes())
    .add("timestamp", String.valueOf(System.currentTimeMillis()).getBytes());

producer.send(record);
```

## æ‹¦æˆªå™¨

```java
public class ProducerInterceptorDemo implements ProducerInterceptor<String, String> {

    @Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {
        // å‘é€å‰æ‹¦æˆª
        System.out.println("å‡†å¤‡å‘é€: " + record.value());

        // å¯ä»¥ä¿®æ”¹æ¶ˆæ¯
        return new ProducerRecord<>(
            record.topic(),
            record.key(),
            record.value() + " [intercepted]"
        );
    }

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        // æ”¶åˆ°ç¡®è®¤åè°ƒç”¨
        if (exception == null) {
            System.out.println("å‘é€æˆåŠŸ: partition=" + metadata.partition());
        } else {
            System.err.println("å‘é€å¤±è´¥: " + exception.getMessage());
        }
    }

    @Override
    public void close() {}

    @Override
    public void configure(Map<String, ?> configs) {}
}

// é…ç½®æ‹¦æˆªå™¨
props.put("interceptor.classes",
    "com.example.ProducerInterceptorDemo");
```

## äº‹åŠ¡æ€§å‘é€

```java
public class TransactionalProducer {

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // å¼€å¯äº‹åŠ¡
        props.put("enable.idempotence", "true");
        props.put("transactional.id", "my-transaction-id");

        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        // åˆå§‹åŒ–äº‹åŠ¡
        producer.initTransactions();

        try {
            // å¼€å§‹äº‹åŠ¡
            producer.beginTransaction();

            // å‘é€æ¶ˆæ¯
            producer.send(new ProducerRecord<>("topic1", "key1", "value1"));
            producer.send(new ProducerRecord<>("topic2", "key2", "value2"));

            // æäº¤äº‹åŠ¡
            producer.commitTransaction();

        } catch (Exception e) {
            // å›æ»šäº‹åŠ¡
            producer.abortTransaction();
            e.printStackTrace();
        } finally {
            producer.close();
        }
    }
}
```

## æœ€ä½³å®è·µ

### 1. ä½¿ç”¨å¼‚æ­¥å‘é€ + å›è°ƒ

```java
for (int i = 0; i < 1000; i++) {
    final int index = i;
    producer.send(
        new ProducerRecord<>("my-topic", "key-" + i, "value-" + i),
        (metadata, exception) -> {
            if (exception != null) {
                // è®°å½•å¤±è´¥çš„æ¶ˆæ¯ï¼Œåç»­é‡è¯•
                System.err.println("å‘é€å¤±è´¥: index=" + index);
            }
        }
    );
}
```

### 2. æ­£ç¡®å…³é—­ç”Ÿäº§è€…

```java
try {
    // å‘é€æ¶ˆæ¯
    producer.send(record);
} finally {
    // ç¡®ä¿æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ
    producer.flush();
    // å…³é—­ç”Ÿäº§è€…
    producer.close();
}
```

### 3. åˆç†é…ç½®æ‰¹æ¬¡å¤§å°å’Œå»¶è¿Ÿ

```java
// é«˜ååé‡åœºæ™¯
props.put("batch.size", 32768);      // å¢å¤§æ‰¹æ¬¡
props.put("linger.ms", 20);          // å¢åŠ ç­‰å¾…æ—¶é—´
props.put("compression.type", "lz4"); // å¯ç”¨å‹ç¼©

// ä½å»¶è¿Ÿåœºæ™¯
props.put("batch.size", 0);          // ä¸æ‰¹é‡
props.put("linger.ms", 0);           // ç«‹å³å‘é€
props.put("compression.type", "none"); // ä¸å‹ç¼©
```

### 4. å¼€å¯å¹‚ç­‰æ€§

```java
// é˜²æ­¢æ¶ˆæ¯é‡å¤
props.put("enable.idempotence", "true");
// æ­¤æ—¶ä»¥ä¸‹é…ç½®ä¼šè‡ªåŠ¨è®¾ç½®ï¼š
// acks=all
// retries=Integer.MAX_VALUE
// max.in.flight.requests.per.connection=5
```

## æ€§èƒ½ä¼˜åŒ–

### æ‰¹é‡å‘é€

```java
props.put("batch.size", 16384);    // 16KB
props.put("linger.ms", 10);        // ç­‰å¾… 10ms
```

### å‹ç¼©

```java
// lz4 å¹³è¡¡äº†å‹ç¼©ç‡å’Œ CPU æ¶ˆè€—
props.put("compression.type", "lz4");
```

### å¢åŠ ç¼“å†²åŒº

```java
props.put("buffer.memory", 67108864); // 64MB
```

## ä¸‹ä¸€æ­¥

- ğŸ“Š [æ¶ˆè´¹è€… API](./consumer-api.md) - å­¦ä¹ æ¶ˆæ¯æ¶ˆè´¹
- ğŸ”§ [é›†ç¾¤ç®¡ç†](./cluster-management.md) - äº†è§£é›†ç¾¤ç®¡ç†
- âš¡ [æ€§èƒ½ä¼˜åŒ–](./performance-optimization.md) - æ·±å…¥æ€§èƒ½ä¼˜åŒ–

## å‚è€ƒèµ„æ–™

- [Producer API å®˜æ–¹æ–‡æ¡£](https://kafka.apache.org/documentation/#producerapi)
- [Producer Configuration](https://kafka.apache.org/documentation/#producerconfigs)
