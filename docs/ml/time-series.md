---
sidebar_position: 15
title: ğŸ“ˆ æ—¶é—´åºåˆ—
---

# æ—¶é—´åºåˆ—åˆ†æ

æ—¶é—´åºåˆ—æ˜¯æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ•°æ®ç‚¹åºåˆ—ï¼Œå¹¿æ³›åº”ç”¨äºé‡‘èã€æ°”è±¡ã€é”€å”®é¢„æµ‹ç­‰é¢†åŸŸã€‚

## æ ¸å¿ƒæ¦‚å¿µ

### æ—¶é—´åºåˆ—ç»„æˆ

```mermaid
graph LR
    A[æ—¶é—´åºåˆ—] --> B[è¶‹åŠ¿ Trend]
    A --> C[å­£èŠ‚æ€§ Seasonality]
    A --> D[å‘¨æœŸæ€§ Cyclicity]
    A --> E[å™ªå£° Noise]
```

```python
from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt

# åˆ†è§£æ—¶é—´åºåˆ—
result = seasonal_decompose(ts, model='additive', period=12)

fig, axes = plt.subplots(4, 1, figsize=(12, 8))
result.observed.plot(ax=axes[0], title='åŸå§‹')
result.trend.plot(ax=axes[1], title='è¶‹åŠ¿')
result.seasonal.plot(ax=axes[2], title='å­£èŠ‚æ€§')
result.resid.plot(ax=axes[3], title='æ®‹å·®')
plt.tight_layout()
```

### å¹³ç¨³æ€§æ£€éªŒ

```python
from statsmodels.tsa.stattools import adfuller

def test_stationarity(series):
    result = adfuller(series)
    print(f'ADF ç»Ÿè®¡é‡: {result[0]:.4f}')
    print(f'p-value: {result[1]:.4f}')
    if result[1] < 0.05:
        print('åºåˆ—æ˜¯å¹³ç¨³çš„')
    else:
        print('åºåˆ—æ˜¯éå¹³ç¨³çš„ï¼Œéœ€è¦å·®åˆ†')
```

## ä¼ ç»Ÿæ–¹æ³•

### ARIMA

$$
ARIMA(p, d, q)
$$

- **p**: è‡ªå›å½’é˜¶æ•°
- **d**: å·®åˆ†æ¬¡æ•°
- **q**: ç§»åŠ¨å¹³å‡é˜¶æ•°

```python
from statsmodels.tsa.arima.model import ARIMA
from pmdarima import auto_arima

# è‡ªåŠ¨é€‰æ‹©å‚æ•°
auto_model = auto_arima(
    ts,
    seasonal=False,
    stepwise=True,
    suppress_warnings=True
)
print(auto_model.summary())

# æ‰‹åŠ¨ ARIMA
model = ARIMA(ts, order=(2, 1, 2))
fitted = model.fit()

# é¢„æµ‹
forecast = fitted.forecast(steps=30)
```

### SARIMA (å­£èŠ‚æ€§ ARIMA)

```python
from statsmodels.tsa.statespace.sarimax import SARIMAX

# SARIMA(p,d,q)(P,D,Q,m)
model = SARIMAX(
    ts,
    order=(1, 1, 1),
    seasonal_order=(1, 1, 1, 12)  # æœˆåº¦å­£èŠ‚æ€§
)
fitted = model.fit()
forecast = fitted.forecast(steps=12)
```

### Prophet

Facebook å¼€æºçš„æ—¶é—´åºåˆ—é¢„æµ‹åº“ï¼Œå¯¹ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼é²æ£’ã€‚

```python
from prophet import Prophet
import pandas as pd

# å‡†å¤‡æ•°æ®ï¼ˆå¿…é¡»æœ‰ ds å’Œ y åˆ—ï¼‰
df = pd.DataFrame({'ds': dates, 'y': values})

# è®­ç»ƒ
model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False
)
model.fit(df)

# é¢„æµ‹
future = model.make_future_dataframe(periods=30)
forecast = model.predict(future)

# å¯è§†åŒ–
model.plot(forecast)
model.plot_components(forecast)
```

## æœºå™¨å­¦ä¹ æ–¹æ³•

### ç‰¹å¾å·¥ç¨‹

```python
def create_time_features(df, date_col):
    df['year'] = df[date_col].dt.year
    df['month'] = df[date_col].dt.month
    df['day'] = df[date_col].dt.day
    df['dayofweek'] = df[date_col].dt.dayofweek
    df['is_weekend'] = df['dayofweek'] >= 5

    # æ»åç‰¹å¾
    for lag in [1, 7, 30]:
        df[f'lag_{lag}'] = df['value'].shift(lag)

    # æ»šåŠ¨ç»Ÿè®¡
    df['rolling_mean_7'] = df['value'].rolling(7).mean()
    df['rolling_std_7'] = df['value'].rolling(7).std()

    return df
```

### XGBoost æ—¶åºé¢„æµ‹

```python
import xgboost as xgb

# åˆ›å»ºç‰¹å¾
df = create_time_features(df, 'date')
df = df.dropna()

# åˆ’åˆ†ï¼ˆæ—¶åºä¸èƒ½éšæœºåˆ’åˆ†ï¼ï¼‰
train = df[df['date'] < '2024-01-01']
test = df[df['date'] >= '2024-01-01']

feature_cols = ['month', 'dayofweek', 'lag_1', 'lag_7', 'rolling_mean_7']

model = xgb.XGBRegressor(n_estimators=100)
model.fit(train[feature_cols], train['value'])
predictions = model.predict(test[feature_cols])
```

## æ·±åº¦å­¦ä¹ æ–¹æ³•

### LSTM

```python
import torch
import torch.nn as nn

class LSTMPredictor(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])  # å–æœ€åæ—¶åˆ»
        return out

# åˆ›å»ºåºåˆ—æ•°æ®
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)
```

## è¯„ä¼°æŒ‡æ ‡

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error

# MAE
mae = mean_absolute_error(y_true, y_pred)

# RMSE
rmse = mean_squared_error(y_true, y_pred, squared=False)

# MAPE
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
```

## æ–¹æ³•é€‰æ‹©

| åœºæ™¯             | æ¨èæ–¹æ³•                       |
| ---------------- | ------------------------------ |
| å¿«é€ŸåŸºçº¿         | ARIMA                          |
| å¤æ‚å­£èŠ‚æ€§       | Prophet / SARIMA               |
| å¤šå˜é‡ã€å¤æ‚ç‰¹å¾ | XGBoost / LightGBM             |
| é•¿åºåˆ—ä¾èµ–       | LSTM / Transformer             |
| ç”Ÿäº§ç¯å¢ƒ         | Prophet (æ˜“ç”¨)ã€XGBoost (æ€§èƒ½) |
