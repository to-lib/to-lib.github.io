---
sidebar_position: 47
title: ğŸ” éšç§è®¡ç®—
---

# éšç§è®¡ç®—

éšç§è®¡ç®—åœ¨ä¿æŠ¤æ•°æ®éšç§çš„åŒæ—¶è¿›è¡Œæœºå™¨å­¦ä¹ ã€‚

## æŠ€æœ¯æ¦‚è§ˆ

```mermaid
graph TB
    A[éšç§è®¡ç®—] --> B[å·®åˆ†éšç§]
    A --> C[åŒæ€åŠ å¯†]
    A --> D[å®‰å…¨å¤šæ–¹è®¡ç®—]
    A --> E[å¯ä¿¡æ‰§è¡Œç¯å¢ƒ]
```

## å·®åˆ†éšç§

### æ ¸å¿ƒæ¦‚å¿µ

$$
\Pr[M(D) \in S] \leq e^\epsilon \cdot \Pr[M(D') \in S] + \delta
$$

- **Îµ (epsilon)**: éšç§é¢„ç®—ï¼Œè¶Šå°è¶Šéšç§
- **Î´ (delta)**: å¤±è´¥æ¦‚ç‡

### å®ç°

```python
import numpy as np

def laplace_mechanism(value, sensitivity, epsilon):
    """æ‹‰æ™®æ‹‰æ–¯æœºåˆ¶"""
    noise = np.random.laplace(0, sensitivity / epsilon)
    return value + noise

def gaussian_mechanism(value, sensitivity, epsilon, delta):
    """é«˜æ–¯æœºåˆ¶"""
    sigma = sensitivity * np.sqrt(2 * np.log(1.25 / delta)) / epsilon
    noise = np.random.normal(0, sigma)
    return value + noise

# DP-SGD
def dp_sgd_step(model, batch, epsilon, delta, max_grad_norm):
    grads = compute_per_sample_gradients(model, batch)

    # æ¢¯åº¦è£å‰ª
    clipped_grads = [clip_gradient(g, max_grad_norm) for g in grads]

    # èšåˆå¹¶åŠ å™ªå£°
    aggregated = sum(clipped_grads) / len(clipped_grads)
    noisy_grad = gaussian_mechanism(aggregated, max_grad_norm, epsilon, delta)

    apply_gradient(model, noisy_grad)
```

### Opacus (PyTorch DP)

```python
from opacus import PrivacyEngine

model = MyModel()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

privacy_engine = PrivacyEngine()
model, optimizer, dataloader = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=dataloader,
    noise_multiplier=1.0,
    max_grad_norm=1.0
)

# æ­£å¸¸è®­ç»ƒï¼Œè‡ªåŠ¨æ·»åŠ  DP
for batch in dataloader:
    loss = model(batch)
    loss.backward()
    optimizer.step()

# è·å–éšç§æ¶ˆè€—
epsilon = privacy_engine.get_epsilon(delta=1e-5)
```

## åŒæ€åŠ å¯†

```python
import tenseal as ts

# åˆ›å»ºä¸Šä¸‹æ–‡
context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192)
context.generate_galois_keys()

# åŠ å¯†æ•°æ®
plain_vector = [1.0, 2.0, 3.0]
encrypted = ts.ckks_vector(context, plain_vector)

# åœ¨å¯†æ–‡ä¸Šè®¡ç®—
result = encrypted * 2 + 1  # ä»æ˜¯å¯†æ–‡

# è§£å¯†
decrypted = result.decrypt()
```

## å®‰å…¨å¤šæ–¹è®¡ç®—

```python
# PySyft ç¤ºä¾‹
import syft as sy

# åˆ›å»ºè™šæ‹Ÿå·¥ä½œè€…
alice = sy.VirtualWorker(hook, id="alice")
bob = sy.VirtualWorker(hook, id="bob")

# ç§˜å¯†å…±äº«
x = torch.tensor([1, 2, 3])
x_shared = x.share(alice, bob)

# åœ¨ç§˜å¯†å…±äº«ä¸Šè®¡ç®—
y_shared = x_shared * 2
y = y_shared.get()  # é‡å»ºç»“æœ
```

## æŠ€æœ¯å¯¹æ¯”

| æŠ€æœ¯     | åŸç†     | æ€§èƒ½ | å®‰å…¨æ€§   |
| -------- | -------- | ---- | -------- |
| å·®åˆ†éšç§ | æ·»åŠ å™ªå£° | é«˜   | å¯è¯æ˜   |
| åŒæ€åŠ å¯† | å¯†æ–‡è®¡ç®— | ä½   | å¼º       |
| å®‰å…¨å¤šæ–¹ | ç§˜å¯†å…±äº« | ä¸­   | å¼º       |
| TEE      | ç¡¬ä»¶éš”ç¦» | é«˜   | ä¾èµ–ç¡¬ä»¶ |
