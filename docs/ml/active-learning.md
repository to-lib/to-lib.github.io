---
sidebar_position: 32
title: ğŸ¯ ä¸»åŠ¨å­¦ä¹ 
---

# ä¸»åŠ¨å­¦ä¹ 

ä¸»åŠ¨å­¦ä¹ æ™ºèƒ½é€‰æ‹©æœ€æœ‰ä»·å€¼çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨ï¼Œå‡å°‘æ ‡æ³¨æˆæœ¬ã€‚

## æ ¸å¿ƒæ€æƒ³

```mermaid
graph LR
    A[æœªæ ‡æ³¨æ± ] --> B[é‡‡æ ·ç­–ç•¥]
    B --> C[é€‰æ‹©æ ·æœ¬]
    C --> D[äººå·¥æ ‡æ³¨]
    D --> E[åŠ å…¥è®­ç»ƒé›†]
    E --> F[æ›´æ–°æ¨¡å‹]
    F --> B
```

## é‡‡æ ·ç­–ç•¥

### ä¸ç¡®å®šæ€§é‡‡æ ·

```python
import numpy as np

def uncertainty_sampling(model, unlabeled_data, n_samples):
    probs = model.predict_proba(unlabeled_data)

    # æœ€å°ç½®ä¿¡åº¦
    confidence = np.max(probs, axis=1)
    uncertain_idx = np.argsort(confidence)[:n_samples]

    return uncertain_idx

def entropy_sampling(model, unlabeled_data, n_samples):
    probs = model.predict_proba(unlabeled_data)
    entropy = -np.sum(probs * np.log(probs + 1e-10), axis=1)
    return np.argsort(entropy)[-n_samples:]

def margin_sampling(model, unlabeled_data, n_samples):
    probs = model.predict_proba(unlabeled_data)
    sorted_probs = np.sort(probs, axis=1)
    margin = sorted_probs[:, -1] - sorted_probs[:, -2]
    return np.argsort(margin)[:n_samples]
```

### å¤šæ ·æ€§é‡‡æ ·

```python
from sklearn.cluster import KMeans

def diversity_sampling(features, n_samples):
    # K-Means èšç±»é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬
    kmeans = KMeans(n_clusters=n_samples)
    kmeans.fit(features)

    # é€‰æ‹©æœ€æ¥è¿‘ä¸­å¿ƒçš„æ ·æœ¬
    selected = []
    for i in range(n_samples):
        cluster_mask = kmeans.labels_ == i
        cluster_features = features[cluster_mask]
        distances = np.linalg.norm(cluster_features - kmeans.cluster_centers_[i], axis=1)
        selected.append(np.where(cluster_mask)[0][np.argmin(distances)])

    return selected
```

### æ··åˆç­–ç•¥

```python
def hybrid_sampling(model, features, unlabeled_data, n_samples, alpha=0.5):
    # ä¸ç¡®å®šæ€§åˆ†æ•°
    probs = model.predict_proba(unlabeled_data)
    uncertainty = 1 - np.max(probs, axis=1)

    # å¤šæ ·æ€§åˆ†æ•° (åˆ°å·²é€‰æ ·æœ¬çš„è·ç¦»)
    diversity = compute_diversity_scores(features)

    # ç»¼åˆåˆ†æ•°
    scores = alpha * uncertainty + (1 - alpha) * diversity
    return np.argsort(scores)[-n_samples:]
```

## å®Œæ•´æµç¨‹

```python
from modAL.models import ActiveLearner
from sklearn.ensemble import RandomForestClassifier

# åˆå§‹åŒ–
learner = ActiveLearner(
    estimator=RandomForestClassifier(),
    X_training=X_initial,
    y_training=y_initial
)

# ä¸»åŠ¨å­¦ä¹ å¾ªç¯
for i in range(n_iterations):
    # æŸ¥è¯¢æœ€ä¸ç¡®å®šçš„æ ·æœ¬
    query_idx, query_instance = learner.query(X_pool)

    # è·å–æ ‡ç­¾ (æ¨¡æ‹Ÿäººå·¥æ ‡æ³¨)
    y_new = oracle.annotate(query_instance)

    # æ›´æ–°æ¨¡å‹
    learner.teach(query_instance, y_new)

    # ä»æ± ä¸­ç§»é™¤
    X_pool = np.delete(X_pool, query_idx, axis=0)
```

## ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥     | ä¼˜ç‚¹     | ç¼ºç‚¹             |
| -------- | -------- | ---------------- |
| ä¸ç¡®å®šæ€§ | ç®€å•é«˜æ•ˆ | å¯èƒ½é€‰æ‹©ç›¸ä¼¼æ ·æœ¬ |
| å¤šæ ·æ€§   | è¦†ç›–å¹¿   | å¿½ç•¥æ¨¡å‹éœ€æ±‚     |
| æ··åˆ     | å¹³è¡¡ä¸¤è€… | éœ€è¦è°ƒå‚         |
| å§”å‘˜ä¼š   | é²æ£’     | è®¡ç®—å¼€é”€å¤§       |
