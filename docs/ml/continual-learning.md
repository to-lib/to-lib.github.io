---
sidebar_position: 34
title: ğŸ§  æŒç»­å­¦ä¹ 
---

# æŒç»­å­¦ä¹ 

æŒç»­å­¦ä¹ ä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ–°ä»»åŠ¡è€Œä¸é—å¿˜æ—§çŸ¥è¯†ï¼ˆé¿å…ç¾éš¾æ€§é—å¿˜ï¼‰ã€‚

## ç¾éš¾æ€§é—å¿˜

```mermaid
graph LR
    A[å­¦ä¹ ä»»åŠ¡A] --> B[ä»»åŠ¡Aè¡¨ç°å¥½]
    B --> C[å­¦ä¹ ä»»åŠ¡B]
    C --> D[ä»»åŠ¡Bè¡¨ç°å¥½]
    D --> E[ä»»åŠ¡Aè¡¨ç°ä¸‹é™!]
```

## è§£å†³æ–¹æ¡ˆ

### æ­£åˆ™åŒ–æ–¹æ³• (EWC)

```python
import torch
import torch.nn as nn

class EWC:
    def __init__(self, model, dataloader, importance=1000):
        self.model = model
        self.importance = importance

        # è®¡ç®— Fisher ä¿¡æ¯çŸ©é˜µ
        self.fisher = {}
        self.old_params = {}

        self._compute_fisher(dataloader)

    def _compute_fisher(self, dataloader):
        self.model.eval()
        for name, param in self.model.named_parameters():
            self.fisher[name] = torch.zeros_like(param)
            self.old_params[name] = param.clone()

        for x, y in dataloader:
            self.model.zero_grad()
            output = self.model(x)
            loss = nn.functional.cross_entropy(output, y)
            loss.backward()

            for name, param in self.model.named_parameters():
                self.fisher[name] += param.grad ** 2 / len(dataloader)

    def penalty(self):
        loss = 0
        for name, param in self.model.named_parameters():
            loss += (self.fisher[name] * (param - self.old_params[name]) ** 2).sum()
        return self.importance * loss
```

### å›æ”¾æ–¹æ³•

```python
class ReplayBuffer:
    def __init__(self, capacity):
        self.buffer = []
        self.capacity = capacity

    def add(self, samples):
        self.buffer.extend(samples)
        if len(self.buffer) > self.capacity:
            # éšæœºä¿ç•™
            indices = np.random.choice(len(self.buffer), self.capacity, replace=False)
            self.buffer = [self.buffer[i] for i in indices]

    def sample(self, n):
        return random.sample(self.buffer, min(n, len(self.buffer)))

# è®­ç»ƒæ—¶æ··åˆæ–°æ—§æ•°æ®
def train_with_replay(model, new_data, replay_buffer, replay_ratio=0.5):
    replay_size = int(len(new_data) * replay_ratio)
    replay_data = replay_buffer.sample(replay_size)
    combined = new_data + replay_data
    train(model, combined)
    replay_buffer.add(new_data)
```

### æ¶æ„æ–¹æ³•

```python
class ProgressiveNetwork(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.columns = nn.ModuleList()
        self.laterals = nn.ModuleList()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim

    def add_column(self, output_dim):
        # æ–°ä»»åŠ¡æ·»åŠ æ–°åˆ—
        column = nn.Sequential(
            nn.Linear(self.input_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Linear(self.hidden_dim, output_dim)
        )

        # å†»ç»“æ—§åˆ—
        for old_col in self.columns:
            for param in old_col.parameters():
                param.requires_grad = False

        self.columns.append(column)
```

## æ–¹æ³•å¯¹æ¯”

| æ–¹æ³•     | æ€æƒ³             | ä¼˜ç‚¹         | ç¼ºç‚¹               |
| -------- | ---------------- | ------------ | ------------------ |
| EWC      | ä¿æŠ¤é‡è¦å‚æ•°     | æ— éœ€å­˜å‚¨æ•°æ® | ä»»åŠ¡æ•°å¢åŠ æ•ˆæœä¸‹é™ |
| å›æ”¾     | ä¿ç•™æ—§æ•°æ®æ ·æœ¬   | ç®€å•æœ‰æ•ˆ     | éœ€è¦å­˜å‚¨ç©ºé—´       |
| æ¶æ„æ‰©å±• | æ¯ä»»åŠ¡æ–°ç½‘ç»œ     | ä¸é—å¿˜       | æ¨¡å‹æŒç»­å¢å¤§       |
| çŸ¥è¯†è’¸é¦ | æ—§æ¨¡å‹æŒ‡å¯¼æ–°æ¨¡å‹ | çµæ´»         | è®¡ç®—å¼€é”€           |
