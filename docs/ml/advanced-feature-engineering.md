---
sidebar_position: 40
title: ğŸ”§ ç‰¹å¾å·¥ç¨‹è¿›é˜¶
---

# ç‰¹å¾å·¥ç¨‹è¿›é˜¶

é«˜çº§ç‰¹å¾å·¥ç¨‹æŠ€æœ¯ä¸è‡ªåŠ¨åŒ–æ–¹æ³•ã€‚

## ç‰¹å¾äº¤å‰

```python
from sklearn.preprocessing import PolynomialFeatures

# å¤šé¡¹å¼ç‰¹å¾
poly = PolynomialFeatures(degree=2, interaction_only=True)
X_poly = poly.fit_transform(X)

# æ‰‹åŠ¨äº¤å‰
df['feature_cross'] = df['feature1'] * df['feature2']
df['feature_ratio'] = df['feature1'] / (df['feature2'] + 1e-8)
```

## Target Encoding

```python
import category_encoders as ce

# ç›®æ ‡ç¼–ç 
encoder = ce.TargetEncoder(cols=['category_col'])
X_encoded = encoder.fit_transform(X, y)

# å¸¦å¹³æ»‘çš„ç›®æ ‡ç¼–ç 
def target_encode_smooth(df, col, target, m=10):
    global_mean = df[target].mean()
    agg = df.groupby(col)[target].agg(['mean', 'count'])
    smooth = (agg['count'] * agg['mean'] + m * global_mean) / (agg['count'] + m)
    return df[col].map(smooth)
```

## æ—¶é—´ç‰¹å¾

```python
def create_time_features(df, date_col):
    df['year'] = df[date_col].dt.year
    df['month'] = df[date_col].dt.month
    df['day'] = df[date_col].dt.day
    df['dayofweek'] = df[date_col].dt.dayofweek
    df['hour'] = df[date_col].dt.hour
    df['is_weekend'] = df['dayofweek'] >= 5
    df['is_month_start'] = df[date_col].dt.is_month_start
    df['is_month_end'] = df[date_col].dt.is_month_end

    # å‘¨æœŸæ€§ç¼–ç 
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)

    return df
```

## èšåˆç‰¹å¾

```python
def create_agg_features(df, group_col, agg_col):
    aggs = df.groupby(group_col)[agg_col].agg(['mean', 'std', 'min', 'max', 'count'])
    aggs.columns = [f'{agg_col}_{stat}' for stat in aggs.columns]
    return df.merge(aggs, on=group_col, how='left')
```

## è‡ªåŠ¨ç‰¹å¾å·¥ç¨‹

### Featuretools

```python
import featuretools as ft

# å®šä¹‰å®ä½“
es = ft.EntitySet(id='data')
es.add_dataframe(dataframe=df, dataframe_name='main', index='id')

# æ·±åº¦ç‰¹å¾åˆæˆ
features, feature_defs = ft.dfs(
    entityset=es,
    target_dataframe_name='main',
    max_depth=2
)
```

### OpenFE

```python
from openfe import OpenFE

ofe = OpenFE()
features = ofe.fit(X_train, y_train, n_jobs=-1)

# åº”ç”¨ç‰¹å¾
X_train_new = ofe.transform(X_train)
X_test_new = ofe.transform(X_test)
```

## ç‰¹å¾é€‰æ‹©è¿›é˜¶

### Boruta

```python
from boruta import BorutaPy
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_jobs=-1)
boruta = BorutaPy(rf, n_estimators='auto', verbose=2)
boruta.fit(X.values, y.values)

selected_features = X.columns[boruta.support_].tolist()
```

### SHAP ç‰¹å¾é€‰æ‹©

```python
import shap

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# åŸºäº SHAP é‡è¦æ€§é€‰æ‹©
importance = np.abs(shap_values).mean(axis=0)
top_features = np.argsort(importance)[-20:]
```

## ç‰¹å¾å­˜å‚¨

```python
# Feast ç¤ºä¾‹
from feast import FeatureStore

store = FeatureStore(repo_path=".")

# è·å–å†å²ç‰¹å¾
training_df = store.get_historical_features(
    entity_df=entity_df,
    features=["user_features:age", "user_features:income"]
).to_df()

# åœ¨çº¿è·å–
online_features = store.get_online_features(
    features=["user_features:age"],
    entity_rows=[{"user_id": 1001}]
).to_dict()
```
