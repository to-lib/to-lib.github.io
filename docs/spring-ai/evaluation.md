---
sidebar_position: 21
title: 评测与回归测试（Evaluation）
---

# 评测与回归测试（Evaluation）

AI 应用的“正确性”很难一次性证明，但可以通过工程化手段让质量可控、可回归：

- 需求迭代时避免质量倒退
- 模型/提示词/向量库变更时能够对比
- 对“回答是否基于知识库”建立度量

这篇文档给出一套可落地的评测思路，适用于：

- 纯 Chat（无 RAG）
- RAG 问答
- 工具/函数调用

## 评测对象

- **答案质量**：是否回答到点、是否符合格式要求
- **事实性**：是否编造（hallucination）
- **一致性**：同类问题回答是否稳定
- **RAG groundedness**：回答是否能在检索到的上下文中找到依据
- **成本与时延**：token、耗时

## 构建 Golden Set（黄金数据集）

建议你维护一份“固定问题集”，每条包含：

- `question`
- `expected`（可选：期望关键词/结构）
- `mustNot`（可选：禁止出现的关键词）
- `notes`（人工备注）

对 RAG，还应记录：

- 期望命中的 `source`（或至少命中某个文档集合）

## 自动化回归测试

### 思路 1：关键词/结构约束（简单可靠）

- 验证输出包含关键点
- 验证输出符合 JSON/Markdown 表格等结构（可结合 OutputParser）

### 思路 2：LLM-as-a-Judge（更强但要谨慎）

让另一个模型对输出打分（相关性/正确性/是否引用上下文）。注意：

- Judge 本身也会有偏差
- 需要固定 judge 模型与 prompt，避免漂移

## RAG 的检索层评测

在回答生成前，先评测“检索是否命中”：

- `recall@k`：期望文档是否出现在 topK
- `mrr`：期望文档排名是否靠前
- 命中数量分布：检索结果是否经常为空

这能快速定位“问题在检索还是在生成”。

## 线上评测与反馈闭环

- **人工反馈按钮**：👍/👎 + 选择原因（不相关/不准确/太长/太短/不安全等）
- **采样回放**：对线上流量抽样进入离线评测
- **分层评测**：按业务场景/用户类型分别评测

## 变更策略建议

每次变更（模型、提示词、分块策略、向量库）建议走：

- 在测试环境跑全量 golden set
- 对比“质量指标 + 成本指标”
- 通过后再灰度到线上

## 下一步

- [可观测性](/docs/spring-ai/observability)
- [文档摄取与向量化](/docs/spring-ai/document-ingestion)
- [最佳实践](/docs/spring-ai/best-practices)
